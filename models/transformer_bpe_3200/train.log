2025-05-29 09:42:35,592 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -                           cfg.name : transformer_bpe_3k_config
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -                     cfg.data.train : data_word_level/train
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -                       cfg.data.dev : data_word_level/dev
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -                      cfg.data.test : data_word_level/test
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -                  cfg.data.src.lang : it
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : shared_models/joint-vocab3200.txt
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.pretokenizer : none
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.num_merges : 3200
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : data_word_level/codes3200.bpe
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : en
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : shared_models/joint-vocab3200.txt
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.pretokenizer : none
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.num_merges : 3200
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : data_word_level/codes3200.bpe
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2025-05-29 09:42:35,592 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/transformer_bpe_3200
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -              cfg.training.use_cuda : False
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2025-05-29 09:42:35,593 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2025-05-29 09:42:35,595 - INFO - joeynmt.data - Building tokenizer...
2025-05-29 09:42:35,600 - INFO - joeynmt.tokenizers - it tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-29 09:42:35,600 - INFO - joeynmt.tokenizers - en tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-29 09:42:35,600 - INFO - joeynmt.data - Loading train set...
2025-05-29 09:42:35,690 - INFO - joeynmt.data - Building vocabulary...
2025-05-29 09:42:35,764 - INFO - joeynmt.data - Loading dev set...
2025-05-29 09:42:35,766 - INFO - joeynmt.data - Loading test set...
2025-05-29 09:42:35,768 - INFO - joeynmt.data - Data loaded.
2025-05-29 09:42:35,768 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=it, trg_lang=en, has_trg=True, random_subset=-1)
2025-05-29 09:42:35,768 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=929, src_lang=it, trg_lang=en, has_trg=True, random_subset=-1)
2025-05-29 09:42:35,768 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1566, src_lang=it, trg_lang=en, has_trg=True, random_subset=-1)
2025-05-29 09:42:35,768 - INFO - joeynmt.data - First training example:
	[SRC] Al G@@ ore : ar@@ re@@ stiamo il ri@@ scal@@ d@@ amento globale
	[TRG] Al G@@ ore : A@@ ver@@ ting the cli@@ mate c@@ ris@@ is
2025-05-29 09:42:35,768 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) the (7) a (8) to (9) di
2025-05-29 09:42:35,768 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) the (7) a (8) to (9) di
2025-05-29 09:42:35,768 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 3418
2025-05-29 09:42:35,768 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 3418
2025-05-29 09:42:35,769 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-29 09:42:35,832 - INFO - joeynmt.model - Enc-dec model built.
2025-05-29 09:42:35,833 - INFO - joeynmt.model - Total params: 3774208
2025-05-29 09:42:35,834 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight']
2025-05-29 09:42:35,834 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=3418),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=3418),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2025-05-29 09:42:35,834 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2025-05-29 09:42:35,834 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2025-05-29 09:42:35,834 - INFO - joeynmt.training - Train stats:
	device: cpu
	n_gpu: 0
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2025-05-29 09:42:35,834 - INFO - joeynmt.training - EPOCH 1
2025-05-29 09:42:51,827 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     3.989498, Batch Acc: 0.063354, Tokens per Sec:     4478, Lr: 0.000300
2025-05-29 09:43:07,912 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     3.963160, Batch Acc: 0.095154, Tokens per Sec:     4388, Lr: 0.000300
2025-05-29 09:43:24,247 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     3.668967, Batch Acc: 0.117616, Tokens per Sec:     4380, Lr: 0.000300
2025-05-29 09:43:40,033 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     3.642300, Batch Acc: 0.128011, Tokens per Sec:     4331, Lr: 0.000300
2025-05-29 09:43:55,828 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     3.435723, Batch Acc: 0.144158, Tokens per Sec:     4623, Lr: 0.000300
2025-05-29 09:43:55,829 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 09:43:55,829 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 09:45:01,886 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.52, ppl:  33.82, acc:   0.14, generation: 66.0501[sec], evaluation: 0.0000[sec]
2025-05-29 09:45:01,889 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 09:45:02,036 - INFO - joeynmt.training - Example #0
2025-05-29 09:45:02,036 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 09:45:02,036 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 09:45:02,036 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['So', 'I', 'have', 'the', 'world', ',', 'I', "'re", 'the', 'world', ',', 'and', 'I', "'re", 'the', 'world', ',', 'and', 'I', "'re", 'the', 'world', ',', 'and', 'the', 'world', ',', 'and', 'I', "'re", 'the', 'world', ',', 'and', 'I', "'re", 'the', 'world', ',', 'and', 'I', "'re", 'the', 'world', ',', 'and', 'I', "'re", 'be', 'the', 'world', '.', '</s>']
2025-05-29 09:45:02,036 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 09:45:02,036 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 09:45:02,036 - INFO - joeynmt.training - 	Hypothesis: So I have the world , I 're the world , and I 're the world , and I 're the world , and the world , and I 're the world , and I 're the world , and I 're the world , and I 're be the world .
2025-05-29 09:45:02,036 - INFO - joeynmt.training - Example #1
2025-05-29 09:45:02,036 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 09:45:02,036 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 09:45:02,036 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'the', 'lot', 'of', 'the', 'world', 'and', 'the', 'world', 'and', 'the', 'world', 'and', 'I', "'re", 'the', 'world', '.', '</s>']
2025-05-29 09:45:02,036 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 09:45:02,036 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 09:45:02,036 - INFO - joeynmt.training - 	Hypothesis: The first the lot of the world and the world and the world and I 're the world .
2025-05-29 09:45:02,036 - INFO - joeynmt.training - Example #2
2025-05-29 09:45:02,036 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 09:45:02,036 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 09:45:02,036 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'a', 'lot', ',', 'I', 'have', 'a', 'a', 'a', 'little', 'little', 'little', 'little', 'little', 'little', 'a', 'a', 'a', 'a', 'lot', 'of', 'the', 'lot', 'of', 'the', 'lot', '.', '</s>']
2025-05-29 09:45:02,037 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 09:45:02,037 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 09:45:02,037 - INFO - joeynmt.training - 	Hypothesis: The a lot , I have a a a little little little little little little a a a a lot of the lot of the lot .
2025-05-29 09:45:02,037 - INFO - joeynmt.training - Example #3
2025-05-29 09:45:02,037 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 09:45:02,037 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 09:45:02,037 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', "'re", 'the', 'world', ',', 'and', 'I', "'re", 'the', 'world', ',', 'and', 'I', "'re", 'the', 'world', '.', '</s>']
2025-05-29 09:45:02,037 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 09:45:02,037 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 09:45:02,037 - INFO - joeynmt.training - 	Hypothesis: And I 're the world , and I 're the world , and I 're the world .
2025-05-29 09:45:02,037 - INFO - joeynmt.training - Example #4
2025-05-29 09:45:02,037 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 09:45:02,037 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 09:45:02,037 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'little', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'ed', 'of', 'the', 'lot', 'of', 'the', 'lot', 'of', 'the', 'lot', '.', '</s>']
2025-05-29 09:45:02,037 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 09:45:02,037 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 09:45:02,037 - INFO - joeynmt.training - 	Hypothesis: The little bbbbbbbbbed of the lot of the lot of the lot .
2025-05-29 09:45:18,009 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     3.408009, Batch Acc: 0.152347, Tokens per Sec:     4427, Lr: 0.000300
2025-05-29 09:45:34,140 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     3.437974, Batch Acc: 0.159485, Tokens per Sec:     4344, Lr: 0.000300
2025-05-29 09:45:50,761 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     3.351960, Batch Acc: 0.170480, Tokens per Sec:     4358, Lr: 0.000300
2025-05-29 09:46:07,125 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     3.428221, Batch Acc: 0.176005, Tokens per Sec:     4325, Lr: 0.000300
2025-05-29 09:46:24,120 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     3.161088, Batch Acc: 0.185144, Tokens per Sec:     4323, Lr: 0.000300
2025-05-29 09:46:24,121 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 09:46:24,121 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 09:47:26,593 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.31, ppl:  27.46, acc:   0.18, generation: 62.4662[sec], evaluation: 0.0000[sec]
2025-05-29 09:47:26,596 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 09:47:26,743 - INFO - joeynmt.training - Example #0
2025-05-29 09:47:26,743 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 09:47:26,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 09:47:26,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'people', 'I', "'m", 'to', 'be', 'to', 'the', 'world', 'that', 'we', 'have', 'to', 'be', 'the', 'world', 'that', 'the', 'world', ',', 'and', 'the', 'world', ',', 'the', 'world', ',', 'and', 'the', 'world', ',', 'and', 'the', 'world', ',', 'and', 'the', 'world', ',', 'the', 'world', ',', 'the', 'world', ',', 'the', 'world', ',', 'the', 'world', '.', '</s>']
2025-05-29 09:47:26,743 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 09:47:26,743 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 09:47:26,743 - INFO - joeynmt.training - 	Hypothesis: The first people I 'm to be to the world that we have to be the world that the world , and the world , the world , and the world , and the world , and the world , the world , the world , the world , the world .
2025-05-29 09:47:26,743 - INFO - joeynmt.training - Example #1
2025-05-29 09:47:26,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 09:47:26,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 09:47:26,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'the', 'world', 'is', 'the', 'world', 'is', 'the', 'world', 'is', 'the', 'world', 'of', 'the', 'world', '.', '</s>']
2025-05-29 09:47:26,743 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 09:47:26,743 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 09:47:26,743 - INFO - joeynmt.training - 	Hypothesis: It 's the world is the world is the world is the world of the world .
2025-05-29 09:47:26,743 - INFO - joeynmt.training - Example #2
2025-05-29 09:47:26,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 09:47:26,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 09:47:26,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'first', 'is', 'the', 'world', ',', 'the', 'world', ',', 'the', 'world', ',', 'the', 'world', ',', 'the', 'world', ',', 'the', 'world', '.', '</s>']
2025-05-29 09:47:26,744 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 09:47:26,744 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 09:47:26,744 - INFO - joeynmt.training - 	Hypothesis: The first first is the world , the world , the world , the world , the world , the world .
2025-05-29 09:47:26,744 - INFO - joeynmt.training - Example #3
2025-05-29 09:47:26,744 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 09:47:26,744 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 09:47:26,744 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'a', 'lot', 'of', 'the', 'world', 'and', 'the', 'world', 'and', 'the', 'world', '.', '</s>']
2025-05-29 09:47:26,744 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 09:47:26,744 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 09:47:26,744 - INFO - joeynmt.training - 	Hypothesis: It 's a lot of the world and the world and the world .
2025-05-29 09:47:26,744 - INFO - joeynmt.training - Example #4
2025-05-29 09:47:26,744 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 09:47:26,744 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 09:47:26,744 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'world', 'was', 'a', 'lot', 'of', 'the', 'world', 'is', 'a', 'lot', 'of', 'the', 'world', ',', '</s>']
2025-05-29 09:47:26,744 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 09:47:26,744 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 09:47:26,744 - INFO - joeynmt.training - 	Hypothesis: The world was a lot of the world is a lot of the world ,
2025-05-29 09:47:43,677 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     3.265695, Batch Acc: 0.194608, Tokens per Sec:     4130, Lr: 0.000300
2025-05-29 09:48:00,147 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     3.163677, Batch Acc: 0.202776, Tokens per Sec:     4305, Lr: 0.000300
2025-05-29 09:48:17,191 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     2.961646, Batch Acc: 0.213677, Tokens per Sec:     4159, Lr: 0.000300
2025-05-29 09:48:34,395 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     3.108689, Batch Acc: 0.224004, Tokens per Sec:     4303, Lr: 0.000300
2025-05-29 09:48:54,461 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     3.075715, Batch Acc: 0.235024, Tokens per Sec:     3536, Lr: 0.000300
2025-05-29 09:48:54,461 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 09:48:54,461 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 09:50:11,483 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.04, ppl:  20.92, acc:   0.23, generation: 77.0143[sec], evaluation: 0.0000[sec]
2025-05-29 09:50:11,486 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 09:50:11,681 - INFO - joeynmt.training - Example #0
2025-05-29 09:50:11,682 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 09:50:11,682 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 09:50:11,682 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'had', 'to', 'go', 'to', 'these', 'these', 'things', 'that', 'I', "'ve", 'got', 'to', 'be', 'to', 'be', 'the', 'same', 'thing', 'of', 'the', 'first', 'first', ',', 'which', 'is', 'the', 'most', 'of', 'the', 'first', 'first', 'first', 'of', 'the', 'first', 'first', 'of', 'the', '19@@', '7@@', '7@@', '7@@', '7@@', '7@@', '7@@', '7@@', '7@@', '5', 'percent', 'of', 'the', 'first', '.', '</s>']
2025-05-29 09:50:11,682 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 09:50:11,682 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 09:50:11,682 - INFO - joeynmt.training - 	Hypothesis: And I had to go to these these things that I 've got to be to be the same thing of the first first , which is the most of the first first first of the first first of the 19777777775 percent of the first .
2025-05-29 09:50:11,682 - INFO - joeynmt.training - Example #1
2025-05-29 09:50:11,682 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 09:50:11,682 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 09:50:11,682 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'the', 'same', 'thing', 'that', 'the', 'same', 'thing', 'is', 'the', 'same', 'thing', 'of', 'the', 'same', 'thing', 'is', 'not', 'the', 'same', 'thing', '.', '</s>']
2025-05-29 09:50:11,682 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 09:50:11,682 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 09:50:11,682 - INFO - joeynmt.training - 	Hypothesis: It 's the same thing that the same thing is the same thing of the same thing is not the same thing .
2025-05-29 09:50:11,683 - INFO - joeynmt.training - Example #2
2025-05-29 09:50:11,683 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 09:50:11,683 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 09:50:11,683 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'first', 'first', 'b@@', 'and@@', '-@@', 're@@', 're@@', 're@@', 're@@', 're@@', 'cogn@@', 'd', ',', 'the', 'same', 'thing', ',', 'the', 'same', 'thing', 'of', 'the', 'same', 'thing', '.', '</s>']
2025-05-29 09:50:11,683 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 09:50:11,683 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 09:50:11,683 - INFO - joeynmt.training - 	Hypothesis: The first first first band-rererererecognd , the same thing , the same thing of the same thing .
2025-05-29 09:50:11,683 - INFO - joeynmt.training - Example #3
2025-05-29 09:50:11,683 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 09:50:11,683 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 09:50:11,683 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'a', 'lot', 'of', 'of', 'the', 'c@@', 'es', 'and', 'you', 'go', '.', '</s>']
2025-05-29 09:50:11,683 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 09:50:11,683 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 09:50:11,683 - INFO - joeynmt.training - 	Hypothesis: It 's a lot of of the ces and you go .
2025-05-29 09:50:11,683 - INFO - joeynmt.training - Example #4
2025-05-29 09:50:11,683 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 09:50:11,683 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 09:50:11,683 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'first', 'first', 'first', 'is', 'a', 'lot', 'of', 'of', 'the', 'c@@', 'and@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', 'percent', 'of', 'years', '.', '</s>']
2025-05-29 09:50:11,683 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 09:50:11,683 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 09:50:11,683 - INFO - joeynmt.training - 	Hypothesis: The first first first first is a lot of of the cand--------percent of years .
2025-05-29 09:50:29,986 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     2.979448, Batch Acc: 0.252628, Tokens per Sec:     3861, Lr: 0.000300
2025-05-29 09:50:46,792 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     2.874117, Batch Acc: 0.262173, Tokens per Sec:     4161, Lr: 0.000300
2025-05-29 09:51:04,633 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     2.864477, Batch Acc: 0.278948, Tokens per Sec:     4041, Lr: 0.000300
2025-05-29 09:51:21,076 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     2.661526, Batch Acc: 0.286232, Tokens per Sec:     4351, Lr: 0.000300
2025-05-29 09:51:37,124 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     2.691200, Batch Acc: 0.292513, Tokens per Sec:     4405, Lr: 0.000300
2025-05-29 09:51:37,124 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 09:51:37,124 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 09:52:33,441 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.77, ppl:  15.92, acc:   0.28, generation: 56.3088[sec], evaluation: 0.0000[sec]
2025-05-29 09:52:33,442 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 09:52:33,617 - INFO - joeynmt.training - Example #0
2025-05-29 09:52:33,617 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 09:52:33,617 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 09:52:33,617 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['They', "'ve", 'got', 'these', 'wee@@', 'k', 'to', 'show', 'these', 'these', 'b@@', 'rou@@', 'ght', 'to', 'show', 'the', 's@@', 'un@@', 'un@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'ly', ',', 'for', 'three', 'years', 'ago', ',', 'for', 'the', 'United', 'States', ',', 'in', 'the', 'United', 'States', ',', 'in', 'the', 'United', 'States', '.', '</s>']
2025-05-29 09:52:33,618 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 09:52:33,618 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 09:52:33,618 - INFO - joeynmt.training - 	Hypothesis: They 've got these week to show these these brought to show the sununddddddddddddly , for three years ago , for the United States , in the United States , in the United States .
2025-05-29 09:52:33,618 - INFO - joeynmt.training - Example #1
2025-05-29 09:52:33,618 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 09:52:33,618 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 09:52:33,618 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'problem', 'is', 'this', 'this', 'is', 'not', 'the', 'world', 'is', 'not', 'the', 'problem', 'is', 'that', 'it', "'s", 'not', 'the', 'the', 'problem', '.', '</s>']
2025-05-29 09:52:33,618 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 09:52:33,618 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 09:52:33,618 - INFO - joeynmt.training - 	Hypothesis: And the problem is this this is not the world is not the problem is that it 's not the the problem .
2025-05-29 09:52:33,618 - INFO - joeynmt.training - Example #2
2025-05-29 09:52:33,618 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 09:52:33,618 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 09:52:33,618 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'The', 'The', 'f@@', 'ast@@', 'er', 'is', ',', 'in', 'a', 'lot', ',', 'in', 'a', 'lot', ',', 'the', 'r@@', 'r@@', 'ate', 'of', 'the', 'the', 're@@', 'cogn@@', 'i@@', 'i@@', 'i@@', 'i@@', 'i@@', 'st', '.', '</s>']
2025-05-29 09:52:33,618 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 09:52:33,618 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 09:52:33,618 - INFO - joeynmt.training - 	Hypothesis: The The The faster is , in a lot , in a lot , the rrate of the the recogniiiiist .
2025-05-29 09:52:33,618 - INFO - joeynmt.training - Example #3
2025-05-29 09:52:33,618 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 09:52:33,618 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 09:52:33,618 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'the', 's@@', 'and@@', '-@@', 'p@@', 'p@@', 'ac@@', 'ac@@', 'ts', '.', '</s>']
2025-05-29 09:52:33,618 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 09:52:33,618 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 09:52:33,618 - INFO - joeynmt.training - 	Hypothesis: It 's the sand-ppacacts .
2025-05-29 09:52:33,619 - INFO - joeynmt.training - Example #4
2025-05-29 09:52:33,619 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 09:52:33,619 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 09:52:33,619 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'first', 'b@@', 'rou@@', 'ght', 'is', 'a', 'little', 'bit', 'of', 'the', 'last', 'years', '.', '</s>']
2025-05-29 09:52:33,619 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 09:52:33,619 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 09:52:33,619 - INFO - joeynmt.training - 	Hypothesis: The first first brought is a little bit of the last years .
2025-05-29 09:52:52,966 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     2.524143, Batch Acc: 0.300734, Tokens per Sec:     3609, Lr: 0.000300
2025-05-29 09:53:10,813 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     2.729878, Batch Acc: 0.313274, Tokens per Sec:     4081, Lr: 0.000300
2025-05-29 09:53:28,962 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     2.623382, Batch Acc: 0.324308, Tokens per Sec:     3891, Lr: 0.000300
2025-05-29 09:53:45,691 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     2.666270, Batch Acc: 0.330556, Tokens per Sec:     4227, Lr: 0.000300
2025-05-29 09:54:04,002 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     2.658006, Batch Acc: 0.343212, Tokens per Sec:     3960, Lr: 0.000300
2025-05-29 09:54:04,003 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 09:54:04,003 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 09:55:07,978 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.57, ppl:  13.08, acc:   0.32, generation: 63.9670[sec], evaluation: 0.0000[sec]
2025-05-29 09:55:07,980 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 09:55:08,188 - INFO - joeynmt.training - Example #0
2025-05-29 09:55:08,189 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 09:55:08,189 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 09:55:08,189 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['They', "'ve", 'been', 'to', 'show', 'these', 'b@@', 'rou@@', 'ght', 'to', 'show', 'you', 'you', 'that', 'the', 'co@@', 'vered', 'that', 'the', 'co@@', 'vered', 'of', 'the', 'co@@', 'vered', ',', 'who', 'three', 'million', 'years', ',', 'for', 'three', 'million', 'years', 'has', 'been', 'the', 'last', 'last', 'last', '1@@', '8', 'of', 'the', 'United', 'States', ',', 'is', 'a', 'few', 'years', '.', '</s>']
2025-05-29 09:55:08,189 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 09:55:08,189 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 09:55:08,189 - INFO - joeynmt.training - 	Hypothesis: They 've been to show these brought to show you you that the covered that the covered of the covered , who three million years , for three million years has been the last last last 18 of the United States , is a few years .
2025-05-29 09:55:08,189 - INFO - joeynmt.training - Example #1
2025-05-29 09:55:08,189 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 09:55:08,189 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 09:55:08,189 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'then', 'it', "'s", 'this', 'very', 'important', '.', '</s>']
2025-05-29 09:55:08,189 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 09:55:08,189 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 09:55:08,189 - INFO - joeynmt.training - 	Hypothesis: And then it 's this very important .
2025-05-29 09:55:08,189 - INFO - joeynmt.training - Example #2
2025-05-29 09:55:08,189 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 09:55:08,189 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 09:55:08,189 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'second', 'is', 'a', 'lot', 'of', 'h@@', 'or@@', 'or@@', 'c', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'most', 'of', 'the', 'system', 'of', 'the', 'system', 'of', 'the', 'system', 'of', 'the', 'system', '.', '</s>']
2025-05-29 09:55:08,189 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 09:55:08,189 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 09:55:08,189 - INFO - joeynmt.training - 	Hypothesis: The second is a lot of hororc is , in a sense , the most of the system of the system of the system of the system .
2025-05-29 09:55:08,189 - INFO - joeynmt.training - Example #3
2025-05-29 09:55:08,189 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 09:55:08,189 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 09:55:08,189 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', "'re", 'going', 'to', 'be', 'a', 't@@', 'in@@', 'y', 'and', 'it', "'s", 'a', 't@@', 'ac@@', 't@@', 'able', '.', '</s>']
2025-05-29 09:55:08,190 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 09:55:08,190 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 09:55:08,190 - INFO - joeynmt.training - 	Hypothesis: You 're going to be a tiny and it 's a tactable .
2025-05-29 09:55:08,190 - INFO - joeynmt.training - Example #4
2025-05-29 09:55:08,190 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 09:55:08,190 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 09:55:08,190 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'is', 'going', 'to', 'be', 'a', 'very', 'very', 'very', 'very', 'very', 'very', 's@@', 's@@', 'and@@', 'ed', 'the', 'last', 'years', '.', '</s>']
2025-05-29 09:55:08,190 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 09:55:08,190 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 09:55:08,190 - INFO - joeynmt.training - 	Hypothesis: The next is going to be a very very very very very very ssanded the last years .
2025-05-29 09:55:24,938 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     2.682136, Batch Acc: 0.346753, Tokens per Sec:     4151, Lr: 0.000300
2025-05-29 09:55:42,385 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     2.435098, Batch Acc: 0.352947, Tokens per Sec:     3930, Lr: 0.000300
2025-05-29 09:56:00,252 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     2.270131, Batch Acc: 0.366160, Tokens per Sec:     3952, Lr: 0.000300
2025-05-29 09:56:17,140 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     2.411148, Batch Acc: 0.373069, Tokens per Sec:     4194, Lr: 0.000300
2025-05-29 09:56:34,609 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     2.198359, Batch Acc: 0.377302, Tokens per Sec:     3936, Lr: 0.000300
2025-05-29 09:56:34,610 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 09:56:34,610 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 09:57:33,294 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.41, ppl:  11.13, acc:   0.36, generation: 58.6766[sec], evaluation: 0.0000[sec]
2025-05-29 09:57:33,296 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 09:57:33,458 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/500.ckpt
2025-05-29 09:57:33,460 - INFO - joeynmt.training - Example #0
2025-05-29 09:57:33,461 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 09:57:33,461 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 09:57:33,461 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'wed', 'these', 'in@@', 'iti@@', 'onal', 'de@@', 'ath', 'to', 'show', 'that', 'the', 'bo@@', 'x', 'of', 'the', 'bo@@', 'x', 'of', 'the', 'bo@@', 'x', 'of', 'the', 'U.@@', 'S.', ',', 'which', 'for', 'three', 'million', 'years', 'has', 'been', 'a', 'few', 'years', 'of', 'the', 'U.@@', 'S.', 'S.', 'S.', 'S.', ',', 'is', 'a', 'very', 'd@@', 'ang@@', 'er', 'of', 'the', '19@@', 'th', 'of', 'the', '40', 'percent', '.', '</s>']
2025-05-29 09:57:33,461 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 09:57:33,461 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 09:57:33,461 - INFO - joeynmt.training - 	Hypothesis: The year I showed these initional death to show that the box of the box of the box of the U.S. , which for three million years has been a few years of the U.S. S. S. S. , is a very danger of the 19th of the 40 percent .
2025-05-29 09:57:33,461 - INFO - joeynmt.training - Example #1
2025-05-29 09:57:33,461 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 09:57:33,461 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 09:57:33,461 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'o', 'this', 'is', 'the', 's@@', 's@@', 's@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'do', 'it', 'in', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 09:57:33,461 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 09:57:33,461 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 09:57:33,461 - INFO - joeynmt.training - 	Hypothesis: To this is the sssavity of the problem because it doesn 't do it in the ice of the ice .
2025-05-29 09:57:33,461 - INFO - joeynmt.training - Example #2
2025-05-29 09:57:33,461 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 09:57:33,461 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 09:57:33,461 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'l@@', 'and@@', '-@@', 'r@@', 'r@@', 'r@@', 'ent', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cu@@', 'st@@', 'or', ',', 'the', 'res@@', 't', 'of', 'the', 'human', 'human', 'system', '.', '</s>']
2025-05-29 09:57:33,461 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 09:57:33,461 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 09:57:33,461 - INFO - joeynmt.training - 	Hypothesis: The land-rrrent is , in a sense , the custor , the rest of the human human system .
2025-05-29 09:57:33,461 - INFO - joeynmt.training - Example #3
2025-05-29 09:57:33,462 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 09:57:33,462 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 09:57:33,462 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'a', 'b@@', 'ut@@', 'h', 'of', 'the', 'in@@', 'spi@@', 'r@@', 'ing', '.', '</s>']
2025-05-29 09:57:33,462 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 09:57:33,462 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 09:57:33,462 - INFO - joeynmt.training - 	Hypothesis: It 's a buth of the inspiring .
2025-05-29 09:57:33,462 - INFO - joeynmt.training - Example #4
2025-05-29 09:57:33,462 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 09:57:33,462 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 09:57:33,462 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'is', 'going', 'to', 'be', 'a', 'very', 'very', 'quick@@', 'ly', ',', 'the', 's@@', 's@@', 'our@@', 'ney', ',', '</s>']
2025-05-29 09:57:33,462 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 09:57:33,462 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 09:57:33,462 - INFO - joeynmt.training - 	Hypothesis: The next next is going to be a very very quickly , the ssourney ,
2025-05-29 09:57:49,961 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     2.257218, Batch Acc: 0.388391, Tokens per Sec:     4184, Lr: 0.000300
2025-05-29 09:58:05,924 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     2.377539, Batch Acc: 0.389920, Tokens per Sec:     4426, Lr: 0.000300
2025-05-29 09:58:22,303 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     2.469514, Batch Acc: 0.402297, Tokens per Sec:     4354, Lr: 0.000300
2025-05-29 09:58:39,804 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     2.088691, Batch Acc: 0.409981, Tokens per Sec:     4089, Lr: 0.000300
2025-05-29 09:58:58,076 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     2.240430, Batch Acc: 0.410443, Tokens per Sec:     3927, Lr: 0.000300
2025-05-29 09:58:58,077 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 09:58:58,077 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 09:59:47,115 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.28, ppl:   9.78, acc:   0.40, generation: 49.0313[sec], evaluation: 0.0000[sec]
2025-05-29 09:59:47,117 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 09:59:47,315 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/1000.ckpt
2025-05-29 09:59:47,318 - INFO - joeynmt.training - Example #0
2025-05-29 09:59:47,319 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 09:59:47,319 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 09:59:47,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['They', "'ve", 'got', 'to', 'show', 'these', 'two', 'de@@', 'mic', 'de@@', 'mic', ',', 'to', 'show', 'that', 'the', 'me@@', 'et', 'of', 'the', 'U.@@', 'S.', ',', ',', 'who', "'s", 'almost', 'three', 'years', 'of', 'years', 'has', 'been', 'very', 'very', 'very', ',', 'the', 'people', 'had', 'the', 'contin@@', 'ent@@', 'al', 'in', 'the', 'contin@@', 'ue', ',', 'is', 're@@', 'cent@@', 'ly', '.', '</s>']
2025-05-29 09:59:47,319 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 09:59:47,319 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 09:59:47,319 - INFO - joeynmt.training - 	Hypothesis: They 've got to show these two demic demic , to show that the meet of the U.S. , , who 's almost three years of years has been very very very , the people had the continental in the continue , is recently .
2025-05-29 09:59:47,319 - INFO - joeynmt.training - Example #1
2025-05-29 09:59:47,319 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 09:59:47,319 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 09:59:47,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'o@@', 'ok', 'this', 'is', 'a', 'gr@@', 'av@@', 'ity', 'of', 'the', 'h@@', 'or@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'have', 'to', 'be', 'a', 'real', 'real', '.', '</s>']
2025-05-29 09:59:47,319 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 09:59:47,319 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 09:59:47,319 - INFO - joeynmt.training - 	Hypothesis: Took this is a gravity of the hority of the problem because it doesn 't have to be a real real .
2025-05-29 09:59:47,319 - INFO - joeynmt.training - Example #2
2025-05-29 09:59:47,319 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 09:59:47,319 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 09:59:47,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'l@@', 'and@@', 'sc@@', 'am@@', 'am@@', 'ong', ',', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'most', 'of', 'the', 'cli@@', 'mate', 'change', '.', '</s>']
2025-05-29 09:59:47,319 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 09:59:47,319 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 09:59:47,319 - INFO - joeynmt.training - 	Hypothesis: The landscamamong , is , in a sense , the most of the climate change .
2025-05-29 09:59:47,319 - INFO - joeynmt.training - Example #3
2025-05-29 09:59:47,319 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 09:59:47,319 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 09:59:47,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', "'re", 'going', 'to', 'be', 'a', 'ver@@', 'al', ',', 'and', 'you', "'re", 'r@@', 'iti@@', 'z@@', 'ens', '.', '</s>']
2025-05-29 09:59:47,320 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 09:59:47,320 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 09:59:47,320 - INFO - joeynmt.training - 	Hypothesis: You 're going to be a veral , and you 're ritizens .
2025-05-29 09:59:47,320 - INFO - joeynmt.training - Example #4
2025-05-29 09:59:47,320 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 09:59:47,320 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 09:59:47,320 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'di@@', 'an', 'ap@@', 'preci@@', 'ous', 'car@@', 'e@@', '-@@', 'to@@', '-@@', 'to@@', '-@@', 'to@@', '-@@', 'old', 'old', 'old', 'old', 'old', 'old', 'old', 'years', '.', '</s>']
2025-05-29 09:59:47,320 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 09:59:47,320 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 09:59:47,320 - INFO - joeynmt.training - 	Hypothesis: The next dian apprecious care-to-to-to-old old old old old old old years .
2025-05-29 10:00:03,397 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     2.258425, Batch Acc: 0.414337, Tokens per Sec:     4387, Lr: 0.000300
2025-05-29 10:00:19,910 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     2.012819, Batch Acc: 0.421726, Tokens per Sec:     4354, Lr: 0.000300
2025-05-29 10:00:36,496 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     2.046675, Batch Acc: 0.428110, Tokens per Sec:     4237, Lr: 0.000300
2025-05-29 10:00:53,106 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     2.145899, Batch Acc: 0.436094, Tokens per Sec:     4241, Lr: 0.000300
2025-05-29 10:01:09,823 - INFO - joeynmt.training - Epoch   1, Step:     4000, Batch Loss:     2.152146, Batch Acc: 0.438587, Tokens per Sec:     4320, Lr: 0.000300
2025-05-29 10:01:09,824 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:01:09,824 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:01:58,736 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.18, ppl:   8.81, acc:   0.42, generation: 48.9065[sec], evaluation: 0.0000[sec]
2025-05-29 10:01:58,739 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:01:58,881 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/1500.ckpt
2025-05-29 10:01:58,883 - INFO - joeynmt.training - Example #0
2025-05-29 10:01:58,883 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:01:58,883 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:01:58,883 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['They', "'ve", 'been', 'sho@@', 'wed', 'these', 'di@@', 'ed', 'to', 'show', 'that', 'the', 'c@@', 'ell', 'of', 'the', 'd@@', 'am@@', 'am@@', 'age', 'of', 'the', 'gl@@', 'aci@@', 'al', ',', 'which', 'for', 'three', 'million', 'years', 'has', 'been', 'the', 'contin@@', 'ue', 'of', '4@@', '8', 'percent', 'of', 'the', 'U.@@', 'S.', 'S.', 'S.', 'S.', 'S.', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 10:01:58,883 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:01:58,883 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:01:58,883 - INFO - joeynmt.training - 	Hypothesis: They 've been showed these died to show that the cell of the damamage of the glacial , which for three million years has been the continue of 48 percent of the U.S. S. S. S. S. continental .
2025-05-29 10:01:58,883 - INFO - joeynmt.training - Example #1
2025-05-29 10:01:58,883 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:01:58,883 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:01:58,883 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'it', "'s", 'this', 'pro@@', 'vi@@', 'vi@@', 'de', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'not', 'the', 'sp@@', 'ess@@', 'ing', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:01:58,883 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:01:58,883 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:01:58,883 - INFO - joeynmt.training - 	Hypothesis: And it 's this provivide the gravity of the problem because not the spessing of the ice .
2025-05-29 10:01:58,883 - INFO - joeynmt.training - Example #2
2025-05-29 10:01:58,883 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:01:58,883 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:01:58,883 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'c@@', 'ell', 'gl@@', 'aci@@', 'al', 'ar@@', 't@@', 'ical', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:01:58,883 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:01:58,883 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:01:58,883 - INFO - joeynmt.training - 	Hypothesis: The cell glacial artical is , in a sense , the heart of the climate system .
2025-05-29 10:01:58,884 - INFO - joeynmt.training - Example #3
2025-05-29 10:01:58,884 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:01:58,884 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:01:58,884 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', "'re", 'going', 'to', 'be', 'a', 'lot', 'of', 'in@@', 'ver@@', 's', '.', '</s>']
2025-05-29 10:01:58,884 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:01:58,884 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:01:58,884 - INFO - joeynmt.training - 	Hypothesis: You 're going to be a lot of invers .
2025-05-29 10:01:58,884 - INFO - joeynmt.training - Example #4
2025-05-29 10:01:58,884 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:01:58,884 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:01:58,884 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'di@@', 'a@@', 've', 'will', 'be', 'a', 'very', 'very', 'quick@@', 'ly', ',', 'the', 'next', 'year', '.', '</s>']
2025-05-29 10:01:58,884 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:01:58,884 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:01:58,884 - INFO - joeynmt.training - 	Hypothesis: The next diave will be a very very quickly , the next year .
2025-05-29 10:02:12,768 - INFO - joeynmt.training - Epoch   1: total training loss 11448.13
2025-05-29 10:02:12,768 - INFO - joeynmt.training - EPOCH 2
2025-05-29 10:02:15,274 - INFO - joeynmt.training - Epoch   2, Step:     4100, Batch Loss:     2.092298, Batch Acc: 0.455674, Tokens per Sec:     3954, Lr: 0.000300
2025-05-29 10:02:32,226 - INFO - joeynmt.training - Epoch   2, Step:     4200, Batch Loss:     2.114377, Batch Acc: 0.456249, Tokens per Sec:     4237, Lr: 0.000300
2025-05-29 10:02:49,410 - INFO - joeynmt.training - Epoch   2, Step:     4300, Batch Loss:     2.166569, Batch Acc: 0.460610, Tokens per Sec:     4182, Lr: 0.000300
2025-05-29 10:03:07,115 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:     2.234216, Batch Acc: 0.461936, Tokens per Sec:     4072, Lr: 0.000300
2025-05-29 10:03:24,317 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     1.998759, Batch Acc: 0.458572, Tokens per Sec:     4108, Lr: 0.000300
2025-05-29 10:03:24,318 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:03:24,318 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:04:08,349 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.12, ppl:   8.35, acc:   0.43, generation: 44.0237[sec], evaluation: 0.0000[sec]
2025-05-29 10:04:08,352 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:04:08,538 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/2000.ckpt
2025-05-29 10:04:08,541 - INFO - joeynmt.training - Example #0
2025-05-29 10:04:08,542 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:04:08,542 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:04:08,542 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['They', "'ve", 'been', 'sho@@', 'wed', 'these', 'di@@', 'am@@', 'age', 'to', 'show', 'that', 'the', 'c@@', 'ell', 'of', 'the', 'c@@', 'y@@', 'y@@', 'y@@', 'nam@@', 'ics', ',', 'which', 'for', 'three', 'million', 'years', ',', 'which', 'for', 'almost', 'three', 'million', 'years', ',', 'they', 'had', 'the', 'world', ',', 'which', 'is', 're@@', 'mo@@', 'ved', 'in', 'the', 'United', 'States', '.', '</s>']
2025-05-29 10:04:08,542 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:04:08,542 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:04:08,542 - INFO - joeynmt.training - 	Hypothesis: They 've been showed these diamage to show that the cell of the cyyynamics , which for three million years , which for almost three million years , they had the world , which is removed in the United States .
2025-05-29 10:04:08,542 - INFO - joeynmt.training - Example #1
2025-05-29 10:04:08,542 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:04:08,542 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:04:08,542 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'in', 'fact', ',', 'this', 'is', 'a', 'lot', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'have', 'the', 'sp@@', 'ent', 'of', 'ice', '.', '</s>']
2025-05-29 10:04:08,542 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:04:08,542 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:04:08,542 - INFO - joeynmt.training - 	Hypothesis: But in fact , this is a lot of the problem because it doesn 't have the spent of ice .
2025-05-29 10:04:08,542 - INFO - joeynmt.training - Example #2
2025-05-29 10:04:08,542 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:04:08,542 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:04:08,542 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'co@@', 'ver', 'of', 'the', 'bo@@', 'tto@@', 'm', 'of', 'the', 'cli@@', 'mate', ',', 'in', 'a', 'sense', ',', 'the', 'cu@@', 'cu@@', 'cu@@', 'ri@@', 'ous', 'system', '.', '</s>']
2025-05-29 10:04:08,542 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:04:08,542 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:04:08,542 - INFO - joeynmt.training - 	Hypothesis: The cover of the bottom of the climate , in a sense , the cucucurious system .
2025-05-29 10:04:08,543 - INFO - joeynmt.training - Example #3
2025-05-29 10:04:08,543 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:04:08,543 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:04:08,543 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'know', ',', 'you', 'know', ',', 'and', 'you', "'re", 'going', 'to', 'be', 'able', '.', '</s>']
2025-05-29 10:04:08,543 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:04:08,543 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:04:08,543 - INFO - joeynmt.training - 	Hypothesis: You know , you know , and you 're going to be able .
2025-05-29 10:04:08,543 - INFO - joeynmt.training - Example #4
2025-05-29 10:04:08,543 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:04:08,543 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:04:08,543 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'di@@', 'a@@', 'positi@@', 've', 'will', 'be', 'a', 'very', 'quick@@', 'ly', ',', 'the', 'next', 'di@@', 'ents', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:04:08,543 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:04:08,543 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:04:08,543 - INFO - joeynmt.training - 	Hypothesis: The next diapositive will be a very quickly , the next dients of the last 25 years .
2025-05-29 10:04:27,916 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     2.116019, Batch Acc: 0.465198, Tokens per Sec:     3686, Lr: 0.000300
2025-05-29 10:04:45,851 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     1.969920, Batch Acc: 0.466013, Tokens per Sec:     3921, Lr: 0.000300
2025-05-29 10:05:02,195 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     1.956679, Batch Acc: 0.465714, Tokens per Sec:     4343, Lr: 0.000300
2025-05-29 10:05:19,200 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     1.781330, Batch Acc: 0.470673, Tokens per Sec:     4227, Lr: 0.000300
2025-05-29 10:05:36,185 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     1.848245, Batch Acc: 0.470980, Tokens per Sec:     4102, Lr: 0.000300
2025-05-29 10:05:36,186 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:05:36,186 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:06:26,646 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.07, ppl:   7.89, acc:   0.45, generation: 50.4532[sec], evaluation: 0.0000[sec]
2025-05-29 10:06:26,649 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:06:26,818 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/2500.ckpt
2025-05-29 10:06:26,823 - INFO - joeynmt.training - Example #0
2025-05-29 10:06:26,823 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:06:26,823 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:06:26,823 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'wed', 'this', 'di@@', 'am@@', 'am@@', 'p', 'to', 'show', 'that', 'the', 'c@@', 'ut@@', 'h', 'of', 'the', 'gl@@', 'aci@@', 'al', 'me@@', 'ant', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'has', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'of', 'the', 'United', 'States', ',', 'is', 're@@', 'stre@@', 'et', 'of', 'the', 'United', 'States', ',', 'is', 're@@', 'stre@@', 'et', 'of', 'the', '40', 'percent', '.', '</s>']
2025-05-29 10:06:26,824 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:06:26,824 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:06:26,824 - INFO - joeynmt.training - 	Hypothesis: The year I showed this diamamp to show that the cuth of the glacial meant , which for almost three million years has had the size of the 48 of the United States , is restreet of the United States , is restreet of the 40 percent .
2025-05-29 10:06:26,824 - INFO - joeynmt.training - Example #1
2025-05-29 10:06:26,824 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:06:26,824 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:06:26,824 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'so', 'I', 'was', 'going', 'to', 'be', 'a', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'have', 'the', 'sp@@', 'end@@', 'ing', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:06:26,824 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:06:26,824 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:06:26,824 - INFO - joeynmt.training - 	Hypothesis: And so I was going to be a gravity of the problem because it doesn 't have the spending of the ice .
2025-05-29 10:06:26,824 - INFO - joeynmt.training - Example #2
2025-05-29 10:06:26,824 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:06:26,824 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:06:26,824 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'gl@@', 'aci@@', 'al', 'ar@@', 't@@', 'ics', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'most', 'of', 'the', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:06:26,824 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:06:26,824 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:06:26,824 - INFO - joeynmt.training - 	Hypothesis: The glacial glacial artics is , in a sense , the heart of the most of the climate system .
2025-05-29 10:06:26,824 - INFO - joeynmt.training - Example #3
2025-05-29 10:06:26,824 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:06:26,824 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:06:26,824 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'have', 'to', 'be', 'in@@', 'ver@@', 's', 'and', 'you', "'re", 's@@', 'iti@@', 'z@@', 'en', '.', '</s>']
2025-05-29 10:06:26,824 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:06:26,825 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:06:26,825 - INFO - joeynmt.training - 	Hypothesis: You have to be invers and you 're sitizen .
2025-05-29 10:06:26,825 - INFO - joeynmt.training - Example #4
2025-05-29 10:06:26,825 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:06:26,825 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:06:26,825 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'di@@', 'a@@', 'stic', 'next', 'di@@', 'ed', 'to', 'be', 'a', 'f@@', 'ast@@', '-@@', 'year@@', '-@@', 'old', 'old', 'old', 'old', 'old', '.', '</s>']
2025-05-29 10:06:26,825 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:06:26,825 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:06:26,825 - INFO - joeynmt.training - 	Hypothesis: The next next diastic next died to be a fast-year-old old old old old .
2025-05-29 10:06:43,840 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     2.075268, Batch Acc: 0.474122, Tokens per Sec:     4070, Lr: 0.000300
2025-05-29 10:07:00,245 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     1.785817, Batch Acc: 0.479959, Tokens per Sec:     4284, Lr: 0.000300
2025-05-29 10:07:16,225 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     1.917871, Batch Acc: 0.480218, Tokens per Sec:     4442, Lr: 0.000300
2025-05-29 10:07:32,550 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     2.025425, Batch Acc: 0.483936, Tokens per Sec:     4338, Lr: 0.000300
2025-05-29 10:07:48,745 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     1.797615, Batch Acc: 0.482840, Tokens per Sec:     4383, Lr: 0.000300
2025-05-29 10:07:48,745 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:07:48,746 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:08:29,892 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.02, ppl:   7.57, acc:   0.46, generation: 41.1398[sec], evaluation: 0.0000[sec]
2025-05-29 10:08:29,894 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:08:30,053 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/3000.ckpt
2025-05-29 10:08:30,056 - INFO - joeynmt.training - Example #0
2025-05-29 10:08:30,056 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:08:30,056 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:08:30,056 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'year', 'I', 'sho@@', 'wed', 'these', 'de@@', 'mon@@', 'str@@', 'ing', 'de@@', 'mon@@', 'str@@', 'ing', 'that', 'the', 'c@@', 'lu@@', 'b', 'co@@', 'ld', '.', 'And', 'for', 'almost', 'three', 'million', 'years', 'of', 'the', 'United', 'States', ',', 'who', 'had', 'the', 'size', 'of', 'the', 'United', 'States', ',', 'is', 're@@', 'stre@@', 'et', 'of', 'the', 'United', 'States', '.', '</s>']
2025-05-29 10:08:30,056 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:08:30,056 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:08:30,056 - INFO - joeynmt.training - 	Hypothesis: The year year I showed these demonstring demonstring that the club cold . And for almost three million years of the United States , who had the size of the United States , is restreet of the United States .
2025-05-29 10:08:30,056 - INFO - joeynmt.training - Example #1
2025-05-29 10:08:30,056 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:08:30,056 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:08:30,056 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', "'s", 'a', 'lot', 'of', 'the', 'problem', 'of', 'the', 'problem', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'have', 'the', 'ice', 'of', 'ice', '.', '</s>']
2025-05-29 10:08:30,056 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:08:30,056 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:08:30,056 - INFO - joeynmt.training - 	Hypothesis: But it 's a lot of the problem of the problem of the problem because it doesn 't have the ice of ice .
2025-05-29 10:08:30,056 - INFO - joeynmt.training - Example #2
2025-05-29 10:08:30,056 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:08:30,056 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:08:30,056 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'gl@@', 'aci@@', 'al', 'ar@@', 't@@', 'ical', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:08:30,057 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:08:30,057 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:08:30,057 - INFO - joeynmt.training - 	Hypothesis: The glacial glacial artical is , in a sense , the heart of the climate system .
2025-05-29 10:08:30,057 - INFO - joeynmt.training - Example #3
2025-05-29 10:08:30,057 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:08:30,057 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:08:30,057 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'a', 'w@@', 'in@@', 'ver@@', 's', ',', 'and', 'you', 'r@@', 'iti@@', 'z@@', 'en', '.', '</s>']
2025-05-29 10:08:30,057 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:08:30,057 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:08:30,057 - INFO - joeynmt.training - 	Hypothesis: It 's a winvers , and you ritizen .
2025-05-29 10:08:30,057 - INFO - joeynmt.training - Example #4
2025-05-29 10:08:30,057 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:08:30,057 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:08:30,057 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'di@@', 'a@@', 'positi@@', 've', 'will', 'be', 'a', 'f@@', 'ast@@', 'oni@@', 'sh@@', 'ing', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:08:30,057 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:08:30,057 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:08:30,057 - INFO - joeynmt.training - 	Hypothesis: The next next diapositive will be a fastonishing the last 25 years .
2025-05-29 10:08:46,605 - INFO - joeynmt.training - Epoch   2, Step:     5600, Batch Loss:     2.040073, Batch Acc: 0.478642, Tokens per Sec:     4285, Lr: 0.000300
2025-05-29 10:09:02,896 - INFO - joeynmt.training - Epoch   2, Step:     5700, Batch Loss:     1.758366, Batch Acc: 0.489333, Tokens per Sec:     4446, Lr: 0.000300
2025-05-29 10:09:19,541 - INFO - joeynmt.training - Epoch   2, Step:     5800, Batch Loss:     1.909742, Batch Acc: 0.491384, Tokens per Sec:     4410, Lr: 0.000300
2025-05-29 10:09:37,869 - INFO - joeynmt.training - Epoch   2, Step:     5900, Batch Loss:     1.762462, Batch Acc: 0.491727, Tokens per Sec:     3852, Lr: 0.000300
2025-05-29 10:09:55,306 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     1.863155, Batch Acc: 0.486309, Tokens per Sec:     4045, Lr: 0.000300
2025-05-29 10:09:55,307 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:09:55,307 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:10:35,986 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.98, ppl:   7.28, acc:   0.47, generation: 40.6728[sec], evaluation: 0.0000[sec]
2025-05-29 10:10:35,989 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:10:36,124 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/3500.ckpt
2025-05-29 10:10:36,127 - INFO - joeynmt.training - Example #0
2025-05-29 10:10:36,127 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:10:36,127 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:10:36,127 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'year', 'I', 'sho@@', 'wn', 'these', 'de@@', 'al', ',', 'the', 'c@@', 'y@@', 'aci@@', 'al', 'di@@', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ant', 'of', 'the', 'hy@@', 'th@@', 'th@@', 'th@@', 'th@@', 'et@@', 'ic', 'of', 'the', 'U.@@', 'S.', '1@@', '8', 'of', 'the', 'United', 'States', ',', 'which', 'is', 're@@', 'stre@@', 'et', 'of', 'the', 'U.@@', 'S.', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 10:10:36,127 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:10:36,127 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:10:36,127 - INFO - joeynmt.training - 	Hypothesis: The year year I shown these deal , the cyacial dishow that the calculant of the hyththththetic of the U.S. 18 of the United States , which is restreet of the U.S. continental .
2025-05-29 10:10:36,127 - INFO - joeynmt.training - Example #1
2025-05-29 10:10:36,127 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:10:36,127 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:10:36,127 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', "'s", 'a', 'dre@@', 'am', 'of', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', ',', 'because', 'it', 'doesn', "'t", 'show', 'it', 'into', 'the', 'ice', '.', '</s>']
2025-05-29 10:10:36,127 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:10:36,127 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:10:36,127 - INFO - joeynmt.training - 	Hypothesis: But it 's a dream of the gravity of the problem , because it doesn 't show it into the ice .
2025-05-29 10:10:36,127 - INFO - joeynmt.training - Example #2
2025-05-29 10:10:36,127 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:10:36,127 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:10:36,127 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'c@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'al', 'me@@', 'chan@@', 'ics', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:10:36,128 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:10:36,128 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:10:36,128 - INFO - joeynmt.training - 	Hypothesis: The cotta glacial mechanics is , in a sense , the heart of the climate system .
2025-05-29 10:10:36,128 - INFO - joeynmt.training - Example #3
2025-05-29 10:10:36,128 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:10:36,128 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:10:36,128 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'know', ',', 'you', 'know', ',', 'you', 'know', ',', 'you', 'know', ',', '</s>']
2025-05-29 10:10:36,128 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:10:36,128 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:10:36,128 - INFO - joeynmt.training - 	Hypothesis: You know , you know , you know , you know ,
2025-05-29 10:10:36,128 - INFO - joeynmt.training - Example #4
2025-05-29 10:10:36,128 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:10:36,128 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:10:36,128 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'di@@', 'a@@', 'v@@', 'est', 'will', 'be', 'a', 'f@@', 'ast@@', '-@@', 'car@@', 'rel@@', 'ated', 'car@@', 'rel@@', 'ated', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:10:36,128 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:10:36,128 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:10:36,128 - INFO - joeynmt.training - 	Hypothesis: The next next diavest will be a fast-carrelated carrelated to the last 25 years .
2025-05-29 10:10:52,787 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     1.848035, Batch Acc: 0.495249, Tokens per Sec:     4228, Lr: 0.000300
2025-05-29 10:11:09,911 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     1.755057, Batch Acc: 0.498906, Tokens per Sec:     4137, Lr: 0.000300
2025-05-29 10:11:27,247 - INFO - joeynmt.training - Epoch   2, Step:     6300, Batch Loss:     1.957434, Batch Acc: 0.494843, Tokens per Sec:     4128, Lr: 0.000300
2025-05-29 10:11:44,675 - INFO - joeynmt.training - Epoch   2, Step:     6400, Batch Loss:     1.663200, Batch Acc: 0.495888, Tokens per Sec:     4152, Lr: 0.000300
2025-05-29 10:12:01,702 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     1.933040, Batch Acc: 0.499798, Tokens per Sec:     4216, Lr: 0.000300
2025-05-29 10:12:01,703 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:12:01,703 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:12:43,556 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.95, ppl:   7.00, acc:   0.47, generation: 41.8460[sec], evaluation: 0.0000[sec]
2025-05-29 10:12:43,559 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:12:43,713 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/4000.ckpt
2025-05-29 10:12:43,715 - INFO - joeynmt.training - Example #0
2025-05-29 10:12:43,715 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:12:43,715 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:12:43,715 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'year', 'I', 'sho@@', 'wed', 'these', 'de@@', 'ath', 'de@@', 'ath', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'al', 'c@@', 'alc@@', 'ul@@', 'ar@@', 't@@', 'ical', 'ar@@', 't@@', 'ical', 'ar@@', 't@@', 'ical', 'ar@@', 't@@', 'ical', ',', 'which', 'is', 'three', 'million', 'years', ',', 'the', 'contin@@', 'ent@@', 'al', 'in', 'the', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 10:12:43,716 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:12:43,716 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:12:43,716 - INFO - joeynmt.training - 	Hypothesis: The year year I showed these death death to show that the calculal calculartical artical artical artical , which is three million years , the continental in the continental continental .
2025-05-29 10:12:43,716 - INFO - joeynmt.training - Example #1
2025-05-29 10:12:43,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:12:43,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:12:43,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', "'s", 'a', 'sub@@', 'val@@', 'ue', 'of', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'I', 'don', "'t", 'show', 'it', "'s", 'the', 'ice', '.', '</s>']
2025-05-29 10:12:43,716 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:12:43,716 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:12:43,716 - INFO - joeynmt.training - 	Hypothesis: But it 's a subvalue of the gravity of the problem because I don 't show it 's the ice .
2025-05-29 10:12:43,716 - INFO - joeynmt.training - Example #2
2025-05-29 10:12:43,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:12:43,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:12:43,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'c@@', 'alc@@', 'ul@@', 'ar@@', 't@@', 'ical', ',', 'is', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:12:43,716 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:12:43,716 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:12:43,716 - INFO - joeynmt.training - 	Hypothesis: The glacial calculartical , is a sense , the heart of the global climate system .
2025-05-29 10:12:43,716 - INFO - joeynmt.training - Example #3
2025-05-29 10:12:43,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:12:43,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:12:43,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'know', ',', 'you', 'can', 'in@@', 'ver@@', 'se', 'and', 'you', 'r@@', 'iti@@', 'z@@', 'en', '.', '</s>']
2025-05-29 10:12:43,717 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:12:43,717 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:12:43,717 - INFO - joeynmt.training - 	Hypothesis: You know , you can inverse and you ritizen .
2025-05-29 10:12:43,717 - INFO - joeynmt.training - Example #4
2025-05-29 10:12:43,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:12:43,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:12:43,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'di@@', 'a@@', 'positi@@', 've', 'is', 'going', 'to', 'car@@', 'rel@@', 'ated', 'a', 's@@', 'our@@', 'ce', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:12:43,717 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:12:43,717 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:12:43,717 - INFO - joeynmt.training - 	Hypothesis: The next next diapositive is going to carrelated a source of the last 25 years .
2025-05-29 10:13:02,363 - INFO - joeynmt.training - Epoch   2, Step:     6600, Batch Loss:     1.706221, Batch Acc: 0.503367, Tokens per Sec:     3751, Lr: 0.000300
2025-05-29 10:13:20,916 - INFO - joeynmt.training - Epoch   2, Step:     6700, Batch Loss:     1.941592, Batch Acc: 0.500355, Tokens per Sec:     3874, Lr: 0.000300
2025-05-29 10:13:38,463 - INFO - joeynmt.training - Epoch   2, Step:     6800, Batch Loss:     1.770316, Batch Acc: 0.501417, Tokens per Sec:     4122, Lr: 0.000300
2025-05-29 10:13:57,251 - INFO - joeynmt.training - Epoch   2, Step:     6900, Batch Loss:     1.767682, Batch Acc: 0.499334, Tokens per Sec:     3834, Lr: 0.000300
2025-05-29 10:14:15,767 - INFO - joeynmt.training - Epoch   2, Step:     7000, Batch Loss:     1.735373, Batch Acc: 0.503684, Tokens per Sec:     3789, Lr: 0.000300
2025-05-29 10:14:15,768 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:14:15,768 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:14:59,408 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.84, acc:   0.48, generation: 43.6325[sec], evaluation: 0.0000[sec]
2025-05-29 10:14:59,410 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:14:59,598 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/4500.ckpt
2025-05-29 10:14:59,601 - INFO - joeynmt.training - Example #0
2025-05-29 10:14:59,601 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:14:59,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:14:59,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'wed', 'these', 'de@@', 'ath', 'de@@', 'mon@@', 'th', 'that', 'the', 'ho@@', 't', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'ta', '.', 'And', 'that', "'s", 'gl@@', 'aci@@', 'al', 'ex@@', 'pen@@', 'sive', ',', 'that', "'s", 'about', '4@@', '8', 'million', 'years', ',', 'the', 'U.@@', 'S.', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 10:14:59,602 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:14:59,602 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:14:59,602 - INFO - joeynmt.training - 	Hypothesis: The year I showed these death demonth that the hot glacial calotta . And that 's glacial expensive , that 's about 48 million years , the U.S. continental .
2025-05-29 10:14:59,602 - INFO - joeynmt.training - Example #1
2025-05-29 10:14:59,602 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:14:59,602 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:14:59,602 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'a', 'sub@@', 'm@@', 'it', 'for', 'the', 'problem', 'is', 'because', 'it', 'doesn', "'t", 'show', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'ice', 'of', 'ice', '.', '</s>']
2025-05-29 10:14:59,602 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:14:59,602 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:14:59,602 - INFO - joeynmt.training - 	Hypothesis: It 's a submit for the problem is because it doesn 't show the problem because it doesn 't show the ice of ice .
2025-05-29 10:14:59,602 - INFO - joeynmt.training - Example #2
2025-05-29 10:14:59,602 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:14:59,602 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:14:59,602 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'gl@@', 'aci@@', 'al', 'ar@@', 't@@', 'ical', ',', 'is', 'in', 'a', 'sense', ',', 'the', 'heart', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:14:59,602 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:14:59,602 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:14:59,602 - INFO - joeynmt.training - 	Hypothesis: The glacial glacial artical , is in a sense , the heart heart of the global climate system .
2025-05-29 10:14:59,602 - INFO - joeynmt.training - Example #3
2025-05-29 10:14:59,602 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:14:59,602 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:14:59,602 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'can', 'be', 'in@@', 'ver@@', 'no', 'in@@', 'ver@@', 's', 'and', 'the', 'w@@', 'il@@', 'ling', '.', '</s>']
2025-05-29 10:14:59,602 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:14:59,602 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:14:59,602 - INFO - joeynmt.training - 	Hypothesis: You can be inverno invers and the willing .
2025-05-29 10:14:59,602 - INFO - joeynmt.training - Example #4
2025-05-29 10:14:59,603 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:14:59,603 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:14:59,603 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'di@@', 'a@@', 'positi@@', 've', 'is', 'going', 'to', 'be', 'a', 'f@@', 'ast@@', 'oni@@', 'sh@@', 'ing', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:14:59,603 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:14:59,603 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:14:59,603 - INFO - joeynmt.training - 	Hypothesis: The next diapositive is going to be a fastonishing the last 25 years .
2025-05-29 10:15:16,856 - INFO - joeynmt.training - Epoch   2, Step:     7100, Batch Loss:     1.483920, Batch Acc: 0.506567, Tokens per Sec:     4189, Lr: 0.000300
2025-05-29 10:15:33,696 - INFO - joeynmt.training - Epoch   2, Step:     7200, Batch Loss:     1.760247, Batch Acc: 0.512145, Tokens per Sec:     4337, Lr: 0.000300
2025-05-29 10:15:50,677 - INFO - joeynmt.training - Epoch   2, Step:     7300, Batch Loss:     1.794531, Batch Acc: 0.509836, Tokens per Sec:     4069, Lr: 0.000300
2025-05-29 10:16:07,106 - INFO - joeynmt.training - Epoch   2, Step:     7400, Batch Loss:     1.702365, Batch Acc: 0.503455, Tokens per Sec:     4299, Lr: 0.000300
2025-05-29 10:16:24,348 - INFO - joeynmt.training - Epoch   2, Step:     7500, Batch Loss:     1.914245, Batch Acc: 0.509517, Tokens per Sec:     4102, Lr: 0.000300
2025-05-29 10:16:24,348 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:16:24,348 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:17:06,469 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.65, acc:   0.49, generation: 42.1140[sec], evaluation: 0.0000[sec]
2025-05-29 10:17:06,472 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:17:06,655 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/5000.ckpt
2025-05-29 10:17:06,659 - INFO - joeynmt.training - Example #0
2025-05-29 10:17:06,659 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:17:06,659 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:17:06,659 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'de', 'de@@', 'ath', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'al', 'c@@', 'alc@@', 'ul@@', 'ar@@', 't@@', 'ics', ',', 'that', "'s", 'almost', 'three', 'million', 'years', ',', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'U.@@', 'S.', 'contin@@', 'ent@@', 'al', ',', 'is', 'a', '40', 'percent', '.', '</s>']
2025-05-29 10:17:06,659 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:17:06,660 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:17:06,660 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slide death that the glacial calotta glacial calculartics , that 's almost three million years , the size of 48 , the U.S. continental , is a 40 percent .
2025-05-29 10:17:06,660 - INFO - joeynmt.training - Example #1
2025-05-29 10:17:06,660 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:17:06,660 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:17:06,660 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', "'s", 'a', 'sub@@', 'val@@', 'ue', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:17:06,660 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:17:06,660 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:17:06,660 - INFO - joeynmt.training - 	Hypothesis: But it 's a subvalue of the problem because it doesn 't show the problem because it doesn 't show the ice of the ice .
2025-05-29 10:17:06,660 - INFO - joeynmt.training - Example #2
2025-05-29 10:17:06,660 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:17:06,660 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:17:06,660 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'ta', 'is', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:17:06,660 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:17:06,660 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:17:06,660 - INFO - joeynmt.training - 	Hypothesis: The glacial calotta is , in a certain sense , the heart of the global climate system .
2025-05-29 10:17:06,660 - INFO - joeynmt.training - Example #3
2025-05-29 10:17:06,660 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:17:06,660 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:17:06,660 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', "'ve", 'got', 'to', 'in@@', 'ver@@', 'n@@', 'y', 'and', 'you', 'r@@', 'iti@@', 'z@@', 'en', '.', '</s>']
2025-05-29 10:17:06,660 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:17:06,660 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:17:06,660 - INFO - joeynmt.training - 	Hypothesis: You 've got to inverny and you ritizen .
2025-05-29 10:17:06,660 - INFO - joeynmt.training - Example #4
2025-05-29 10:17:06,660 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:17:06,660 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:17:06,660 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'di@@', 'a@@', 'positi@@', 've', 'is', 'going', 'to', 'be', 'a', 'quick@@', 'ly', 'quick@@', 'ly', 'car@@', 'ri@@', 'ed', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:17:06,661 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:17:06,661 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:17:06,661 - INFO - joeynmt.training - 	Hypothesis: The next diapositive is going to be a quickly quickly carried to the last 25 years .
2025-05-29 10:17:23,010 - INFO - joeynmt.training - Epoch   2, Step:     7600, Batch Loss:     1.736095, Batch Acc: 0.509836, Tokens per Sec:     4211, Lr: 0.000300
2025-05-29 10:17:39,388 - INFO - joeynmt.training - Epoch   2, Step:     7700, Batch Loss:     1.670473, Batch Acc: 0.513224, Tokens per Sec:     4301, Lr: 0.000300
2025-05-29 10:17:56,379 - INFO - joeynmt.training - Epoch   2, Step:     7800, Batch Loss:     1.768281, Batch Acc: 0.512566, Tokens per Sec:     4110, Lr: 0.000300
2025-05-29 10:18:13,003 - INFO - joeynmt.training - Epoch   2, Step:     7900, Batch Loss:     1.760762, Batch Acc: 0.509151, Tokens per Sec:     4082, Lr: 0.000300
2025-05-29 10:18:29,801 - INFO - joeynmt.training - Epoch   2, Step:     8000, Batch Loss:     1.677947, Batch Acc: 0.511249, Tokens per Sec:     4215, Lr: 0.000300
2025-05-29 10:18:29,802 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:18:29,802 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:19:08,430 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.44, acc:   0.49, generation: 38.6206[sec], evaluation: 0.0000[sec]
2025-05-29 10:19:08,433 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:19:08,621 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/5500.ckpt
2025-05-29 10:19:08,625 - INFO - joeynmt.training - Example #0
2025-05-29 10:19:08,625 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:19:08,625 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:19:08,625 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'de', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'al', 'c@@', 'ut@@', 't@@', 'ics', ',', 'that', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', 'United', 'States', ',', 'is', 're@@', 'stre@@', 'et', 'of', 'the', '19@@', 'th', 'of', 'the', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 10:19:08,625 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:19:08,625 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:19:08,625 - INFO - joeynmt.training - 	Hypothesis: The glacial I showed these slide demonstrate that the calotta glacial cuttics , that for almost three million years had the size of the United States , is restreet of the 19th of the continental .
2025-05-29 10:19:08,625 - INFO - joeynmt.training - Example #1
2025-05-29 10:19:08,625 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:19:08,625 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:19:08,625 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'ject', 'is', 'this', 'sub@@', 'val@@', 'u@@', 'es', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ent', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:19:08,625 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:19:08,625 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:19:08,625 - INFO - joeynmt.training - 	Hypothesis: But this subject is this subvalues of the problem because it doesn 't show the spent of the ice .
2025-05-29 10:19:08,625 - INFO - joeynmt.training - Example #2
2025-05-29 10:19:08,625 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:19:08,625 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:19:08,625 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ics', 'is', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'heart', 'of', 'the', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:19:08,625 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:19:08,625 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:19:08,625 - INFO - joeynmt.training - 	Hypothesis: The glacial calottics is , in a certain sense , the heart of the climate system .
2025-05-29 10:19:08,625 - INFO - joeynmt.training - Example #3
2025-05-29 10:19:08,625 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:19:08,625 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:19:08,625 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'know', ',', 'you', 'know', ',', 'you', 'know', ',', 'you', 'know', ',', '</s>']
2025-05-29 10:19:08,626 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:19:08,626 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:19:08,626 - INFO - joeynmt.training - 	Hypothesis: You know , you know , you know , you know ,
2025-05-29 10:19:08,626 - INFO - joeynmt.training - Example #4
2025-05-29 10:19:08,626 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:19:08,626 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:19:08,626 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'de@@', 'mon@@', 'str@@', 'ate', 'is', 'going', 'to', 'be', 'a', 'quick@@', 'ly', 'car@@', 'rel@@', 'y', 'relati@@', 'on@@', 'ship', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:19:08,626 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:19:08,626 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:19:08,626 - INFO - joeynmt.training - 	Hypothesis: The next next demonstrate is going to be a quickly carrely relationship of the last 25 years .
2025-05-29 10:19:24,995 - INFO - joeynmt.training - Epoch   2, Step:     8100, Batch Loss:     1.664817, Batch Acc: 0.508680, Tokens per Sec:     4219, Lr: 0.000300
2025-05-29 10:19:37,438 - INFO - joeynmt.training - Epoch   2: total training loss 7704.27
2025-05-29 10:19:37,439 - INFO - joeynmt.training - EPOCH 3
2025-05-29 10:19:42,022 - INFO - joeynmt.training - Epoch   3, Step:     8200, Batch Loss:     1.671628, Batch Acc: 0.539973, Tokens per Sec:     4076, Lr: 0.000300
2025-05-29 10:19:59,384 - INFO - joeynmt.training - Epoch   3, Step:     8300, Batch Loss:     1.598861, Batch Acc: 0.534535, Tokens per Sec:     4130, Lr: 0.000300
2025-05-29 10:20:16,637 - INFO - joeynmt.training - Epoch   3, Step:     8400, Batch Loss:     1.732290, Batch Acc: 0.537262, Tokens per Sec:     4196, Lr: 0.000300
2025-05-29 10:20:33,598 - INFO - joeynmt.training - Epoch   3, Step:     8500, Batch Loss:     1.597496, Batch Acc: 0.533144, Tokens per Sec:     4200, Lr: 0.000300
2025-05-29 10:20:33,599 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:20:33,599 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:21:18,503 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.33, acc:   0.50, generation: 44.8963[sec], evaluation: 0.0000[sec]
2025-05-29 10:21:18,506 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:21:18,652 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/6000.ckpt
2025-05-29 10:21:18,655 - INFO - joeynmt.training - Example #0
2025-05-29 10:21:18,655 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:21:18,655 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:21:18,655 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['So', ',', 'I', 'sho@@', 'wed', 'these', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'al', 'gl@@', 'aci@@', 'al', 'gl@@', 'aci@@', 'al', 'gl@@', 'aci@@', 'al', '.', 'And', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', ',', 'and', 'it', "'s", 're@@', 'stre@@', 't@@', 'ch', 'of', 'the', '4@@', '8', 'percent', '.', '</s>']
2025-05-29 10:21:18,655 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:21:18,655 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:21:18,655 - INFO - joeynmt.training - 	Hypothesis: So , I showed these these slides to show that the calotta glacial glacial glacial glacial . And for almost three million years had the size of 48 continental , and it 's restretch of the 48 percent .
2025-05-29 10:21:18,655 - INFO - joeynmt.training - Example #1
2025-05-29 10:21:18,655 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:21:18,655 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:21:18,655 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'I', "'m", 'going', 'to', 'be', 'a', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'it', 'a', 'sp@@', 'ess@@', 'or', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:21:18,656 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:21:18,656 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:21:18,656 - INFO - joeynmt.training - 	Hypothesis: But I 'm going to be a gravity of the problem because it doesn 't show it a spessor of the ice .
2025-05-29 10:21:18,656 - INFO - joeynmt.training - Example #2
2025-05-29 10:21:18,656 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:21:18,656 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:21:18,656 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'gl@@', 'aci@@', 'al', 'c@@', 'y@@', 'y@@', 'y@@', 'nam@@', 'al', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'heart', 'of', 'the', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:21:18,656 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:21:18,656 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:21:18,656 - INFO - joeynmt.training - 	Hypothesis: The glacial glacial cyyynamal , in a certain sense , the heart of the climate system .
2025-05-29 10:21:18,656 - INFO - joeynmt.training - Example #3
2025-05-29 10:21:18,656 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:21:18,656 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:21:18,656 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'can', 'ex@@', 'pen@@', 'sive', 'and', 'you', 'can', 's@@', 'le@@', 'g', 'up', '.', '</s>']
2025-05-29 10:21:18,656 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:21:18,656 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:21:18,656 - INFO - joeynmt.training - 	Hypothesis: You can expensive and you can sleg up .
2025-05-29 10:21:18,656 - INFO - joeynmt.training - Example #4
2025-05-29 10:21:18,656 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:21:18,656 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:21:18,656 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'f@@', 'ast', 'car@@', 'rel@@', 'ated', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:21:18,656 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:21:18,656 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:21:18,656 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a fast carrelated to the last 25 years .
2025-05-29 10:21:35,171 - INFO - joeynmt.training - Epoch   3, Step:     8600, Batch Loss:     1.594951, Batch Acc: 0.531206, Tokens per Sec:     4308, Lr: 0.000300
2025-05-29 10:21:52,557 - INFO - joeynmt.training - Epoch   3, Step:     8700, Batch Loss:     1.765250, Batch Acc: 0.525442, Tokens per Sec:     4014, Lr: 0.000300
2025-05-29 10:22:09,260 - INFO - joeynmt.training - Epoch   3, Step:     8800, Batch Loss:     1.717763, Batch Acc: 0.535093, Tokens per Sec:     4205, Lr: 0.000300
2025-05-29 10:22:26,193 - INFO - joeynmt.training - Epoch   3, Step:     8900, Batch Loss:     1.622437, Batch Acc: 0.535142, Tokens per Sec:     4172, Lr: 0.000300
2025-05-29 10:22:43,072 - INFO - joeynmt.training - Epoch   3, Step:     9000, Batch Loss:     1.925446, Batch Acc: 0.535092, Tokens per Sec:     4311, Lr: 0.000300
2025-05-29 10:22:43,073 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:22:43,073 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:23:25,737 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.29, acc:   0.50, generation: 42.6564[sec], evaluation: 0.0000[sec]
2025-05-29 10:23:25,739 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:23:25,941 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/6500.ckpt
2025-05-29 10:23:25,945 - INFO - joeynmt.training - Example #0
2025-05-29 10:23:25,945 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:23:25,945 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:23:25,945 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'these', 'sli@@', 'de', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'ta', ',', 'which', 'is', 'about', 'three', 'million', 'years', ',', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'of', 'the', 'United', 'States', 'of', 'the', '19@@', 'th', 'of', 'the', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 10:23:25,945 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:23:25,945 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:23:25,945 - INFO - joeynmt.training - 	Hypothesis: I showed these slide demonstrate that the calotta glacial calotta , which is about three million years , had the size of the 48 of the United States of the 19th of the continental .
2025-05-29 10:23:25,945 - INFO - joeynmt.training - Example #1
2025-05-29 10:23:25,945 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:23:25,945 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:23:25,945 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'ject', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ent', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:23:25,945 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:23:25,945 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:23:25,945 - INFO - joeynmt.training - 	Hypothesis: But this subject of the problem because it doesn 't show the spent of the problem because it doesn 't show the ice of the ice .
2025-05-29 10:23:25,945 - INFO - joeynmt.training - Example #2
2025-05-29 10:23:25,945 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:23:25,945 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:23:25,945 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ical', ',', 'is', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:23:25,946 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:23:25,946 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:23:25,946 - INFO - joeynmt.training - 	Hypothesis: The glacial calottical , is in a sense , the heart of the climate system .
2025-05-29 10:23:25,946 - INFO - joeynmt.training - Example #3
2025-05-29 10:23:25,946 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:23:25,946 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:23:25,946 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', "'re", 'in@@', 'ver@@', 's', 'and', 'ex@@', 'ten@@', 'd', 'of', 'ex@@', 't', 'and', 'ex@@', 't', '.', '</s>']
2025-05-29 10:23:25,946 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:23:25,946 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:23:25,946 - INFO - joeynmt.training - 	Hypothesis: You 're invers and extend of ext and ext .
2025-05-29 10:23:25,946 - INFO - joeynmt.training - Example #4
2025-05-29 10:23:25,946 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:23:25,946 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:23:25,946 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'de@@', 'positi@@', 've', 'will', 'be', 'a', 'f@@', 'ast', ',', 'it', 'will', 'be', 'a', 'f@@', 'ast@@', 'er', 'than', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:23:25,946 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:23:25,946 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:23:25,946 - INFO - joeynmt.training - 	Hypothesis: The next depositive will be a fast , it will be a faster than the last 25 years .
2025-05-29 10:23:43,254 - INFO - joeynmt.training - Epoch   3, Step:     9100, Batch Loss:     1.750164, Batch Acc: 0.536120, Tokens per Sec:     4132, Lr: 0.000300
2025-05-29 10:24:00,225 - INFO - joeynmt.training - Epoch   3, Step:     9200, Batch Loss:     1.682061, Batch Acc: 0.529644, Tokens per Sec:     4207, Lr: 0.000300
2025-05-29 10:24:18,765 - INFO - joeynmt.training - Epoch   3, Step:     9300, Batch Loss:     1.855051, Batch Acc: 0.537440, Tokens per Sec:     3826, Lr: 0.000300
2025-05-29 10:24:36,168 - INFO - joeynmt.training - Epoch   3, Step:     9400, Batch Loss:     1.637804, Batch Acc: 0.534749, Tokens per Sec:     4151, Lr: 0.000300
2025-05-29 10:24:53,496 - INFO - joeynmt.training - Epoch   3, Step:     9500, Batch Loss:     1.574147, Batch Acc: 0.535772, Tokens per Sec:     4062, Lr: 0.000300
2025-05-29 10:24:53,497 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:24:53,497 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:25:40,353 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.81, ppl:   6.12, acc:   0.51, generation: 46.8497[sec], evaluation: 0.0000[sec]
2025-05-29 10:25:40,356 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:25:40,559 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/7000.ckpt
2025-05-29 10:25:40,561 - INFO - joeynmt.training - Example #0
2025-05-29 10:25:40,562 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:25:40,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:25:40,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'de', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'ta', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'had', 'the', 'size', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 10:25:40,562 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:25:40,562 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:25:40,562 - INFO - joeynmt.training - 	Hypothesis: The glacial I showed these slide demonstrate that the calotta glacial calotta , which for almost three million years had had the size of 48 continental .
2025-05-29 10:25:40,562 - INFO - joeynmt.training - Example #1
2025-05-29 10:25:40,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:25:40,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:25:40,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', "'s", 'a', 'sub@@', 'j@@', 'our@@', 'ney', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ent', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:25:40,562 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:25:40,562 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:25:40,562 - INFO - joeynmt.training - 	Hypothesis: But it 's a subjourney of the problem because it doesn 't show the spent of the ice of the ice .
2025-05-29 10:25:40,562 - INFO - joeynmt.training - Example #2
2025-05-29 10:25:40,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:25:40,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:25:40,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'al', 'c@@', 'y@@', 'cle', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'heart', 'heart', 'heart', 'of', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:25:40,562 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:25:40,562 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:25:40,562 - INFO - joeynmt.training - 	Hypothesis: The glacial calotal cycle is , in a sense , the heart heart heart heart of climate system .
2025-05-29 10:25:40,562 - INFO - joeynmt.training - Example #3
2025-05-29 10:25:40,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:25:40,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:25:40,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'know', ',', 'you', "'re", 'in@@', 'ver@@', 'ti@@', 's@@', 'er', 'and', 'down', '.', '</s>']
2025-05-29 10:25:40,563 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:25:40,563 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:25:40,563 - INFO - joeynmt.training - 	Hypothesis: You know , you 're invertiser and down .
2025-05-29 10:25:40,563 - INFO - joeynmt.training - Example #4
2025-05-29 10:25:40,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:25:40,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:25:40,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'rapi@@', 'd', 'car@@', 'rel@@', 'ated', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:25:40,563 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:25:40,563 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:25:40,563 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a rapid carrelated to the last 25 years .
2025-05-29 10:25:59,141 - INFO - joeynmt.training - Epoch   3, Step:     9600, Batch Loss:     1.689205, Batch Acc: 0.539335, Tokens per Sec:     3855, Lr: 0.000300
2025-05-29 10:26:17,389 - INFO - joeynmt.training - Epoch   3, Step:     9700, Batch Loss:     1.773984, Batch Acc: 0.534808, Tokens per Sec:     3969, Lr: 0.000300
2025-05-29 10:26:35,536 - INFO - joeynmt.training - Epoch   3, Step:     9800, Batch Loss:     1.600456, Batch Acc: 0.536902, Tokens per Sec:     3871, Lr: 0.000300
2025-05-29 10:26:52,827 - INFO - joeynmt.training - Epoch   3, Step:     9900, Batch Loss:     1.658133, Batch Acc: 0.530868, Tokens per Sec:     4103, Lr: 0.000300
2025-05-29 10:27:10,665 - INFO - joeynmt.training - Epoch   3, Step:    10000, Batch Loss:     1.637557, Batch Acc: 0.545101, Tokens per Sec:     4023, Lr: 0.000300
2025-05-29 10:27:10,667 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:27:10,667 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:27:53,440 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.04, acc:   0.51, generation: 42.7662[sec], evaluation: 0.0000[sec]
2025-05-29 10:27:53,442 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:27:53,667 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/7500.ckpt
2025-05-29 10:27:53,669 - INFO - joeynmt.training - Example #0
2025-05-29 10:27:53,669 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:27:53,669 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:27:53,670 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'these', 'sli@@', 'de', 'sli@@', 'de', 'to', 'show', 'that', 'the', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'ta', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'of', 'the', '19@@', '8@@', '8', 'contin@@', 'ent@@', 'al', ',', 'it', "'s", 're@@', 'stre@@', 't', 'of', '40', 'percent', '.', '</s>']
2025-05-29 10:27:53,670 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:27:53,670 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:27:53,670 - INFO - joeynmt.training - 	Hypothesis: I showed these slide slide to show that the calotta glacial calotta , which for almost three million years had the size of the 48 of the 1988 continental , it 's restret of 40 percent .
2025-05-29 10:27:53,670 - INFO - joeynmt.training - Example #1
2025-05-29 10:27:53,670 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:27:53,670 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:27:53,670 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', "'s", 'a', 'lot', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'it', 'ex@@', 'hi@@', 'b@@', 'ition', ',', 'because', 'it', 'doesn', "'t", 'show', 'it', 'sp@@', 'ent', 'it', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:27:53,670 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:27:53,670 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:27:53,670 - INFO - joeynmt.training - 	Hypothesis: But it 's a lot of the problem because it doesn 't show it exhibition , because it doesn 't show it spent it of the ice .
2025-05-29 10:27:53,670 - INFO - joeynmt.training - Example #2
2025-05-29 10:27:53,670 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:27:53,670 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:27:53,670 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ical', 'cal@@', 'ot@@', 't@@', 'ical', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'p@@', 'it@@', 'it@@', 'ch@@', 'es', 'of', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:27:53,670 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:27:53,670 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:27:53,670 - INFO - joeynmt.training - 	Hypothesis: The artical calottical , in a certain sense , the pititches of global climate system .
2025-05-29 10:27:53,670 - INFO - joeynmt.training - Example #3
2025-05-29 10:27:53,670 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:27:53,670 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:27:53,670 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'go', 'up', 'to', 'the', 'w@@', 'all@@', '-@@', 'up', 'and', 'ex@@', 't', 'of', 'ex@@', 't', '.', '</s>']
2025-05-29 10:27:53,671 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:27:53,671 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:27:53,671 - INFO - joeynmt.training - 	Hypothesis: You go up to the wall-up and ext of ext .
2025-05-29 10:27:53,671 - INFO - joeynmt.training - Example #4
2025-05-29 10:27:53,671 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:27:53,671 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:27:53,671 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'quick@@', 'ly', 'car@@', 'rel@@', 'y', 'for', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:27:53,671 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:27:53,671 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:27:53,671 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quickly carrely for the last 25 years .
2025-05-29 10:28:14,453 - INFO - joeynmt.training - Epoch   3, Step:    10100, Batch Loss:     1.449014, Batch Acc: 0.541383, Tokens per Sec:     3444, Lr: 0.000300
2025-05-29 10:28:34,227 - INFO - joeynmt.training - Epoch   3, Step:    10200, Batch Loss:     1.535742, Batch Acc: 0.539237, Tokens per Sec:     3662, Lr: 0.000300
2025-05-29 10:28:54,460 - INFO - joeynmt.training - Epoch   3, Step:    10300, Batch Loss:     1.472996, Batch Acc: 0.544012, Tokens per Sec:     3651, Lr: 0.000300
2025-05-29 10:29:13,996 - INFO - joeynmt.training - Epoch   3, Step:    10400, Batch Loss:     1.565996, Batch Acc: 0.537815, Tokens per Sec:     3707, Lr: 0.000300
2025-05-29 10:29:33,101 - INFO - joeynmt.training - Epoch   3, Step:    10500, Batch Loss:     1.967838, Batch Acc: 0.538824, Tokens per Sec:     3723, Lr: 0.000300
2025-05-29 10:29:33,102 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:29:33,102 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:30:15,168 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.78, ppl:   5.95, acc:   0.52, generation: 42.0590[sec], evaluation: 0.0000[sec]
2025-05-29 10:30:15,170 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:30:15,374 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/8000.ckpt
2025-05-29 10:30:15,377 - INFO - joeynmt.training - Example #0
2025-05-29 10:30:15,377 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:30:15,377 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:30:15,377 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'de', 'sli@@', 'de', 'that', 'cal@@', 'ot@@', 'ta', 'c@@', 'y@@', 'cle', ',', 'which', 'is', 'about', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'of', 'the', 'United', 'States', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent', ',', 'is', 're@@', 'ach@@', 'ing', 'in', '40', 'percent', '.', '</s>']
2025-05-29 10:30:15,377 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:30:15,377 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:30:15,377 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slide slide that calotta cycle , which is about three million years had the size of the 48 of the United States of 48 continental continental continental continental continent , is reaching in 40 percent .
2025-05-29 10:30:15,377 - INFO - joeynmt.training - Example #1
2025-05-29 10:30:15,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:30:15,378 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:30:15,378 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'val@@', 'ue', 'of', 'the', 'problem', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'it', 'sp@@', 'ent', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:30:15,378 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:30:15,378 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:30:15,378 - INFO - joeynmt.training - 	Hypothesis: But this subvalue of the problem of the problem because it doesn 't show it spent of the ice .
2025-05-29 10:30:15,378 - INFO - joeynmt.training - Example #2
2025-05-29 10:30:15,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:30:15,378 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:30:15,378 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ical', 'cal@@', 'ot@@', 't@@', 'ical', 'cal@@', 'ot@@', 's', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'course', ',', 'the', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:30:15,378 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:30:15,378 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:30:15,378 - INFO - joeynmt.training - 	Hypothesis: The artical calottical calots , in a sense , the heart of course , the heart of the global climate system .
2025-05-29 10:30:15,378 - INFO - joeynmt.training - Example #3
2025-05-29 10:30:15,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:30:15,378 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:30:15,378 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'go', 'up', 'and', 'the', 'w@@', 'in@@', 'ds', 'and', 'the', 'sum@@', 'mer', '.', '</s>']
2025-05-29 10:30:15,378 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:30:15,378 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:30:15,378 - INFO - joeynmt.training - 	Hypothesis: You go up and the winds and the summer .
2025-05-29 10:30:15,378 - INFO - joeynmt.training - Example #4
2025-05-29 10:30:15,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:30:15,378 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:30:15,378 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'quick@@', 'ly', 'car@@', 'rel@@', 'ated', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:30:15,379 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:30:15,379 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:30:15,379 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quickly carrelated to the last 25 years .
2025-05-29 10:30:32,824 - INFO - joeynmt.training - Epoch   3, Step:    10600, Batch Loss:     1.783552, Batch Acc: 0.541254, Tokens per Sec:     4063, Lr: 0.000300
2025-05-29 10:30:49,568 - INFO - joeynmt.training - Epoch   3, Step:    10700, Batch Loss:     1.711981, Batch Acc: 0.539777, Tokens per Sec:     4228, Lr: 0.000300
2025-05-29 10:31:07,623 - INFO - joeynmt.training - Epoch   3, Step:    10800, Batch Loss:     1.496610, Batch Acc: 0.541648, Tokens per Sec:     3942, Lr: 0.000300
2025-05-29 10:31:25,525 - INFO - joeynmt.training - Epoch   3, Step:    10900, Batch Loss:     1.660470, Batch Acc: 0.543534, Tokens per Sec:     3885, Lr: 0.000300
2025-05-29 10:31:44,177 - INFO - joeynmt.training - Epoch   3, Step:    11000, Batch Loss:     1.667751, Batch Acc: 0.540833, Tokens per Sec:     3840, Lr: 0.000300
2025-05-29 10:31:44,178 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:31:44,178 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:32:29,232 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.78, ppl:   5.90, acc:   0.51, generation: 45.0462[sec], evaluation: 0.0000[sec]
2025-05-29 10:32:29,235 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:32:29,524 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/8500.ckpt
2025-05-29 10:32:29,525 - INFO - joeynmt.training - Example #0
2025-05-29 10:32:29,525 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:32:29,525 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:32:29,525 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', "'ve", 'sho@@', 'wed', 'these', 'sli@@', 'de', 'de@@', 'mon@@', 'str@@', 'ate', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'cal@@', 'ot@@', 't@@', 'ical', 'cal@@', 'ot@@', 't@@', 'ics', ',', 'for', 'almost', 'three', 'million', 'years', 'had', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 10:32:29,526 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:32:29,526 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:32:29,526 - INFO - joeynmt.training - 	Hypothesis: I 've showed these slide demonstrate demonstrate that the calottical calottics , for almost three million years had had the size of the 48 continental size of the 48 continental .
2025-05-29 10:32:29,526 - INFO - joeynmt.training - Example #1
2025-05-29 10:32:29,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:32:29,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:32:29,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho@@', 'w@@', 'ever', ',', 'you', 'have', 'a', 'lot', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ent', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:32:29,526 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:32:29,526 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:32:29,526 - INFO - joeynmt.training - 	Hypothesis: However , you have a lot of the problem because it doesn 't show the spent of the ice .
2025-05-29 10:32:29,526 - INFO - joeynmt.training - Example #2
2025-05-29 10:32:29,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:32:29,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:32:29,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ical', 'c@@', 'y@@', 'cle', 'is', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'pul@@', 's@@', '-@@', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:32:29,526 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:32:29,526 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:32:29,526 - INFO - joeynmt.training - 	Hypothesis: The glacial calottical cycle is , in a certain sense , the puls-climate system .
2025-05-29 10:32:29,526 - INFO - joeynmt.training - Example #3
2025-05-29 10:32:29,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:32:29,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:32:29,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'get', 'up', 'of', 'the', 'in@@', 'ver@@', 'no', 'and', 'you', 'get', 'the', 'sum@@', 'mer', '.', '</s>']
2025-05-29 10:32:29,527 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:32:29,527 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:32:29,527 - INFO - joeynmt.training - 	Hypothesis: You get up of the inverno and you get the summer .
2025-05-29 10:32:29,527 - INFO - joeynmt.training - Example #4
2025-05-29 10:32:29,527 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:32:29,527 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:32:29,527 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'rapi@@', 'd', 'car@@', 'rel@@', 'ated', 'car@@', 'rel@@', 'ate', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:32:29,527 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:32:29,527 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:32:29,527 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a rapid carrelated carrelate to the last 25 years .
2025-05-29 10:32:49,639 - INFO - joeynmt.training - Epoch   3, Step:    11100, Batch Loss:     1.700946, Batch Acc: 0.541198, Tokens per Sec:     3508, Lr: 0.000300
2025-05-29 10:33:08,547 - INFO - joeynmt.training - Epoch   3, Step:    11200, Batch Loss:     1.499240, Batch Acc: 0.544925, Tokens per Sec:     3705, Lr: 0.000300
2025-05-29 10:33:27,929 - INFO - joeynmt.training - Epoch   3, Step:    11300, Batch Loss:     1.777680, Batch Acc: 0.547192, Tokens per Sec:     3683, Lr: 0.000300
2025-05-29 10:33:45,301 - INFO - joeynmt.training - Epoch   3, Step:    11400, Batch Loss:     1.563871, Batch Acc: 0.546047, Tokens per Sec:     3978, Lr: 0.000300
2025-05-29 10:34:03,145 - INFO - joeynmt.training - Epoch   3, Step:    11500, Batch Loss:     1.541224, Batch Acc: 0.554343, Tokens per Sec:     4051, Lr: 0.000300
2025-05-29 10:34:03,146 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:34:03,146 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:34:46,133 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.81, acc:   0.52, generation: 42.9797[sec], evaluation: 0.0000[sec]
2025-05-29 10:34:46,135 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:34:46,411 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/9000.ckpt
2025-05-29 10:34:46,412 - INFO - joeynmt.training - Example #0
2025-05-29 10:34:46,412 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:34:46,412 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:34:46,412 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'last', 'year', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ical', 'cal@@', 'ot@@', 't@@', 'ical', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 10:34:46,412 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:34:46,413 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:34:46,413 - INFO - joeynmt.training - 	Hypothesis: The last year I showed these slides to demonstrate that the glacial calottical calottical , which for almost three million years had the size of 48 continental .
2025-05-29 10:34:46,413 - INFO - joeynmt.training - Example #1
2025-05-29 10:34:46,413 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:34:46,413 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:34:46,413 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho@@', 'w@@', 'ever', ',', 'this', 'sub@@', 'val@@', 'ley', 'is', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'that', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:34:46,413 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:34:46,413 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:34:46,413 - INFO - joeynmt.training - 	Hypothesis: However , this subvalley is the gravity of the problem because it doesn 't show that the ice of the ice .
2025-05-29 10:34:46,413 - INFO - joeynmt.training - Example #2
2025-05-29 10:34:46,413 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:34:46,413 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:34:46,413 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'H@@', 'e@@', 'm', 'cal@@', 'ot@@', 't@@', 'ical', 'cal@@', 'ot@@', 't@@', 'ical', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:34:46,413 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:34:46,413 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:34:46,413 - INFO - joeynmt.training - 	Hypothesis: The Hem calottical calottical , in a sense , the heart of the global climate system .
2025-05-29 10:34:46,413 - INFO - joeynmt.training - Example #3
2025-05-29 10:34:46,413 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:34:46,413 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:34:46,413 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'know', ',', 'you', "'re", 'going', 'to', 'be', 'w@@', 'il@@', 'ling', 'and', 'w@@', 'il@@', 'ling', '.', '</s>']
2025-05-29 10:34:46,413 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:34:46,413 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:34:46,413 - INFO - joeynmt.training - 	Hypothesis: You know , you 're going to be willing and willing .
2025-05-29 10:34:46,413 - INFO - joeynmt.training - Example #4
2025-05-29 10:34:46,413 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:34:46,413 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:34:46,413 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rapi@@', 'd', 'car@@', 'rel@@', 'ated', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:34:46,414 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:34:46,414 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:34:46,414 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid carrelated to the last 25 years .
2025-05-29 10:35:06,071 - INFO - joeynmt.training - Epoch   3, Step:    11600, Batch Loss:     1.765216, Batch Acc: 0.545099, Tokens per Sec:     3489, Lr: 0.000300
2025-05-29 10:35:28,610 - INFO - joeynmt.training - Epoch   3, Step:    11700, Batch Loss:     1.464940, Batch Acc: 0.548652, Tokens per Sec:     3159, Lr: 0.000300
2025-05-29 10:35:51,179 - INFO - joeynmt.training - Epoch   3, Step:    11800, Batch Loss:     1.721650, Batch Acc: 0.542620, Tokens per Sec:     3173, Lr: 0.000300
2025-05-29 10:36:10,583 - INFO - joeynmt.training - Epoch   3, Step:    11900, Batch Loss:     1.636458, Batch Acc: 0.552882, Tokens per Sec:     3642, Lr: 0.000300
2025-05-29 10:36:29,326 - INFO - joeynmt.training - Epoch   3, Step:    12000, Batch Loss:     1.716780, Batch Acc: 0.545470, Tokens per Sec:     3869, Lr: 0.000300
2025-05-29 10:36:29,327 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:36:29,327 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:37:15,992 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.75, ppl:   5.73, acc:   0.52, generation: 46.6563[sec], evaluation: 0.0000[sec]
2025-05-29 10:37:15,994 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:37:16,134 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/9500.ckpt
2025-05-29 10:37:16,137 - INFO - joeynmt.training - Example #0
2025-05-29 10:37:16,137 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:37:16,137 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:37:16,137 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['So', ',', 'last', 'year', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'de', 'sli@@', 'de', 'to', 'show', 'that', 'the', 'cal@@', 'ot@@', 't@@', '-@@', 'dol@@', 'ph@@', 'ins', ',', 'that', "'s", 'gl@@', 'aci@@', 'al', ',', 'that', 'for', 'almost', 'three', 'million', 'years', ',', 'he', 'had', 'the', 'size', 'of', '4@@', '8', '.', '</s>']
2025-05-29 10:37:16,137 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:37:16,137 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:37:16,137 - INFO - joeynmt.training - 	Hypothesis: So , last year I showed these slide slide to show that the calott-dolphins , that 's glacial , that for almost three million years , he had the size of 48 .
2025-05-29 10:37:16,137 - INFO - joeynmt.training - Example #1
2025-05-29 10:37:16,137 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:37:16,137 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:37:16,137 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', "'s", 'a', 'sub@@', 'val@@', 'ley', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'ex@@', 'hi@@', 'bit', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:37:16,138 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:37:16,138 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:37:16,138 - INFO - joeynmt.training - 	Hypothesis: But it 's a subvalley of the problem because it doesn 't show the problem because it doesn 't show the exhibit of the ice .
2025-05-29 10:37:16,138 - INFO - joeynmt.training - Example #2
2025-05-29 10:37:16,138 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:37:16,138 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:37:16,138 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ical', 'cal@@', 'ot@@', 't@@', 'ical', 'c@@', 'alc@@', 'ul@@', 'us', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'y@@', 'el@@', 'ess', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:37:16,138 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:37:16,138 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:37:16,138 - INFO - joeynmt.training - 	Hypothesis: The artical calottical calculus , in a sense , the pyeless of the global climate system .
2025-05-29 10:37:16,138 - INFO - joeynmt.training - Example #3
2025-05-29 10:37:16,138 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:37:16,138 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:37:16,138 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'can', 'ex@@', 'ten@@', 'd', 'of', 'ex@@', 'ten@@', 'd', 'and', 'ex@@', 'ten@@', 'd', 'of', 'ex@@', 'tre@@', 'me', '.', '</s>']
2025-05-29 10:37:16,138 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:37:16,138 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:37:16,138 - INFO - joeynmt.training - 	Hypothesis: You can extend of extend and extend of extreme .
2025-05-29 10:37:16,138 - INFO - joeynmt.training - Example #4
2025-05-29 10:37:16,138 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:37:16,138 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:37:16,138 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'qu@@', 'ick', 'car@@', 'rel@@', 'ated', 'to', 'the', 'past', '25', 'years', '.', '</s>']
2025-05-29 10:37:16,138 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:37:16,139 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:37:16,139 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quick carrelated to the past 25 years .
2025-05-29 10:37:34,936 - INFO - joeynmt.training - Epoch   3, Step:    12100, Batch Loss:     1.694304, Batch Acc: 0.550201, Tokens per Sec:     3840, Lr: 0.000300
2025-05-29 10:37:54,463 - INFO - joeynmt.training - Epoch   3, Step:    12200, Batch Loss:     1.734596, Batch Acc: 0.547902, Tokens per Sec:     3729, Lr: 0.000300
2025-05-29 10:38:02,093 - INFO - joeynmt.training - Epoch   3: total training loss 6801.90
2025-05-29 10:38:02,093 - INFO - joeynmt.training - EPOCH 4
2025-05-29 10:38:13,554 - INFO - joeynmt.training - Epoch   4, Step:    12300, Batch Loss:     1.536833, Batch Acc: 0.570385, Tokens per Sec:     3788, Lr: 0.000300
2025-05-29 10:38:31,580 - INFO - joeynmt.training - Epoch   4, Step:    12400, Batch Loss:     1.580115, Batch Acc: 0.561942, Tokens per Sec:     3895, Lr: 0.000300
2025-05-29 10:38:52,812 - INFO - joeynmt.training - Epoch   4, Step:    12500, Batch Loss:     1.566884, Batch Acc: 0.567208, Tokens per Sec:     3427, Lr: 0.000300
2025-05-29 10:38:52,813 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:38:52,813 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:39:41,062 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.66, acc:   0.53, generation: 48.2403[sec], evaluation: 0.0000[sec]
2025-05-29 10:39:41,064 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:39:41,180 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/10000.ckpt
2025-05-29 10:39:41,184 - INFO - joeynmt.training - Example #0
2025-05-29 10:39:41,185 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:39:41,185 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:39:41,185 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', "'ve", 'sho@@', 'wed', 'these', 'sli@@', 'de', 'de@@', 'mon@@', 'str@@', 'ate', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'cal@@', 'ot@@', 'tic', 'cal@@', 'ot@@', 'tic', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'percent', '.', '</s>']
2025-05-29 10:39:41,185 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:39:41,185 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:39:41,185 - INFO - joeynmt.training - 	Hypothesis: I 've showed these slide demonstrate demonstrate that the calottic calottic , which for almost three million years had the size of 48 million years had the size of 48 percent .
2025-05-29 10:39:41,185 - INFO - joeynmt.training - Example #1
2025-05-29 10:39:41,185 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:39:41,185 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:39:41,185 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho@@', 'w@@', 'ever', ',', 'this', 'under@@', 'ne@@', 'ath', 'the', 'problem', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'read', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:39:41,185 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:39:41,185 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:39:41,185 - INFO - joeynmt.training - 	Hypothesis: However , this underneath the problem of the problem because it doesn 't show the spread of the ice .
2025-05-29 10:39:41,185 - INFO - joeynmt.training - Example #2
2025-05-29 10:39:41,185 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:39:41,185 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:39:41,185 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'age', 'is', ',', 'in', 'a', 'sense', ',', 'a', 'sense', ',', 'the', 'p@@', 'y@@', 'el@@', 'ess', 'of', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:39:41,186 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:39:41,186 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:39:41,186 - INFO - joeynmt.training - 	Hypothesis: The glacial calotage is , in a sense , a sense , the pyeless of global climate system .
2025-05-29 10:39:41,186 - INFO - joeynmt.training - Example #3
2025-05-29 10:39:41,186 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:39:41,186 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:39:41,186 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'exp@@', 'an@@', 'ies', 'and', 'st@@', 'and', 're@@', 'tre@@', 'at@@', 'ment', '.', '</s>']
2025-05-29 10:39:41,186 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:39:41,186 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:39:41,186 - INFO - joeynmt.training - 	Hypothesis: It 's expanies and stand retreatment .
2025-05-29 10:39:41,186 - INFO - joeynmt.training - Example #4
2025-05-29 10:39:41,186 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:39:41,186 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:39:41,186 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'rapi@@', 'd', 'car@@', 'rel@@', 'ated', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:39:41,186 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:39:41,186 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:39:41,186 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a rapid carrelated to the last 25 years .
2025-05-29 10:40:01,246 - INFO - joeynmt.training - Epoch   4, Step:    12600, Batch Loss:     1.526197, Batch Acc: 0.569854, Tokens per Sec:     3573, Lr: 0.000300
2025-05-29 10:40:19,205 - INFO - joeynmt.training - Epoch   4, Step:    12700, Batch Loss:     1.566037, Batch Acc: 0.562807, Tokens per Sec:     4018, Lr: 0.000300
2025-05-29 10:40:38,571 - INFO - joeynmt.training - Epoch   4, Step:    12800, Batch Loss:     1.328374, Batch Acc: 0.573794, Tokens per Sec:     3658, Lr: 0.000300
2025-05-29 10:40:56,326 - INFO - joeynmt.training - Epoch   4, Step:    12900, Batch Loss:     1.504274, Batch Acc: 0.564070, Tokens per Sec:     3990, Lr: 0.000300
2025-05-29 10:41:15,119 - INFO - joeynmt.training - Epoch   4, Step:    13000, Batch Loss:     1.629638, Batch Acc: 0.567433, Tokens per Sec:     3763, Lr: 0.000300
2025-05-29 10:41:15,120 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:41:15,120 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:42:02,775 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.66, acc:   0.53, generation: 47.6470[sec], evaluation: 0.0000[sec]
2025-05-29 10:42:02,780 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:42:02,900 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/10500.ckpt
2025-05-29 10:42:02,906 - INFO - joeynmt.training - Example #0
2025-05-29 10:42:02,906 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:42:02,906 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:42:02,906 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'de', 'sli@@', 'de', 'de@@', 'mon@@', 'str@@', 'ate', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'cal@@', 'ot@@', 'ta', ',', 'which', 'is', 'about', 'three', 'million', 'years', ',', 'had', 'the', 'size', 'of', '4@@', '8', 'million', 'years', ',', 'the', 'United', 'States', ',', 'is', 're@@', 'stre@@', 'et', '40', 'percent', '.', '</s>']
2025-05-29 10:42:02,906 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:42:02,906 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:42:02,906 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slide slide demonstrate demonstrate that the calotta , which is about three million years , had the size of 48 million years , the United States , is restreet 40 percent .
2025-05-29 10:42:02,906 - INFO - joeynmt.training - Example #1
2025-05-29 10:42:02,906 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:42:02,906 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:42:02,906 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', "'s", 'a', 'sub@@', 'val@@', 'ley', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ent', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:42:02,906 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:42:02,906 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:42:02,906 - INFO - joeynmt.training - 	Hypothesis: But it 's a subvalley the gravity of the problem because it doesn 't show the spent the ice of the ice .
2025-05-29 10:42:02,907 - INFO - joeynmt.training - Example #2
2025-05-29 10:42:02,907 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:42:02,907 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:42:02,907 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'Ar@@', 'c@@', 'tic', 'gl@@', 'aci@@', 'al', 'c@@', 'y@@', 'cle', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'in@@', 'k', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:42:02,907 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:42:02,907 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:42:02,907 - INFO - joeynmt.training - 	Hypothesis: The Arctic glacial cycle is , in a sense , the pink of the global climate system .
2025-05-29 10:42:02,907 - INFO - joeynmt.training - Example #3
2025-05-29 10:42:02,907 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:42:02,907 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:42:02,907 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'go', 'up', 'to', 'the', 'w@@', 'all', ',', 'you', "'re", 's@@', 'n@@', 'ice', '.', '</s>']
2025-05-29 10:42:02,907 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:42:02,907 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:42:02,907 - INFO - joeynmt.training - 	Hypothesis: You go up to the wall , you 're snice .
2025-05-29 10:42:02,907 - INFO - joeynmt.training - Example #4
2025-05-29 10:42:02,907 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:42:02,907 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:42:02,907 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'rel@@', 'ated', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:42:02,907 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:42:02,907 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:42:02,907 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick carrelated to the last 25 years .
2025-05-29 10:42:21,959 - INFO - joeynmt.training - Epoch   4, Step:    13100, Batch Loss:     1.549469, Batch Acc: 0.563764, Tokens per Sec:     3701, Lr: 0.000300
2025-05-29 10:42:40,653 - INFO - joeynmt.training - Epoch   4, Step:    13200, Batch Loss:     1.539055, Batch Acc: 0.560527, Tokens per Sec:     3866, Lr: 0.000300
2025-05-29 10:42:59,745 - INFO - joeynmt.training - Epoch   4, Step:    13300, Batch Loss:     1.787553, Batch Acc: 0.561732, Tokens per Sec:     3716, Lr: 0.000300
2025-05-29 10:43:18,736 - INFO - joeynmt.training - Epoch   4, Step:    13400, Batch Loss:     1.532657, Batch Acc: 0.563507, Tokens per Sec:     3791, Lr: 0.000300
2025-05-29 10:43:36,639 - INFO - joeynmt.training - Epoch   4, Step:    13500, Batch Loss:     1.580993, Batch Acc: 0.563817, Tokens per Sec:     3904, Lr: 0.000300
2025-05-29 10:43:36,641 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:43:36,641 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:44:22,113 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.64, acc:   0.53, generation: 45.4626[sec], evaluation: 0.0000[sec]
2025-05-29 10:44:22,115 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:44:22,283 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/11000.ckpt
2025-05-29 10:44:22,287 - INFO - joeynmt.training - Example #0
2025-05-29 10:44:22,287 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:44:22,287 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:44:22,287 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', ',', 'I', 'sho@@', 'wed', 'these', 'these', 'sli@@', 'des', 'to', 'de@@', 'vic@@', 'es', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'ta', ',', 'which', 'is', 'about', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', ',', 'it', "'s", 're@@', 'stre@@', 'et', '40', 'percent', '.', '</s>']
2025-05-29 10:44:22,288 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:44:22,288 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:44:22,288 - INFO - joeynmt.training - 	Hypothesis: Last year , I showed these these slides to devices to show that the glacial calotta , which is about three million years has been the size of 48 continental , it 's restreet 40 percent .
2025-05-29 10:44:22,288 - INFO - joeynmt.training - Example #1
2025-05-29 10:44:22,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:44:22,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:44:22,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho@@', 'w@@', 'ever', ',', 'this', 'sub@@', 'val@@', 'ley', 'the', 'problem', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'pres@@', 'ent', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:44:22,288 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:44:22,288 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:44:22,288 - INFO - joeynmt.training - 	Hypothesis: However , this subvalley the problem of the problem because it doesn 't show the present of the ice .
2025-05-29 10:44:22,288 - INFO - joeynmt.training - Example #2
2025-05-29 10:44:22,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:44:22,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:44:22,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ical', 'gl@@', 'aci@@', 'al', 'c@@', 'alc@@', 'ul@@', 'us', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'of', 'the', 'global', 'cli@@', 'mate', '.', '</s>']
2025-05-29 10:44:22,289 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:44:22,289 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:44:22,289 - INFO - joeynmt.training - 	Hypothesis: The artical glacial calculus is , in a sense , the clear of the global climate .
2025-05-29 10:44:22,289 - INFO - joeynmt.training - Example #3
2025-05-29 10:44:22,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:44:22,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:44:22,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'go', 'to', 'the', 'w@@', 'in@@', 'ver@@', 'n@@', 'y', 'and', 'you', 'get', 'ex@@', 'ed', '.', '</s>']
2025-05-29 10:44:22,289 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:44:22,289 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:44:22,289 - INFO - joeynmt.training - 	Hypothesis: You go to the winverny and you get exed .
2025-05-29 10:44:22,289 - INFO - joeynmt.training - Example #4
2025-05-29 10:44:22,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:44:22,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:44:22,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rapi@@', 'd', 'car@@', 'rel@@', 'ated', 'to', 'the', 'ad@@', 'v@@', 'ice', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:44:22,289 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:44:22,289 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:44:22,289 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid carrelated to the advice of the last 25 years .
2025-05-29 10:44:40,968 - INFO - joeynmt.training - Epoch   4, Step:    13600, Batch Loss:     1.679198, Batch Acc: 0.567087, Tokens per Sec:     3812, Lr: 0.000300
2025-05-29 10:44:59,195 - INFO - joeynmt.training - Epoch   4, Step:    13700, Batch Loss:     1.681494, Batch Acc: 0.564701, Tokens per Sec:     3894, Lr: 0.000300
2025-05-29 10:45:18,041 - INFO - joeynmt.training - Epoch   4, Step:    13800, Batch Loss:     1.564007, Batch Acc: 0.565686, Tokens per Sec:     3769, Lr: 0.000300
2025-05-29 10:45:37,834 - INFO - joeynmt.training - Epoch   4, Step:    13900, Batch Loss:     1.502437, Batch Acc: 0.565873, Tokens per Sec:     3626, Lr: 0.000300
2025-05-29 10:45:56,917 - INFO - joeynmt.training - Epoch   4, Step:    14000, Batch Loss:     1.507040, Batch Acc: 0.564017, Tokens per Sec:     3737, Lr: 0.000300
2025-05-29 10:45:56,919 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:45:56,919 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:46:42,128 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.58, acc:   0.53, generation: 45.2019[sec], evaluation: 0.0000[sec]
2025-05-29 10:46:42,136 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:46:42,300 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/11500.ckpt
2025-05-29 10:46:42,305 - INFO - joeynmt.training - Example #0
2025-05-29 10:46:42,305 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:46:42,305 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:46:42,305 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'these', 'these', 'sli@@', 'de', 'sli@@', 'de', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 's', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'has', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 10:46:42,305 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:46:42,305 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:46:42,305 - INFO - joeynmt.training - 	Hypothesis: I showed these these slide slide to demonstrate that the glacial calots , which for almost three million years has had the size of 48 , the size of the 48 continental .
2025-05-29 10:46:42,305 - INFO - joeynmt.training - Example #1
2025-05-29 10:46:42,305 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:46:42,305 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:46:42,305 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho@@', 'w@@', 'ever', ',', 'this', 'sub@@', 'val@@', 'u@@', 'able', ',', 'because', 'it', 'doesn', "'t", 'show', 'the', 'big', 'thing', '.', '</s>']
2025-05-29 10:46:42,305 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:46:42,305 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:46:42,305 - INFO - joeynmt.training - 	Hypothesis: However , this subvaluable , because it doesn 't show the big thing .
2025-05-29 10:46:42,305 - INFO - joeynmt.training - Example #2
2025-05-29 10:46:42,305 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:46:42,305 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:46:42,306 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ical', 'ice', 'c@@', 'alc@@', 'ul@@', 'us', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:46:42,306 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:46:42,306 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:46:42,306 - INFO - joeynmt.training - 	Hypothesis: The artical ice calculus is , in a sense , the clear heart of global climate system .
2025-05-29 10:46:42,306 - INFO - joeynmt.training - Example #3
2025-05-29 10:46:42,306 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:46:42,306 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:46:42,306 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'an@@', 'ces', '.', '</s>']
2025-05-29 10:46:42,306 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:46:42,306 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:46:42,306 - INFO - joeynmt.training - 	Hypothesis: You expances .
2025-05-29 10:46:42,306 - INFO - joeynmt.training - Example #4
2025-05-29 10:46:42,306 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:46:42,306 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:46:42,306 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rapi@@', 'd', 'car@@', 'rel@@', 'ated', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:46:42,306 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:46:42,306 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:46:42,306 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid carrelated to the last 25 years .
2025-05-29 10:47:01,201 - INFO - joeynmt.training - Epoch   4, Step:    14100, Batch Loss:     1.368984, Batch Acc: 0.572203, Tokens per Sec:     3859, Lr: 0.000300
2025-05-29 10:47:18,601 - INFO - joeynmt.training - Epoch   4, Step:    14200, Batch Loss:     1.429142, Batch Acc: 0.565273, Tokens per Sec:     3994, Lr: 0.000300
2025-05-29 10:47:35,958 - INFO - joeynmt.training - Epoch   4, Step:    14300, Batch Loss:     1.424077, Batch Acc: 0.562087, Tokens per Sec:     4033, Lr: 0.000300
2025-05-29 10:47:54,183 - INFO - joeynmt.training - Epoch   4, Step:    14400, Batch Loss:     1.423911, Batch Acc: 0.563870, Tokens per Sec:     3977, Lr: 0.000300
2025-05-29 10:48:11,984 - INFO - joeynmt.training - Epoch   4, Step:    14500, Batch Loss:     1.564614, Batch Acc: 0.565411, Tokens per Sec:     3994, Lr: 0.000300
2025-05-29 10:48:11,984 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:48:11,984 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:48:57,917 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.47, acc:   0.53, generation: 45.9255[sec], evaluation: 0.0000[sec]
2025-05-29 10:48:57,919 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:48:58,078 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/12000.ckpt
2025-05-29 10:48:58,082 - INFO - joeynmt.training - Example #0
2025-05-29 10:48:58,082 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:48:58,082 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:48:58,082 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'these', 'these', 'sli@@', 'des', 'of', 'the', 'sli@@', 'de', 'of', 'the', 'sli@@', 'de', 'of', 'the', 'pa@@', 'int@@', 'ing', 'c@@', 'alc@@', 'ul@@', 'us', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'of', 'the', 'United', 'States', 'contin@@', 'ent@@', 'al', ',', 'it', "'s", 're@@', 'mark@@', 'able', 'to', '40', 'percent', '.', '</s>']
2025-05-29 10:48:58,083 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:48:58,083 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:48:58,083 - INFO - joeynmt.training - 	Hypothesis: I showed these these slides of the slide of the slide of the painting calculus , which for almost three million years had the size of 48 million years had the size of the 48 of the United States continental , it 's remarkable to 40 percent .
2025-05-29 10:48:58,083 - INFO - joeynmt.training - Example #1
2025-05-29 10:48:58,083 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:48:58,083 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:48:58,083 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho@@', 'w@@', 'ever', 'this', 'sub@@', 'm@@', 'b', 'is', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ent', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:48:58,083 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:48:58,083 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:48:58,083 - INFO - joeynmt.training - 	Hypothesis: However this submb is the gravity of the problem because it doesn 't show the spent of the ice .
2025-05-29 10:48:58,083 - INFO - joeynmt.training - Example #2
2025-05-29 10:48:58,083 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:48:58,083 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:48:58,083 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'c@@', 'alc@@', 'ul@@', 'us', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:48:58,083 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:48:58,083 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:48:58,083 - INFO - joeynmt.training - 	Hypothesis: The arctic calculus is , in a sense , the heart of the global climate system .
2025-05-29 10:48:58,083 - INFO - joeynmt.training - Example #3
2025-05-29 10:48:58,083 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:48:58,083 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:48:58,083 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'go', 'to', 'the', 'w@@', 'in@@', 'ds', 'and', 'you', 'get', 'r@@', 'iti@@', 'z@@', 'ens', '.', '</s>']
2025-05-29 10:48:58,083 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:48:58,083 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:48:58,083 - INFO - joeynmt.training - 	Hypothesis: You go to the winds and you get ritizens .
2025-05-29 10:48:58,083 - INFO - joeynmt.training - Example #4
2025-05-29 10:48:58,084 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:48:58,084 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:48:58,084 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'f@@', 'ast', 'car@@', 'rel@@', 'ated', 'to', 'the', 'ad@@', 'v@@', 'ent', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:48:58,084 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:48:58,084 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:48:58,084 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a fast carrelated to the advent of the last 25 years .
2025-05-29 10:49:15,647 - INFO - joeynmt.training - Epoch   4, Step:    14600, Batch Loss:     1.597256, Batch Acc: 0.563937, Tokens per Sec:     4128, Lr: 0.000300
2025-05-29 10:49:33,243 - INFO - joeynmt.training - Epoch   4, Step:    14700, Batch Loss:     1.509149, Batch Acc: 0.569813, Tokens per Sec:     4115, Lr: 0.000300
2025-05-29 10:49:51,611 - INFO - joeynmt.training - Epoch   4, Step:    14800, Batch Loss:     1.631808, Batch Acc: 0.568338, Tokens per Sec:     3946, Lr: 0.000300
2025-05-29 10:50:09,143 - INFO - joeynmt.training - Epoch   4, Step:    14900, Batch Loss:     1.427147, Batch Acc: 0.567339, Tokens per Sec:     4039, Lr: 0.000300
2025-05-29 10:50:27,350 - INFO - joeynmt.training - Epoch   4, Step:    15000, Batch Loss:     1.553842, Batch Acc: 0.566457, Tokens per Sec:     3864, Lr: 0.000300
2025-05-29 10:50:27,351 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:50:27,352 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:51:16,319 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.44, acc:   0.54, generation: 48.9601[sec], evaluation: 0.0000[sec]
2025-05-29 10:51:16,322 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:51:16,575 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/12500.ckpt
2025-05-29 10:51:16,579 - INFO - joeynmt.training - Example #0
2025-05-29 10:51:16,580 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:51:16,580 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:51:16,580 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'these', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'al', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'has', 'had', 'had', 'had', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'has', 'had', 'had', 'the', 'size', 'of', '4@@', '8', '.', '</s>']
2025-05-29 10:51:16,580 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:51:16,580 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:51:16,580 - INFO - joeynmt.training - 	Hypothesis: I showed these these slides to show that the glacial calotta glacial , which for almost three million years has had had had the size of 48 million years has had had the size of 48 .
2025-05-29 10:51:16,580 - INFO - joeynmt.training - Example #1
2025-05-29 10:51:16,580 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:51:16,580 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:51:16,580 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'that', 'sub@@', 'val@@', 'ue', 'this', 'sub@@', 'val@@', 'val@@', 'u@@', 'able', ',', 'because', 'it', 'doesn', "'t", 'show', 'that', 'much', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:51:16,580 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:51:16,580 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:51:16,580 - INFO - joeynmt.training - 	Hypothesis: But that subvalue this subvalvaluable , because it doesn 't show that much of the ice .
2025-05-29 10:51:16,580 - INFO - joeynmt.training - Example #2
2025-05-29 10:51:16,580 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:51:16,580 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:51:16,580 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'co@@', 'ver@@', 'ing', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:51:16,580 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:51:16,580 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:51:16,580 - INFO - joeynmt.training - 	Hypothesis: The arctic covering is , in a sense , the heart of the global climate system .
2025-05-29 10:51:16,580 - INFO - joeynmt.training - Example #3
2025-05-29 10:51:16,581 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:51:16,581 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:51:16,581 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'and@@', 'ed', 'up', 'and', 'w@@', 'in@@', 'ds', 'of', 'the', 'sum@@', 'mer', '.', '</s>']
2025-05-29 10:51:16,581 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:51:16,581 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:51:16,581 - INFO - joeynmt.training - 	Hypothesis: You expanded up and winds of the summer .
2025-05-29 10:51:16,581 - INFO - joeynmt.training - Example #4
2025-05-29 10:51:16,581 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:51:16,581 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:51:16,581 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'rapi@@', 'd', 'car@@', 'rel@@', 'ated', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:51:16,581 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:51:16,581 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:51:16,581 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a rapid carrelated to the last 25 years .
2025-05-29 10:51:34,720 - INFO - joeynmt.training - Epoch   4, Step:    15100, Batch Loss:     1.561111, Batch Acc: 0.566084, Tokens per Sec:     3928, Lr: 0.000300
2025-05-29 10:51:52,498 - INFO - joeynmt.training - Epoch   4, Step:    15200, Batch Loss:     1.536705, Batch Acc: 0.567063, Tokens per Sec:     4041, Lr: 0.000300
2025-05-29 10:52:10,265 - INFO - joeynmt.training - Epoch   4, Step:    15300, Batch Loss:     1.448178, Batch Acc: 0.558855, Tokens per Sec:     3904, Lr: 0.000300
2025-05-29 10:52:31,133 - INFO - joeynmt.training - Epoch   4, Step:    15400, Batch Loss:     1.527012, Batch Acc: 0.572224, Tokens per Sec:     3401, Lr: 0.000300
2025-05-29 10:52:49,522 - INFO - joeynmt.training - Epoch   4, Step:    15500, Batch Loss:     1.457132, Batch Acc: 0.568921, Tokens per Sec:     3731, Lr: 0.000300
2025-05-29 10:52:49,523 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:52:49,523 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:53:32,708 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.44, acc:   0.54, generation: 43.1774[sec], evaluation: 0.0000[sec]
2025-05-29 10:53:32,859 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/13000.ckpt
2025-05-29 10:53:32,863 - INFO - joeynmt.training - Example #0
2025-05-29 10:53:32,863 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:53:32,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:53:32,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'these', 'sli@@', 'des', 'of', 'the', 'ar@@', 't@@', 'tic', 'sli@@', 'de', 'of', 'the', 'ar@@', 't@@', 't@@', 'ical', 'ar@@', 't@@', 'tic', ',', 'which', 'for', 'almost', 'three', 'million', 'years', ',', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 10:53:32,863 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:53:32,863 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:53:32,863 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these these slides of the arttic slide of the arttical arttic , which for almost three million years , had the size of the 48 continental .
2025-05-29 10:53:32,863 - INFO - joeynmt.training - Example #1
2025-05-29 10:53:32,863 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:53:32,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:53:32,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'val@@', 'ue', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ent', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:53:32,864 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:53:32,864 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:53:32,864 - INFO - joeynmt.training - 	Hypothesis: But this subvalue the gravity of the problem because it doesn 't show the spent of the ice .
2025-05-29 10:53:32,864 - INFO - joeynmt.training - Example #2
2025-05-29 10:53:32,864 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:53:32,864 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:53:32,864 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ical', 'cal@@', 'ot@@', 'h', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 's', 'is', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'cle@@', 'an', 'of', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:53:32,864 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:53:32,864 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:53:32,864 - INFO - joeynmt.training - 	Hypothesis: The artical caloth glacial calots is , in a certain sense , the clean of global climate system .
2025-05-29 10:53:32,864 - INFO - joeynmt.training - Example #3
2025-05-29 10:53:32,864 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:53:32,864 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:53:32,864 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'an@@', 'ies', 'of', 'the', 'w@@', 'int@@', 'er', 'and', 'you', 'get', 'the', 'sum@@', 'mer', '.', '</s>']
2025-05-29 10:53:32,864 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:53:32,864 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:53:32,864 - INFO - joeynmt.training - 	Hypothesis: You expanies of the winter and you get the summer .
2025-05-29 10:53:32,864 - INFO - joeynmt.training - Example #4
2025-05-29 10:53:32,864 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:53:32,864 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:53:32,864 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'rapi@@', 'd@@', 'ly', 'car@@', 'rel@@', 'ated', 'to', 'the', 'ad@@', 'v@@', 'ents', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:53:32,864 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:53:32,864 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:53:32,864 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a rapidly carrelated to the advents of the last 25 years .
2025-05-29 10:53:50,966 - INFO - joeynmt.training - Epoch   4, Step:    15600, Batch Loss:     1.485319, Batch Acc: 0.569284, Tokens per Sec:     3798, Lr: 0.000300
2025-05-29 10:54:08,904 - INFO - joeynmt.training - Epoch   4, Step:    15700, Batch Loss:     1.537569, Batch Acc: 0.567590, Tokens per Sec:     3978, Lr: 0.000300
2025-05-29 10:54:27,022 - INFO - joeynmt.training - Epoch   4, Step:    15800, Batch Loss:     1.773759, Batch Acc: 0.567430, Tokens per Sec:     3935, Lr: 0.000300
2025-05-29 10:54:44,322 - INFO - joeynmt.training - Epoch   4, Step:    15900, Batch Loss:     1.600123, Batch Acc: 0.572358, Tokens per Sec:     4220, Lr: 0.000300
2025-05-29 10:55:02,300 - INFO - joeynmt.training - Epoch   4, Step:    16000, Batch Loss:     1.813986, Batch Acc: 0.570517, Tokens per Sec:     4089, Lr: 0.000300
2025-05-29 10:55:02,301 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:55:02,302 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:55:45,023 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.38, acc:   0.54, generation: 42.7144[sec], evaluation: 0.0000[sec]
2025-05-29 10:55:45,026 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:55:45,191 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/13500.ckpt
2025-05-29 10:55:45,195 - INFO - joeynmt.training - Example #0
2025-05-29 10:55:45,195 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:55:45,196 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:55:45,196 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', "'ve", 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ical', 'c@@', 'alc@@', 'ul@@', 'ations', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 10:55:45,196 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:55:45,196 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:55:45,196 - INFO - joeynmt.training - 	Hypothesis: I 've showed these slides to demonstrate that the glacial calottical calculations , which for almost three million years had the size of the 48 continental .
2025-05-29 10:55:45,196 - INFO - joeynmt.training - Example #1
2025-05-29 10:55:45,196 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:55:45,196 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:55:45,196 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'water', 'under@@', 'val@@', 'ue', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ess@@', 'or', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:55:45,196 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:55:45,196 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:55:45,196 - INFO - joeynmt.training - 	Hypothesis: But this underwater undervalue the gravity of the problem because it doesn 't show the spessor of the ice .
2025-05-29 10:55:45,197 - INFO - joeynmt.training - Example #2
2025-05-29 10:55:45,197 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:55:45,197 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:55:45,197 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'gl@@', 'aci@@', 'al', 'c@@', 'alc@@', 'ul@@', 'ation', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ite', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:55:45,197 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:55:45,197 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:55:45,197 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial calculation is , in a sense , the pite heart of the global climate system .
2025-05-29 10:55:45,197 - INFO - joeynmt.training - Example #3
2025-05-29 10:55:45,197 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:55:45,197 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:55:45,197 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'exp@@', 'an@@', 'ded', 'by', 'ex@@', 'tre@@', 'me', 'and', 'ex@@', 'tre@@', 'me', '.', '</s>']
2025-05-29 10:55:45,197 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:55:45,197 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:55:45,197 - INFO - joeynmt.training - 	Hypothesis: It 's expanded by extreme and extreme .
2025-05-29 10:55:45,197 - INFO - joeynmt.training - Example #4
2025-05-29 10:55:45,197 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:55:45,197 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:55:45,197 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'qu@@', 'ick', 'car@@', 'rel@@', 'ated', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:55:45,197 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:55:45,197 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:55:45,197 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quick carrelated to the last 25 years .
2025-05-29 10:56:02,336 - INFO - joeynmt.training - Epoch   4, Step:    16100, Batch Loss:     1.743984, Batch Acc: 0.574112, Tokens per Sec:     4035, Lr: 0.000300
2025-05-29 10:56:19,908 - INFO - joeynmt.training - Epoch   4, Step:    16200, Batch Loss:     1.735393, Batch Acc: 0.570102, Tokens per Sec:     4010, Lr: 0.000300
2025-05-29 10:56:38,182 - INFO - joeynmt.training - Epoch   4, Step:    16300, Batch Loss:     1.578702, Batch Acc: 0.571028, Tokens per Sec:     3903, Lr: 0.000300
2025-05-29 10:56:40,539 - INFO - joeynmt.training - Epoch   4: total training loss 6357.52
2025-05-29 10:56:40,539 - INFO - joeynmt.training - EPOCH 5
2025-05-29 10:56:54,951 - INFO - joeynmt.training - Epoch   5, Step:    16400, Batch Loss:     1.308674, Batch Acc: 0.591528, Tokens per Sec:     4213, Lr: 0.000300
2025-05-29 10:57:11,849 - INFO - joeynmt.training - Epoch   5, Step:    16500, Batch Loss:     1.536012, Batch Acc: 0.592036, Tokens per Sec:     4118, Lr: 0.000300
2025-05-29 10:57:11,850 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:57:11,851 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 10:57:53,981 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.38, acc:   0.54, generation: 42.1226[sec], evaluation: 0.0000[sec]
2025-05-29 10:57:53,983 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 10:57:54,133 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/14000.ckpt
2025-05-29 10:57:54,136 - INFO - joeynmt.training - Example #0
2025-05-29 10:57:54,136 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 10:57:54,136 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 10:57:54,136 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'last', 'year', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'de', 'sli@@', 'de', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ical', 'c@@', 'alc@@', 'ul@@', 'ation', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 10:57:54,136 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 10:57:54,136 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 10:57:54,136 - INFO - joeynmt.training - 	Hypothesis: The last year I showed these slide slide to show that the glacial calottical calculation , which is almost three million years had the size of the 48 continental .
2025-05-29 10:57:54,136 - INFO - joeynmt.training - Example #1
2025-05-29 10:57:54,136 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 10:57:54,136 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 10:57:54,136 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', "'s", 'a', 'lot', 'of', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ent', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 10:57:54,136 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 10:57:54,136 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 10:57:54,136 - INFO - joeynmt.training - 	Hypothesis: But it 's a lot of the gravity of the problem because it doesn 't show the spent of the ice .
2025-05-29 10:57:54,136 - INFO - joeynmt.training - Example #2
2025-05-29 10:57:54,137 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 10:57:54,137 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 10:57:54,137 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ical', 'cal@@', 'ot@@', 'h', 'is', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'pul@@', 's@@', '-@@', 'global', 'cu@@', 'mate', 'system', '.', '</s>']
2025-05-29 10:57:54,137 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 10:57:54,137 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 10:57:54,137 - INFO - joeynmt.training - 	Hypothesis: The artical caloth is , in a certain sense , the puls-global cumate system .
2025-05-29 10:57:54,137 - INFO - joeynmt.training - Example #3
2025-05-29 10:57:54,137 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 10:57:54,137 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 10:57:54,137 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'w@@', 'in@@', 'ver@@', 'n@@', 'ice', 'and', 're@@', 'ti@@', 'red', 'of', 'the', 'sum@@', 'mer', '.', '</s>']
2025-05-29 10:57:54,137 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 10:57:54,137 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 10:57:54,137 - INFO - joeynmt.training - 	Hypothesis: It 's winvernice and retired of the summer .
2025-05-29 10:57:54,137 - INFO - joeynmt.training - Example #4
2025-05-29 10:57:54,137 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 10:57:54,137 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 10:57:54,137 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rapi@@', 'd', 'car@@', 'rel@@', 'ated', 'to', 'the', 'ad@@', 'v@@', 'ent', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 10:57:54,137 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 10:57:54,137 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 10:57:54,137 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid carrelated to the advent of the last 25 years .
2025-05-29 10:58:11,780 - INFO - joeynmt.training - Epoch   5, Step:    16600, Batch Loss:     1.595903, Batch Acc: 0.589999, Tokens per Sec:     3952, Lr: 0.000300
2025-05-29 10:58:29,634 - INFO - joeynmt.training - Epoch   5, Step:    16700, Batch Loss:     1.349387, Batch Acc: 0.591117, Tokens per Sec:     4013, Lr: 0.000300
2025-05-29 10:58:47,504 - INFO - joeynmt.training - Epoch   5, Step:    16800, Batch Loss:     1.432165, Batch Acc: 0.588793, Tokens per Sec:     4080, Lr: 0.000300
2025-05-29 10:59:04,825 - INFO - joeynmt.training - Epoch   5, Step:    16900, Batch Loss:     1.585841, Batch Acc: 0.587907, Tokens per Sec:     4095, Lr: 0.000300
2025-05-29 10:59:22,522 - INFO - joeynmt.training - Epoch   5, Step:    17000, Batch Loss:     1.297654, Batch Acc: 0.591651, Tokens per Sec:     3945, Lr: 0.000300
2025-05-29 10:59:22,522 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 10:59:22,522 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:00:12,483 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.35, acc:   0.54, generation: 49.9492[sec], evaluation: 0.0000[sec]
2025-05-29 11:00:12,485 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 11:00:12,663 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/14500.ckpt
2025-05-29 11:00:12,666 - INFO - joeynmt.training - Example #0
2025-05-29 11:00:12,666 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:00:12,666 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:00:12,666 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'these', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'so@@', 'und', 'cal@@', 'ot@@', 'ter', ',', 'which', 'is', 'so', 'much', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', 'ar@@', 't@@', 'ical', 'ar@@', 't@@', 'ical', ',', 'which', 'is', 're@@', 'mark@@', 'able', 'to', 'the', 'United', 'States', ',', 'it', "'s", 're@@', 'stre@@', 't@@', 'ched', '40', 'percent', '.', '</s>']
2025-05-29 11:00:12,667 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:00:12,667 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:00:12,667 - INFO - joeynmt.training - 	Hypothesis: I showed these these slides to show that the sound calotter , which is so much three million years had the size of the artical artical , which is remarkable to the United States , it 's restretched 40 percent .
2025-05-29 11:00:12,667 - INFO - joeynmt.training - Example #1
2025-05-29 11:00:12,667 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:00:12,667 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:00:12,667 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'val@@', 'u@@', 'able', ',', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ess@@', 'or', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:00:12,667 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:00:12,667 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:00:12,667 - INFO - joeynmt.training - 	Hypothesis: But this subvaluable , the gravity of the problem because it doesn 't show the spessor of the ice .
2025-05-29 11:00:12,667 - INFO - joeynmt.training - Example #2
2025-05-29 11:00:12,667 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:00:12,667 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:00:12,667 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ical', 'cal@@', 'ot@@', 'h', 'c@@', 'alc@@', 'ul@@', 'ation', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:00:12,667 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:00:12,667 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:00:12,667 - INFO - joeynmt.training - 	Hypothesis: The artical caloth calculation is , in a sense , the clear heart of the global climate system .
2025-05-29 11:00:12,667 - INFO - joeynmt.training - Example #3
2025-05-29 11:00:12,667 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:00:12,667 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:00:12,667 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'go', 'to', 'the', 'w@@', 'int@@', 'er', 'and', 'you', 'get', 'ex@@', 'tre@@', 'me', 'of', 'the', 'w@@', 'int@@', 'er', '.', '</s>']
2025-05-29 11:00:12,668 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:00:12,668 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:00:12,668 - INFO - joeynmt.training - 	Hypothesis: You go to the winter and you get extreme of the winter .
2025-05-29 11:00:12,668 - INFO - joeynmt.training - Example #4
2025-05-29 11:00:12,668 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:00:12,668 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:00:12,668 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'rel@@', 'ated', 'to', 'the', 'ad@@', 'v@@', 'est@@', 'im@@', 'ents', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:00:12,668 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:00:12,668 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:00:12,668 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick carrelated to the advestiments of the last 25 years .
2025-05-29 11:00:33,477 - INFO - joeynmt.training - Epoch   5, Step:    17100, Batch Loss:     1.451708, Batch Acc: 0.589001, Tokens per Sec:     3421, Lr: 0.000300
2025-05-29 11:00:52,746 - INFO - joeynmt.training - Epoch   5, Step:    17200, Batch Loss:     1.760134, Batch Acc: 0.588805, Tokens per Sec:     3690, Lr: 0.000300
2025-05-29 11:01:10,667 - INFO - joeynmt.training - Epoch   5, Step:    17300, Batch Loss:     1.491041, Batch Acc: 0.582089, Tokens per Sec:     3857, Lr: 0.000300
2025-05-29 11:01:28,940 - INFO - joeynmt.training - Epoch   5, Step:    17400, Batch Loss:     1.366905, Batch Acc: 0.584026, Tokens per Sec:     3896, Lr: 0.000300
2025-05-29 11:01:46,396 - INFO - joeynmt.training - Epoch   5, Step:    17500, Batch Loss:     1.454376, Batch Acc: 0.585999, Tokens per Sec:     3946, Lr: 0.000300
2025-05-29 11:01:46,396 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:01:46,396 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:02:29,020 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.34, acc:   0.54, generation: 42.6169[sec], evaluation: 0.0000[sec]
2025-05-29 11:02:29,023 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 11:02:29,182 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/15500.ckpt
2025-05-29 11:02:29,185 - INFO - joeynmt.training - Example #0
2025-05-29 11:02:29,185 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:02:29,185 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:02:29,185 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'ta', ',', 'which', 'is', 'about', 'three', 'million', 'years', 'has', 'had', 'the', 'size', 'of', 'the', '4@@', '8', ',', 'in', 'the', 'contin@@', 'ent@@', 'al', ',', 'is', 'about', '40', 'percent', '.', '</s>']
2025-05-29 11:02:29,186 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:02:29,186 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:02:29,186 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the glacial calotta , which is about three million years has had the size of the 48 , in the continental , is about 40 percent .
2025-05-29 11:02:29,186 - INFO - joeynmt.training - Example #1
2025-05-29 11:02:29,186 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:02:29,186 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:02:29,186 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'val@@', 'ley', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ent', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ent', 'the', 'p@@', 'ath', '.', '</s>']
2025-05-29 11:02:29,186 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:02:29,186 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:02:29,186 - INFO - joeynmt.training - 	Hypothesis: But this subvalley the gravity of the problem because it doesn 't show the spent of the problem because it doesn 't show the spent the path .
2025-05-29 11:02:29,186 - INFO - joeynmt.training - Example #2
2025-05-29 11:02:29,186 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:02:29,186 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:02:29,186 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ical', 'cal@@', 'ot@@', 'ta', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', ',', 'the', 'cle@@', 'an', 'of', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:02:29,186 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:02:29,186 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:02:29,186 - INFO - joeynmt.training - 	Hypothesis: The artical calotta is , in a sense , the clean , the clean of global climate system .
2025-05-29 11:02:29,186 - INFO - joeynmt.training - Example #3
2025-05-29 11:02:29,186 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:02:29,186 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:02:29,186 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'an@@', 'ies', '.', '</s>']
2025-05-29 11:02:29,186 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:02:29,186 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:02:29,186 - INFO - joeynmt.training - 	Hypothesis: You expanies .
2025-05-29 11:02:29,186 - INFO - joeynmt.training - Example #4
2025-05-29 11:02:29,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:02:29,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:02:29,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'rapi@@', 'd', 'car@@', 'rel@@', 'ated', 'to', 'the', 'ad@@', 'v@@', 'ent', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:02:29,187 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:02:29,187 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:02:29,187 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a rapid carrelated to the advent of the last 25 years .
2025-05-29 11:02:46,008 - INFO - joeynmt.training - Epoch   5, Step:    17600, Batch Loss:     1.410539, Batch Acc: 0.586073, Tokens per Sec:     4330, Lr: 0.000300
2025-05-29 11:03:02,853 - INFO - joeynmt.training - Epoch   5, Step:    17700, Batch Loss:     1.339442, Batch Acc: 0.584271, Tokens per Sec:     4089, Lr: 0.000300
2025-05-29 11:03:19,772 - INFO - joeynmt.training - Epoch   5, Step:    17800, Batch Loss:     1.317896, Batch Acc: 0.582883, Tokens per Sec:     4299, Lr: 0.000300
2025-05-29 11:03:36,423 - INFO - joeynmt.training - Epoch   5, Step:    17900, Batch Loss:     1.493668, Batch Acc: 0.585748, Tokens per Sec:     4394, Lr: 0.000300
2025-05-29 11:03:53,766 - INFO - joeynmt.training - Epoch   5, Step:    18000, Batch Loss:     1.394427, Batch Acc: 0.583886, Tokens per Sec:     4150, Lr: 0.000300
2025-05-29 11:03:53,767 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:03:53,767 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:04:33,762 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.27, acc:   0.54, generation: 39.9873[sec], evaluation: 0.0000[sec]
2025-05-29 11:04:33,764 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 11:04:33,917 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/15000.ckpt
2025-05-29 11:04:33,919 - INFO - joeynmt.training - Example #0
2025-05-29 11:04:33,919 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:04:33,919 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:04:33,919 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'de', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ica', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 11:04:33,919 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:04:33,919 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:04:33,919 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slide to show that the glacial calottica , which for almost three million years had the size of the 48 size of the 48 continental .
2025-05-29 11:04:33,919 - INFO - joeynmt.training - Example #1
2025-05-29 11:04:33,919 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:04:33,919 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:04:33,919 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'ject', 'of', 'the', 'problem', 'of', 'the', 'problem', 'because', 'it', "'s", 'not', 'the', 'sh@@', 'ape', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:04:33,919 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:04:33,919 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:04:33,919 - INFO - joeynmt.training - 	Hypothesis: But this subject of the problem of the problem because it 's not the shape of the ice .
2025-05-29 11:04:33,919 - INFO - joeynmt.training - Example #2
2025-05-29 11:04:33,919 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:04:33,919 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:04:33,919 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ical', 'ice', 'ice', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:04:33,920 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:04:33,920 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:04:33,920 - INFO - joeynmt.training - 	Hypothesis: The artical ice ice ice is , in a sense , the clear of the global climate system .
2025-05-29 11:04:33,920 - INFO - joeynmt.training - Example #3
2025-05-29 11:04:33,920 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:04:33,920 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:04:33,920 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', "'re", 'exp@@', 'and@@', 'ed', 'up', 'and', 'you', 're@@', 'tre@@', 'at', 'the', 'w@@', 'int@@', 'er', '.', '</s>']
2025-05-29 11:04:33,920 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:04:33,920 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:04:33,920 - INFO - joeynmt.training - 	Hypothesis: You 're expanded up and you retreat the winter .
2025-05-29 11:04:33,920 - INFO - joeynmt.training - Example #4
2025-05-29 11:04:33,920 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:04:33,920 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:04:33,920 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'qu@@', 'ick', ',', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'rel@@', 'ated', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:04:33,920 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:04:33,920 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:04:33,920 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quick , is going to be a quick related to the last 25 years .
2025-05-29 11:04:51,843 - INFO - joeynmt.training - Epoch   5, Step:    18100, Batch Loss:     1.563668, Batch Acc: 0.590882, Tokens per Sec:     3933, Lr: 0.000300
2025-05-29 11:05:10,897 - INFO - joeynmt.training - Epoch   5, Step:    18200, Batch Loss:     1.627736, Batch Acc: 0.581908, Tokens per Sec:     3769, Lr: 0.000300
2025-05-29 11:05:28,732 - INFO - joeynmt.training - Epoch   5, Step:    18300, Batch Loss:     1.171695, Batch Acc: 0.589230, Tokens per Sec:     4054, Lr: 0.000300
2025-05-29 11:05:46,985 - INFO - joeynmt.training - Epoch   5, Step:    18400, Batch Loss:     1.292894, Batch Acc: 0.585077, Tokens per Sec:     3890, Lr: 0.000300
2025-05-29 11:06:05,328 - INFO - joeynmt.training - Epoch   5, Step:    18500, Batch Loss:     1.380655, Batch Acc: 0.577194, Tokens per Sec:     3898, Lr: 0.000300
2025-05-29 11:06:05,331 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:06:05,331 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:06:48,798 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.26, acc:   0.55, generation: 43.4592[sec], evaluation: 0.0000[sec]
2025-05-29 11:06:48,800 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 11:06:48,970 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/16000.ckpt
2025-05-29 11:06:48,972 - INFO - joeynmt.training - Example #0
2025-05-29 11:06:48,972 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:06:48,972 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:06:48,972 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'these', 'sli@@', 'de', 'to', 'show', 'that', 'the', 'cal@@', 'ot@@', 't@@', 'ical', 'cal@@', 'ot@@', 't@@', 'ical', 'c@@', 'alc@@', 'ul@@', 'ations', ',', 'which', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'size', 'of', '4@@', '8', 'United', 'States', 'contin@@', 'ent@@', 'al', ',', 'is', 're@@', 'stre@@', 't', '40', 'percent', '.', '</s>']
2025-05-29 11:06:48,972 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:06:48,972 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:06:48,972 - INFO - joeynmt.training - 	Hypothesis: I showed these slide to show that the calottical calottical calculations , which almost three million years had the size of 48 , the size of 48 United States continental , is restret 40 percent .
2025-05-29 11:06:48,972 - INFO - joeynmt.training - Example #1
2025-05-29 11:06:48,973 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:06:48,973 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:06:48,973 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho@@', 'w@@', 'ever', ',', 'this', 'sub@@', 'val@@', 'ley', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:06:48,973 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:06:48,973 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:06:48,973 - INFO - joeynmt.training - 	Hypothesis: However , this subvalley the gravity of the problem because it doesn 't show the ice of the ice .
2025-05-29 11:06:48,973 - INFO - joeynmt.training - Example #2
2025-05-29 11:06:48,973 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:06:48,973 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:06:48,973 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'is', ',', 'in', 'a', 'sense', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:06:48,973 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:06:48,973 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:06:48,973 - INFO - joeynmt.training - 	Hypothesis: The artica is , in a sense , in a sense , the clear of the global climate system .
2025-05-29 11:06:48,973 - INFO - joeynmt.training - Example #3
2025-05-29 11:06:48,973 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:06:48,973 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:06:48,973 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'can', 'exp@@', 'an@@', 'ding', 'w@@', 'in@@', 'ver@@', 'n@@', 'y', 'and', 'ex@@', 'tre@@', 'me', 'ex@@', 'tre@@', 'me', '.', '</s>']
2025-05-29 11:06:48,973 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:06:48,973 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:06:48,973 - INFO - joeynmt.training - 	Hypothesis: You can expanding winverny and extreme extreme .
2025-05-29 11:06:48,973 - INFO - joeynmt.training - Example #4
2025-05-29 11:06:48,973 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:06:48,973 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:06:48,973 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', ',', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'rel@@', 'ated', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:06:48,974 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:06:48,974 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:06:48,974 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick , is going to be a quick carrelated to the last 25 years .
2025-05-29 11:07:06,785 - INFO - joeynmt.training - Epoch   5, Step:    18600, Batch Loss:     1.554757, Batch Acc: 0.581529, Tokens per Sec:     3964, Lr: 0.000300
2025-05-29 11:07:24,425 - INFO - joeynmt.training - Epoch   5, Step:    18700, Batch Loss:     1.346921, Batch Acc: 0.590134, Tokens per Sec:     3983, Lr: 0.000300
2025-05-29 11:07:42,927 - INFO - joeynmt.training - Epoch   5, Step:    18800, Batch Loss:     1.420374, Batch Acc: 0.583608, Tokens per Sec:     3881, Lr: 0.000300
2025-05-29 11:08:01,406 - INFO - joeynmt.training - Epoch   5, Step:    18900, Batch Loss:     1.432383, Batch Acc: 0.584726, Tokens per Sec:     3842, Lr: 0.000300
2025-05-29 11:08:19,753 - INFO - joeynmt.training - Epoch   5, Step:    19000, Batch Loss:     1.590545, Batch Acc: 0.579985, Tokens per Sec:     3892, Lr: 0.000300
2025-05-29 11:08:19,754 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:08:19,754 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:09:01,216 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.24, acc:   0.55, generation: 41.4547[sec], evaluation: 0.0000[sec]
2025-05-29 11:09:01,218 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 11:09:01,378 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/16500.ckpt
2025-05-29 11:09:01,380 - INFO - joeynmt.training - Example #0
2025-05-29 11:09:01,380 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:09:01,380 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:09:01,380 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'these', 'these', 'these', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'so@@', 'und', 'cal@@', 'ot@@', 's', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'dimen@@', 'sions', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', 'dimen@@', 'sions', ',', 'is', 're@@', 'mark@@', 'able', '.', '</s>']
2025-05-29 11:09:01,380 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:09:01,380 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:09:01,380 - INFO - joeynmt.training - 	Hypothesis: I showed these these these slides to demonstrate that the sound calots , which for almost three million years had the size of the 48 dimensions of the 48 continental dimensions , is remarkable .
2025-05-29 11:09:01,380 - INFO - joeynmt.training - Example #1
2025-05-29 11:09:01,380 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:09:01,380 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:09:01,380 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho@@', 'w@@', 'ever', ',', 'this', 'sub@@', 'val@@', 'u@@', 'able', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'end@@', 'ing', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:09:01,381 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:09:01,381 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:09:01,381 - INFO - joeynmt.training - 	Hypothesis: However , this subvaluable of the problem because it doesn 't show the spending of the ice .
2025-05-29 11:09:01,381 - INFO - joeynmt.training - Example #2
2025-05-29 11:09:01,381 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:09:01,381 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:09:01,381 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'so@@', 'und', 'cal@@', 'ot@@', 's', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', ',', 'the', 'cle@@', 'an', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:09:01,381 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:09:01,381 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:09:01,381 - INFO - joeynmt.training - 	Hypothesis: The arctic sound calots is , in a sense , the clean , the clean of the global climate system .
2025-05-29 11:09:01,381 - INFO - joeynmt.training - Example #3
2025-05-29 11:09:01,381 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:09:01,381 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:09:01,381 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'and@@', 'ed', 'up', 'w@@', 'int@@', 'er', 'and', 'r@@', 'iti@@', 'ra', 'of', 'ex@@', 'tre@@', 'me', '.', '</s>']
2025-05-29 11:09:01,381 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:09:01,381 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:09:01,381 - INFO - joeynmt.training - 	Hypothesis: You expanded up winter and ritira of extreme .
2025-05-29 11:09:01,381 - INFO - joeynmt.training - Example #4
2025-05-29 11:09:01,381 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:09:01,381 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:09:01,381 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'qu@@', 'ick', 'car@@', 'rel@@', 'ated', 'to', 'the', 'ad@@', 'v@@', 'ant@@', 'age', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:09:01,381 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:09:01,381 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:09:01,381 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quick carrelated to the advantage of the last 25 years .
2025-05-29 11:09:19,530 - INFO - joeynmt.training - Epoch   5, Step:    19100, Batch Loss:     1.488126, Batch Acc: 0.580161, Tokens per Sec:     3839, Lr: 0.000300
2025-05-29 11:09:39,416 - INFO - joeynmt.training - Epoch   5, Step:    19200, Batch Loss:     1.362703, Batch Acc: 0.580814, Tokens per Sec:     3596, Lr: 0.000300
2025-05-29 11:09:59,843 - INFO - joeynmt.training - Epoch   5, Step:    19300, Batch Loss:     1.544670, Batch Acc: 0.581705, Tokens per Sec:     3515, Lr: 0.000300
2025-05-29 11:10:21,368 - INFO - joeynmt.training - Epoch   5, Step:    19400, Batch Loss:     1.514955, Batch Acc: 0.583268, Tokens per Sec:     3304, Lr: 0.000300
2025-05-29 11:10:40,680 - INFO - joeynmt.training - Epoch   5, Step:    19500, Batch Loss:     1.617540, Batch Acc: 0.581723, Tokens per Sec:     3640, Lr: 0.000300
2025-05-29 11:10:40,681 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:10:40,681 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:11:22,252 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.23, acc:   0.55, generation: 41.5600[sec], evaluation: 0.0000[sec]
2025-05-29 11:11:22,254 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 11:11:22,402 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/17000.ckpt
2025-05-29 11:11:22,406 - INFO - joeynmt.training - Example #0
2025-05-29 11:11:22,406 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:11:22,406 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:11:22,406 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ho@@', 't', 'ho@@', 'ot@@', 't@@', 'ical', 'ice', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'percent', '.', '</s>']
2025-05-29 11:11:22,406 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:11:22,406 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:11:22,406 - INFO - joeynmt.training - 	Hypothesis: I showed these slides to demonstrate that the hot hoottical ice , which for almost three million years had the size of the 48 million years had the size of 48 million years had the size of 48 percent .
2025-05-29 11:11:22,406 - INFO - joeynmt.training - Example #1
2025-05-29 11:11:22,406 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:11:22,406 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:11:22,406 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'val@@', 'ue', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ess@@', 'or', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:11:22,406 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:11:22,406 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:11:22,406 - INFO - joeynmt.training - 	Hypothesis: But this subvalue of the problem because it doesn 't show the gravity of the problem because it doesn 't show the spessor of the ice .
2025-05-29 11:11:22,406 - INFO - joeynmt.training - Example #2
2025-05-29 11:11:22,406 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:11:22,406 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:11:22,406 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 's', 'is', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'cle@@', 'an', ',', 'the', 'pul@@', 's@@', '-@@', 'up', 'of', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:11:22,407 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:11:22,407 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:11:22,407 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial calots is , in a certain sense , the clean , the puls-up of global climate system .
2025-05-29 11:11:22,407 - INFO - joeynmt.training - Example #3
2025-05-29 11:11:22,407 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:11:22,407 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:11:22,407 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', "'re", 'exp@@', 'and@@', 'ed', 'to', 'the', 'w@@', 'in@@', 'ds', 'and', 'you', 'get', 'sum@@', 'mer', '.', '</s>']
2025-05-29 11:11:22,407 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:11:22,407 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:11:22,407 - INFO - joeynmt.training - 	Hypothesis: You 're expanded to the winds and you get summer .
2025-05-29 11:11:22,407 - INFO - joeynmt.training - Example #4
2025-05-29 11:11:22,407 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:11:22,407 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:11:22,407 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'rel@@', 'ed', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:11:22,407 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:11:22,407 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:11:22,407 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick carreled to the last 25 years .
2025-05-29 11:11:40,452 - INFO - joeynmt.training - Epoch   5, Step:    19600, Batch Loss:     1.603160, Batch Acc: 0.581677, Tokens per Sec:     3860, Lr: 0.000300
2025-05-29 11:11:58,019 - INFO - joeynmt.training - Epoch   5, Step:    19700, Batch Loss:     1.490560, Batch Acc: 0.582033, Tokens per Sec:     4118, Lr: 0.000300
2025-05-29 11:12:20,448 - INFO - joeynmt.training - Epoch   5, Step:    19800, Batch Loss:     1.430775, Batch Acc: 0.586384, Tokens per Sec:     3167, Lr: 0.000300
2025-05-29 11:12:43,402 - INFO - joeynmt.training - Epoch   5, Step:    19900, Batch Loss:     1.490852, Batch Acc: 0.587999, Tokens per Sec:     3089, Lr: 0.000300
2025-05-29 11:13:04,981 - INFO - joeynmt.training - Epoch   5, Step:    20000, Batch Loss:     1.410130, Batch Acc: 0.579655, Tokens per Sec:     3264, Lr: 0.000300
2025-05-29 11:13:04,982 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:13:04,982 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:14:09,253 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.20, acc:   0.55, generation: 64.2614[sec], evaluation: 0.0000[sec]
2025-05-29 11:14:09,255 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 11:14:09,429 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/17500.ckpt
2025-05-29 11:14:09,431 - INFO - joeynmt.training - Example #0
2025-05-29 11:14:09,431 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:14:09,431 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:14:09,431 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'these', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ar@@', 't@@', 'ics', ',', 'that', 'for', 'almost', 'three', 'million', 'years', ',', 'had', 'the', '4@@', '8', ',', 'for', 'almost', 'three', 'million', 'years', ',', 'had', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', 'dimen@@', 'sions', 'of', 'the', '4@@', '8', '.', '</s>']
2025-05-29 11:14:09,432 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:14:09,432 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:14:09,432 - INFO - joeynmt.training - 	Hypothesis: I showed these these slides to show that the glacial calottartics , that for almost three million years , had the 48 , for almost three million years , had the 48 continental dimensions of the 48 .
2025-05-29 11:14:09,432 - INFO - joeynmt.training - Example #1
2025-05-29 11:14:09,432 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:14:09,432 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:14:09,432 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'grad@@', 'u@@', 'ate', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'ro@@', 'om@@', 's', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:14:09,432 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:14:09,432 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:14:09,432 - INFO - joeynmt.training - 	Hypothesis: But this undergraduate gravity of the problem because it doesn 't show the rooms of the ice .
2025-05-29 11:14:09,432 - INFO - joeynmt.training - Example #2
2025-05-29 11:14:09,432 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:14:09,432 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:14:09,432 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'ho@@', 'ot@@', 'age', 'cal@@', 'ot@@', 'ta', 'is', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'cle@@', 'an', ',', 'the', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:14:09,432 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:14:09,432 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:14:09,432 - INFO - joeynmt.training - 	Hypothesis: The arctic hootage calotta is , in a certain sense , the clean , the heart of the global climate system .
2025-05-29 11:14:09,432 - INFO - joeynmt.training - Example #3
2025-05-29 11:14:09,432 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:14:09,432 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:14:09,432 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'and@@', 'd', 'to', 'the', 'w@@', 'in@@', 'ds', 'and', 'the', 'sum@@', 'mer', '.', '</s>']
2025-05-29 11:14:09,433 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:14:09,433 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:14:09,433 - INFO - joeynmt.training - 	Hypothesis: You expandd to the winds and the summer .
2025-05-29 11:14:09,433 - INFO - joeynmt.training - Example #4
2025-05-29 11:14:09,433 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:14:09,433 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:14:09,433 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'rapi@@', 'd', 'car@@', 'rel@@', 'ated', 'to', 'the', 'de@@', 'ad', 'rel@@', 'ated', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:14:09,433 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:14:09,433 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:14:09,433 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a rapid carrelated to the dead related to the last 25 years .
2025-05-29 11:14:29,117 - INFO - joeynmt.training - Epoch   5, Step:    20100, Batch Loss:     1.561308, Batch Acc: 0.578864, Tokens per Sec:     3574, Lr: 0.000300
2025-05-29 11:14:48,180 - INFO - joeynmt.training - Epoch   5, Step:    20200, Batch Loss:     1.283411, Batch Acc: 0.583858, Tokens per Sec:     3768, Lr: 0.000300
2025-05-29 11:15:07,382 - INFO - joeynmt.training - Epoch   5, Step:    20300, Batch Loss:     1.639424, Batch Acc: 0.582199, Tokens per Sec:     3690, Lr: 0.000300
2025-05-29 11:15:26,392 - INFO - joeynmt.training - Epoch   5: total training loss 6071.45
2025-05-29 11:15:26,393 - INFO - joeynmt.training - EPOCH 6
2025-05-29 11:15:26,748 - INFO - joeynmt.training - Epoch   6, Step:    20400, Batch Loss:     1.399622, Batch Acc: 0.593927, Tokens per Sec:     4002, Lr: 0.000300
2025-05-29 11:15:45,926 - INFO - joeynmt.training - Epoch   6, Step:    20500, Batch Loss:     1.280450, Batch Acc: 0.605229, Tokens per Sec:     3690, Lr: 0.000300
2025-05-29 11:15:45,927 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:15:45,927 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:16:27,387 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.16, acc:   0.55, generation: 41.4511[sec], evaluation: 0.0000[sec]
2025-05-29 11:16:27,389 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 11:16:27,573 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/18000.ckpt
2025-05-29 11:16:27,575 - INFO - joeynmt.training - Example #0
2025-05-29 11:16:27,575 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:16:27,575 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:16:27,575 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ar@@', 't@@', 'ics', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', '.', '</s>']
2025-05-29 11:16:27,576 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:16:27,576 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:16:27,576 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these these slides to show that the glacial calottartics , which is almost three million years had the size of 48 million years had the size of 48 .
2025-05-29 11:16:27,576 - INFO - joeynmt.training - Example #1
2025-05-29 11:16:27,576 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:16:27,576 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:16:27,576 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'l@@', 'ying', 'under@@', 'l@@', 'ying', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'I', 'don', "'t", 'show', 'the', 'sp@@', 'end@@', 'ing', 'of', 'ice', '.', '</s>']
2025-05-29 11:16:27,576 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:16:27,576 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:16:27,576 - INFO - joeynmt.training - 	Hypothesis: But this underlying underlying the gravity of the problem because I don 't show the spending of ice .
2025-05-29 11:16:27,576 - INFO - joeynmt.training - Example #2
2025-05-29 11:16:27,576 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:16:27,576 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:16:27,576 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'age', 'is', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'cle@@', 'ar', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:16:27,576 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:16:27,576 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:16:27,576 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial calotage is , in a certain sense , the clear of the global climate system .
2025-05-29 11:16:27,576 - INFO - joeynmt.training - Example #3
2025-05-29 11:16:27,576 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:16:27,576 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:16:27,576 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'an@@', 'ies', '.', '</s>']
2025-05-29 11:16:27,576 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:16:27,577 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:16:27,577 - INFO - joeynmt.training - 	Hypothesis: You expanies .
2025-05-29 11:16:27,577 - INFO - joeynmt.training - Example #4
2025-05-29 11:16:27,577 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:16:27,577 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:16:27,577 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'rapi@@', 'd', 'car@@', 'ri@@', 'ed', 'for', 'the', 'past', '25', 'years', '.', '</s>']
2025-05-29 11:16:27,577 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:16:27,577 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:16:27,577 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a rapid carried for the past 25 years .
2025-05-29 11:16:44,749 - INFO - joeynmt.training - Epoch   6, Step:    20600, Batch Loss:     1.396279, Batch Acc: 0.603846, Tokens per Sec:     4029, Lr: 0.000300
2025-05-29 11:17:03,172 - INFO - joeynmt.training - Epoch   6, Step:    20700, Batch Loss:     1.319145, Batch Acc: 0.609820, Tokens per Sec:     4042, Lr: 0.000300
2025-05-29 11:17:21,704 - INFO - joeynmt.training - Epoch   6, Step:    20800, Batch Loss:     1.525419, Batch Acc: 0.601147, Tokens per Sec:     3857, Lr: 0.000300
2025-05-29 11:17:39,441 - INFO - joeynmt.training - Epoch   6, Step:    20900, Batch Loss:     1.358179, Batch Acc: 0.609083, Tokens per Sec:     4020, Lr: 0.000300
2025-05-29 11:17:56,871 - INFO - joeynmt.training - Epoch   6, Step:    21000, Batch Loss:     1.262838, Batch Acc: 0.604562, Tokens per Sec:     3982, Lr: 0.000300
2025-05-29 11:17:56,872 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:17:56,872 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:18:41,836 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.18, acc:   0.55, generation: 44.9557[sec], evaluation: 0.0000[sec]
2025-05-29 11:18:41,997 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/18500.ckpt
2025-05-29 11:18:42,000 - INFO - joeynmt.training - Example #0
2025-05-29 11:18:42,000 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:18:42,000 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:18:42,000 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'these', 'these', 'years', 'old', ',', 'I', 'sho@@', 'wed', 'these', 'these', 'de@@', 'vic@@', 'es', 'to', 'show', 'that', 'the', 'ar@@', 't@@', 'ical', 'he@@', 'at', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'has', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 11:18:42,000 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:18:42,000 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:18:42,000 - INFO - joeynmt.training - 	Hypothesis: I showed these these years old , I showed these these devices to show that the artical heat , which for almost three million years has had the size of the 48 size of the 48 continental .
2025-05-29 11:18:42,000 - INFO - joeynmt.training - Example #1
2025-05-29 11:18:42,000 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:18:42,001 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:18:42,001 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho@@', 'w@@', 'ever', 'this', 'sub@@', 'val@@', 'val@@', 'u@@', 'able', 'for', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', "'s", 'not', 'sho@@', 'wing', 'the', 'sp@@', 'ess@@', 'or', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:18:42,001 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:18:42,001 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:18:42,001 - INFO - joeynmt.training - 	Hypothesis: However this subvalvaluable for the gravity of the problem because it 's not showing the spessor of the ice .
2025-05-29 11:18:42,001 - INFO - joeynmt.training - Example #2
2025-05-29 11:18:42,001 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:18:42,001 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:18:42,001 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'cal@@', 'ot@@', 's', 'is', 'in', 'a', 'sense', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:18:42,001 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:18:42,001 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:18:42,001 - INFO - joeynmt.training - 	Hypothesis: The arctic calots is in a sense , in a sense , the clear heart of the global climate system .
2025-05-29 11:18:42,001 - INFO - joeynmt.training - Example #3
2025-05-29 11:18:42,001 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:18:42,001 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:18:42,001 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'and@@', 'ed', 'up', 'the', 'w@@', 'in@@', 'ds', 'and', 'you', 'ex@@', 'ten@@', 'd', 'the', 'w@@', 'in@@', 'ds', '.', '</s>']
2025-05-29 11:18:42,001 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:18:42,001 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:18:42,001 - INFO - joeynmt.training - 	Hypothesis: You expanded up the winds and you extend the winds .
2025-05-29 11:18:42,001 - INFO - joeynmt.training - Example #4
2025-05-29 11:18:42,001 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:18:42,001 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:18:42,001 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rapi@@', 'd', 'car@@', 'rel@@', 'ated', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:18:42,002 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:18:42,002 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:18:42,002 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid carrelated to the last 25 years .
2025-05-29 11:19:00,315 - INFO - joeynmt.training - Epoch   6, Step:    21100, Batch Loss:     1.436960, Batch Acc: 0.597095, Tokens per Sec:     3867, Lr: 0.000300
2025-05-29 11:19:17,861 - INFO - joeynmt.training - Epoch   6, Step:    21200, Batch Loss:     1.217854, Batch Acc: 0.598313, Tokens per Sec:     3986, Lr: 0.000300
2025-05-29 11:19:35,647 - INFO - joeynmt.training - Epoch   6, Step:    21300, Batch Loss:     1.419529, Batch Acc: 0.597633, Tokens per Sec:     4043, Lr: 0.000300
2025-05-29 11:19:52,931 - INFO - joeynmt.training - Epoch   6, Step:    21400, Batch Loss:     1.362988, Batch Acc: 0.596131, Tokens per Sec:     4137, Lr: 0.000300
2025-05-29 11:20:09,689 - INFO - joeynmt.training - Epoch   6, Step:    21500, Batch Loss:     1.538679, Batch Acc: 0.599356, Tokens per Sec:     4207, Lr: 0.000300
2025-05-29 11:20:09,690 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:20:09,690 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:20:52,205 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.17, acc:   0.55, generation: 42.5076[sec], evaluation: 0.0000[sec]
2025-05-29 11:20:52,375 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/19000.ckpt
2025-05-29 11:20:52,378 - INFO - joeynmt.training - Example #0
2025-05-29 11:20:52,379 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:20:52,379 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:20:52,379 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', ',', 'I', 'sho@@', 'wed', 'these', 'de@@', 'vic@@', 'es', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ica', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'has', 'had', 'the', 'size', 'of', '4@@', '8', 'percent', '.', '</s>']
2025-05-29 11:20:52,379 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:20:52,379 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:20:52,379 - INFO - joeynmt.training - 	Hypothesis: Last year , I showed these devices to show that the glacial calottica , which is almost three million years had the size of 48 million years had the size of 48 million years has had the size of 48 percent .
2025-05-29 11:20:52,379 - INFO - joeynmt.training - Example #1
2025-05-29 11:20:52,379 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:20:52,379 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:20:52,379 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', '-@@', 'val@@', 'u@@', 'able', ',', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ess@@', 'or', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:20:52,379 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:20:52,379 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:20:52,379 - INFO - joeynmt.training - 	Hypothesis: But this sub-valuable , the gravity of the problem because it doesn 't show the spessor of the ice .
2025-05-29 11:20:52,379 - INFO - joeynmt.training - Example #2
2025-05-29 11:20:52,379 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:20:52,379 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:20:52,379 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ica', 'is', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'cle@@', 'an', ',', 'the', 'cle@@', 'an', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:20:52,379 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:20:52,379 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:20:52,379 - INFO - joeynmt.training - 	Hypothesis: The glacial calottica is , in a certain sense , the clean , the clean of the global climate system .
2025-05-29 11:20:52,379 - INFO - joeynmt.training - Example #3
2025-05-29 11:20:52,380 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:20:52,380 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:20:52,380 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'can', "'t", 'w@@', 'int@@', 'er', 'and', 'you', 'get', 'r@@', 'it@@', 'ate', '.', '</s>']
2025-05-29 11:20:52,380 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:20:52,380 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:20:52,380 - INFO - joeynmt.training - 	Hypothesis: You can 't winter and you get ritate .
2025-05-29 11:20:52,380 - INFO - joeynmt.training - Example #4
2025-05-29 11:20:52,380 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:20:52,380 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:20:52,380 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'qu@@', 'ick', 'relati@@', 'on@@', 'ship', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:20:52,380 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:20:52,380 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:20:52,380 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quick relationship to the last 25 years .
2025-05-29 11:21:09,335 - INFO - joeynmt.training - Epoch   6, Step:    21600, Batch Loss:     1.429008, Batch Acc: 0.601293, Tokens per Sec:     4155, Lr: 0.000300
2025-05-29 11:21:26,520 - INFO - joeynmt.training - Epoch   6, Step:    21700, Batch Loss:     1.436700, Batch Acc: 0.602639, Tokens per Sec:     4238, Lr: 0.000300
2025-05-29 11:21:43,469 - INFO - joeynmt.training - Epoch   6, Step:    21800, Batch Loss:     1.213105, Batch Acc: 0.598112, Tokens per Sec:     4149, Lr: 0.000300
2025-05-29 11:22:00,184 - INFO - joeynmt.training - Epoch   6, Step:    21900, Batch Loss:     1.350073, Batch Acc: 0.597163, Tokens per Sec:     4158, Lr: 0.000300
2025-05-29 11:22:16,783 - INFO - joeynmt.training - Epoch   6, Step:    22000, Batch Loss:     1.342667, Batch Acc: 0.593231, Tokens per Sec:     4203, Lr: 0.000300
2025-05-29 11:22:16,788 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:22:16,788 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:22:56,601 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.14, acc:   0.55, generation: 39.8056[sec], evaluation: 0.0000[sec]
2025-05-29 11:22:56,603 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 11:22:56,799 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/19500.ckpt
2025-05-29 11:22:56,803 - INFO - joeynmt.training - Example #0
2025-05-29 11:22:56,803 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:22:56,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:22:56,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', "'ve", 'sho@@', 'wed', 'these', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', '-@@', 'ho@@', 'ot@@', 't@@', 'ical', 'cal@@', 'ot@@', 't@@', 'ical', ',', 'which', 'is', 'about', 'the', '4@@', '8', 'million', 'years', 'has', 'been', 'the', 'size', 'of', '4@@', '8', 'United', 'States', 'contin@@', 'ent@@', 'al', ',', 'you', 'have', 'to', 'be', 'about', '40', 'percent', '.', '</s>']
2025-05-29 11:22:56,803 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:22:56,803 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:22:56,803 - INFO - joeynmt.training - 	Hypothesis: I 've showed these these slides to show that the glacial calott-hoottical calottical , which is about the 48 million years has been the size of 48 United States continental , you have to be about 40 percent .
2025-05-29 11:22:56,803 - INFO - joeynmt.training - Example #1
2025-05-29 11:22:56,804 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:22:56,804 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:22:56,804 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'ground', ',', 'it', "'s", 'a', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', "'s", 'not', 'shows', 'the', 'sp@@', 'ess@@', 'or', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:22:56,804 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:22:56,804 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:22:56,804 - INFO - joeynmt.training - 	Hypothesis: But this underground , it 's a gravity of the problem because it 's not shows the spessor of the ice .
2025-05-29 11:22:56,804 - INFO - joeynmt.training - Example #2
2025-05-29 11:22:56,804 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:22:56,804 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:22:56,804 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ical', 'cal@@', 'ot@@', 'ta', "'s", 'cal@@', 'ot@@', 'ta', "'s", 'cal@@', 'ot@@', 'ta', ',', 'in', 'a', 'sense', ',', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:22:56,804 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:22:56,804 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:22:56,804 - INFO - joeynmt.training - 	Hypothesis: The artical calotta 's calotta 's calotta , in a sense , the global climate system .
2025-05-29 11:22:56,804 - INFO - joeynmt.training - Example #3
2025-05-29 11:22:56,804 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:22:56,804 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:22:56,804 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'go', 'out', 'of', 'w@@', 'in@@', 'ds', 'and', 'you', 'get', 'the', 'sum@@', 'mer', '.', '</s>']
2025-05-29 11:22:56,804 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:22:56,804 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:22:56,804 - INFO - joeynmt.training - 	Hypothesis: You go out of winds and you get the summer .
2025-05-29 11:22:56,804 - INFO - joeynmt.training - Example #4
2025-05-29 11:22:56,804 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:22:56,804 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:22:56,804 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'rel@@', 'ated', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:22:56,805 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:22:56,805 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:22:56,805 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick carrelated to the last 25 years .
2025-05-29 11:23:15,150 - INFO - joeynmt.training - Epoch   6, Step:    22100, Batch Loss:     1.360039, Batch Acc: 0.597285, Tokens per Sec:     3909, Lr: 0.000300
2025-05-29 11:23:32,006 - INFO - joeynmt.training - Epoch   6, Step:    22200, Batch Loss:     1.430769, Batch Acc: 0.595853, Tokens per Sec:     4218, Lr: 0.000300
2025-05-29 11:23:49,624 - INFO - joeynmt.training - Epoch   6, Step:    22300, Batch Loss:     1.250267, Batch Acc: 0.601877, Tokens per Sec:     3974, Lr: 0.000300
2025-05-29 11:24:07,144 - INFO - joeynmt.training - Epoch   6, Step:    22400, Batch Loss:     1.441581, Batch Acc: 0.599033, Tokens per Sec:     3932, Lr: 0.000300
2025-05-29 11:24:26,187 - INFO - joeynmt.training - Epoch   6, Step:    22500, Batch Loss:     1.388550, Batch Acc: 0.595102, Tokens per Sec:     3809, Lr: 0.000300
2025-05-29 11:24:26,188 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:24:26,188 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:25:12,080 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.09, acc:   0.56, generation: 45.8831[sec], evaluation: 0.0000[sec]
2025-05-29 11:25:12,082 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 11:25:12,274 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/20000.ckpt
2025-05-29 11:25:12,277 - INFO - joeynmt.training - Example #0
2025-05-29 11:25:12,277 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:25:12,277 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:25:12,277 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'P@@', 'l@@', 'ay@@', 'er', "'s", 'c@@', 'alc@@', 'ul@@', 'us', ',', 'which', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 11:25:12,277 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:25:12,277 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:25:12,277 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these these slides to show that the Player 's calculus , which almost three million years had the size of 48 million years had the size of 48 continental .
2025-05-29 11:25:12,277 - INFO - joeynmt.training - Example #1
2025-05-29 11:25:12,277 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:25:12,277 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:25:12,277 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'that', "'s", 'this', 'under@@', 'val@@', 'u@@', 'able', 'to', 'gr@@', 'av@@', 'ity', ',', 'because', 'it', 'doesn', "'t", 'shows', 'the', 'sp@@', 'ent', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:25:12,278 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:25:12,278 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:25:12,278 - INFO - joeynmt.training - 	Hypothesis: But that 's this undervaluable to gravity , because it doesn 't shows the spent of the ice .
2025-05-29 11:25:12,278 - INFO - joeynmt.training - Example #2
2025-05-29 11:25:12,278 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:25:12,278 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:25:12,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'gl@@', 'aci@@', 'al', 'c@@', 'alc@@', 'ul@@', 'ator', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', ',', 'the', 'cle@@', 'an', 'of', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:25:12,278 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:25:12,278 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:25:12,278 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial calculator is , in a sense , the clean , the clean of global climate system .
2025-05-29 11:25:12,278 - INFO - joeynmt.training - Example #3
2025-05-29 11:25:12,278 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:25:12,278 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:25:12,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'an@@', 'ies', 'of', 'w@@', 'int@@', 'er', 'and', 're@@', 'ti@@', 'red', 'of', 'ex@@', 'tre@@', 'me', '.', '</s>']
2025-05-29 11:25:12,278 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:25:12,278 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:25:12,278 - INFO - joeynmt.training - 	Hypothesis: You expanies of winter and retired of extreme .
2025-05-29 11:25:12,278 - INFO - joeynmt.training - Example #4
2025-05-29 11:25:12,278 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:25:12,278 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:25:12,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'qu@@', 'ick', 'rel@@', 'ated', 'to', 'the', 'ad@@', 'v@@', 'anc@@', 'ed', 'se@@', 'ver@@', 'al', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:25:12,278 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:25:12,278 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:25:12,278 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quick related to the advanced several of the last 25 years .
2025-05-29 11:25:30,560 - INFO - joeynmt.training - Epoch   6, Step:    22600, Batch Loss:     1.399232, Batch Acc: 0.599207, Tokens per Sec:     3931, Lr: 0.000300
2025-05-29 11:25:48,085 - INFO - joeynmt.training - Epoch   6, Step:    22700, Batch Loss:     1.405330, Batch Acc: 0.597413, Tokens per Sec:     4090, Lr: 0.000300
2025-05-29 11:26:05,537 - INFO - joeynmt.training - Epoch   6, Step:    22800, Batch Loss:     1.361831, Batch Acc: 0.589212, Tokens per Sec:     4026, Lr: 0.000300
2025-05-29 11:26:23,229 - INFO - joeynmt.training - Epoch   6, Step:    22900, Batch Loss:     1.398207, Batch Acc: 0.593811, Tokens per Sec:     3948, Lr: 0.000300
2025-05-29 11:26:41,778 - INFO - joeynmt.training - Epoch   6, Step:    23000, Batch Loss:     1.539980, Batch Acc: 0.596618, Tokens per Sec:     3890, Lr: 0.000300
2025-05-29 11:26:41,778 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:26:41,779 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:27:25,961 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.07, acc:   0.55, generation: 44.1752[sec], evaluation: 0.0000[sec]
2025-05-29 11:27:25,964 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 11:27:26,158 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/21000.ckpt
2025-05-29 11:27:26,161 - INFO - joeynmt.training - Example #0
2025-05-29 11:27:26,161 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:27:26,161 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:27:26,161 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', ',', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', '-@@', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ica', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'United', 'States', '.', '</s>']
2025-05-29 11:27:26,161 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:27:26,161 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:27:26,161 - INFO - joeynmt.training - 	Hypothesis: Last year , I showed these slides to show that the glacial calott-glacial calottica , which is almost three million years had the size of 48 United States .
2025-05-29 11:27:26,161 - INFO - joeynmt.training - Example #1
2025-05-29 11:27:26,161 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:27:26,161 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:27:26,161 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'val@@', 'ute', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ent', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ent', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:27:26,161 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:27:26,161 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:27:26,161 - INFO - joeynmt.training - 	Hypothesis: But this subvalute the gravity of the problem because it doesn 't show the spent of the problem because it doesn 't show the spent of the ice .
2025-05-29 11:27:26,161 - INFO - joeynmt.training - Example #2
2025-05-29 11:27:26,161 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:27:26,161 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:27:26,161 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'ter', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', 'is', 'a', 'cle@@', 'an', ',', 'the', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:27:26,161 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:27:26,162 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:27:26,162 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial calotter is , in a sense , the clean is a clean , the heart of the global climate system .
2025-05-29 11:27:26,162 - INFO - joeynmt.training - Example #3
2025-05-29 11:27:26,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:27:26,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:27:26,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'going', 'to', 'be', 'up', 'and', 're@@', 'ti@@', 'red', '.', '</s>']
2025-05-29 11:27:26,162 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:27:26,162 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:27:26,162 - INFO - joeynmt.training - 	Hypothesis: It 's going to be up and retired .
2025-05-29 11:27:26,162 - INFO - joeynmt.training - Example #4
2025-05-29 11:27:26,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:27:26,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:27:26,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'qu@@', 'ick', 'car@@', 'ri@@', 'ed', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'ri@@', 'ed', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:27:26,162 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:27:26,162 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:27:26,162 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quick carried to be a quick carried on the last 25 years .
2025-05-29 11:27:44,118 - INFO - joeynmt.training - Epoch   6, Step:    23100, Batch Loss:     1.371319, Batch Acc: 0.600894, Tokens per Sec:     3930, Lr: 0.000300
2025-05-29 11:28:02,417 - INFO - joeynmt.training - Epoch   6, Step:    23200, Batch Loss:     1.514295, Batch Acc: 0.589214, Tokens per Sec:     3939, Lr: 0.000300
2025-05-29 11:28:20,380 - INFO - joeynmt.training - Epoch   6, Step:    23300, Batch Loss:     1.407176, Batch Acc: 0.599144, Tokens per Sec:     3878, Lr: 0.000300
2025-05-29 11:28:38,436 - INFO - joeynmt.training - Epoch   6, Step:    23400, Batch Loss:     1.294591, Batch Acc: 0.599285, Tokens per Sec:     3936, Lr: 0.000300
2025-05-29 11:28:55,247 - INFO - joeynmt.training - Epoch   6, Step:    23500, Batch Loss:     1.402864, Batch Acc: 0.603124, Tokens per Sec:     4315, Lr: 0.000300
2025-05-29 11:28:55,248 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:28:55,248 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:29:37,634 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.03, acc:   0.56, generation: 42.3784[sec], evaluation: 0.0000[sec]
2025-05-29 11:29:37,637 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 11:29:37,857 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/21500.ckpt
2025-05-29 11:29:37,861 - INFO - joeynmt.training - Example #0
2025-05-29 11:29:37,861 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:29:37,861 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:29:37,861 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', ',', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ica', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'percent', '.', '</s>']
2025-05-29 11:29:37,861 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:29:37,861 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:29:37,861 - INFO - joeynmt.training - 	Hypothesis: Last year , I showed these slides to show that the glacial calottica , which for almost three million years had the size of 48 million years had the size of 48 million years had the size of 48 percent .
2025-05-29 11:29:37,861 - INFO - joeynmt.training - Example #1
2025-05-29 11:29:37,861 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:29:37,861 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:29:37,861 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'l@@', 'ying', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ac@@', 'es', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:29:37,861 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:29:37,861 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:29:37,861 - INFO - joeynmt.training - 	Hypothesis: But this underlying the gravity of the problem because it doesn 't show the spaces of the ice .
2025-05-29 11:29:37,861 - INFO - joeynmt.training - Example #2
2025-05-29 11:29:37,861 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:29:37,861 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:29:37,861 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'of', 'the', 'ar@@', 'c@@', 'tic', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:29:37,862 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:29:37,862 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:29:37,862 - INFO - joeynmt.training - 	Hypothesis: The arctic of the arctic , in a certain sense , the heart of the global climate system .
2025-05-29 11:29:37,862 - INFO - joeynmt.training - Example #3
2025-05-29 11:29:37,862 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:29:37,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:29:37,862 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'know', ',', 'you', 'exp@@', 'and@@', 'ed', 'up', 'and', 'r@@', 'iti@@', 'zed', 'sum@@', 'mer', '.', '</s>']
2025-05-29 11:29:37,862 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:29:37,862 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:29:37,862 - INFO - joeynmt.training - 	Hypothesis: You know , you expanded up and ritized summer .
2025-05-29 11:29:37,862 - INFO - joeynmt.training - Example #4
2025-05-29 11:29:37,862 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:29:37,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:29:37,862 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'rapi@@', 'd', 'car@@', 'ri@@', 'ed', 'on', 'the', 'next', '25', 'years', '.', '</s>']
2025-05-29 11:29:37,862 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:29:37,862 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:29:37,862 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a rapid carried on the next 25 years .
2025-05-29 11:29:56,177 - INFO - joeynmt.training - Epoch   6, Step:    23600, Batch Loss:     1.365698, Batch Acc: 0.598036, Tokens per Sec:     3927, Lr: 0.000300
2025-05-29 11:30:13,949 - INFO - joeynmt.training - Epoch   6, Step:    23700, Batch Loss:     1.504679, Batch Acc: 0.600205, Tokens per Sec:     3890, Lr: 0.000300
2025-05-29 11:30:31,039 - INFO - joeynmt.training - Epoch   6, Step:    23800, Batch Loss:     1.204825, Batch Acc: 0.603167, Tokens per Sec:     4187, Lr: 0.000300
2025-05-29 11:30:48,952 - INFO - joeynmt.training - Epoch   6, Step:    23900, Batch Loss:     1.475740, Batch Acc: 0.596945, Tokens per Sec:     3987, Lr: 0.000300
2025-05-29 11:31:05,894 - INFO - joeynmt.training - Epoch   6, Step:    24000, Batch Loss:     1.213092, Batch Acc: 0.596516, Tokens per Sec:     4192, Lr: 0.000300
2025-05-29 11:31:05,897 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:31:05,897 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:31:49,036 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.04, acc:   0.55, generation: 43.1319[sec], evaluation: 0.0000[sec]
2025-05-29 11:31:49,283 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/20500.ckpt
2025-05-29 11:31:49,285 - INFO - joeynmt.training - Example #0
2025-05-29 11:31:49,286 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:31:49,286 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:31:49,286 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'next', 'year', 'to', 'show', 'that', 'the', 'P@@', 'ot@@', 't@@', 'ical', 'c@@', 'alc@@', 'ul@@', 'us', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'U.@@', 'S.', 'contin@@', 'ent@@', 'al', ',', 'it', "'s", 're@@', 'mark@@', 'able', '.', '</s>']
2025-05-29 11:31:49,286 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:31:49,286 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:31:49,286 - INFO - joeynmt.training - 	Hypothesis: And I showed these slides to show that the next year to show that the Pottical calculus , which for almost three million years had the size of 48 million years had the size of 48 , the U.S. continental , it 's remarkable .
2025-05-29 11:31:49,286 - INFO - joeynmt.training - Example #1
2025-05-29 11:31:49,286 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:31:49,286 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:31:49,286 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'est@@', 'im@@', 'ate', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ess@@', 'or', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:31:49,286 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:31:49,286 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:31:49,286 - INFO - joeynmt.training - 	Hypothesis: But this underestimate the gravity of the problem because it doesn 't show the spessor of the ice .
2025-05-29 11:31:49,286 - INFO - joeynmt.training - Example #2
2025-05-29 11:31:49,286 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:31:49,286 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:31:49,286 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'Ar@@', 'c@@', 'tic', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'a', 'sense', ',', 'the', 'cle@@', 'an', ',', 'the', 'heart', 'of', 'a', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:31:49,286 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:31:49,286 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:31:49,287 - INFO - joeynmt.training - 	Hypothesis: The Arctic ice is , in a sense , a sense , the clean , the heart of a global climate system .
2025-05-29 11:31:49,287 - INFO - joeynmt.training - Example #3
2025-05-29 11:31:49,287 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:31:49,287 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:31:49,287 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'and@@', 'ed', 'up', 'and', 'w@@', 'int@@', 'er', 'and', 'ex@@', 'tre@@', 'me', 'ex@@', 'tre@@', 'me', '.', '</s>']
2025-05-29 11:31:49,287 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:31:49,287 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:31:49,287 - INFO - joeynmt.training - 	Hypothesis: You expanded up and winter and extreme extreme .
2025-05-29 11:31:49,287 - INFO - joeynmt.training - Example #4
2025-05-29 11:31:49,287 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:31:49,287 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:31:49,287 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'few', '25', 'years', '.', '</s>']
2025-05-29 11:31:49,287 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:31:49,287 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:31:49,287 - INFO - joeynmt.training - 	Hypothesis: The next next few 25 years .
2025-05-29 11:32:07,066 - INFO - joeynmt.training - Epoch   6, Step:    24100, Batch Loss:     1.524536, Batch Acc: 0.600870, Tokens per Sec:     4028, Lr: 0.000300
2025-05-29 11:32:24,927 - INFO - joeynmt.training - Epoch   6, Step:    24200, Batch Loss:     1.367569, Batch Acc: 0.606039, Tokens per Sec:     4073, Lr: 0.000300
2025-05-29 11:32:42,903 - INFO - joeynmt.training - Epoch   6, Step:    24300, Batch Loss:     1.414199, Batch Acc: 0.593330, Tokens per Sec:     3867, Lr: 0.000300
2025-05-29 11:33:02,079 - INFO - joeynmt.training - Epoch   6, Step:    24400, Batch Loss:     1.310185, Batch Acc: 0.598526, Tokens per Sec:     3608, Lr: 0.000300
2025-05-29 11:33:20,551 - INFO - joeynmt.training - Epoch   6: total training loss 5841.81
2025-05-29 11:33:20,552 - INFO - joeynmt.training - EPOCH 7
2025-05-29 11:33:24,266 - INFO - joeynmt.training - Epoch   7, Step:    24500, Batch Loss:     1.337737, Batch Acc: 0.613567, Tokens per Sec:     3260, Lr: 0.000300
2025-05-29 11:33:24,266 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:33:24,266 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:34:10,449 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.03, acc:   0.56, generation: 46.1738[sec], evaluation: 0.0000[sec]
2025-05-29 11:34:10,696 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/22000.ckpt
2025-05-29 11:34:10,698 - INFO - joeynmt.training - Example #0
2025-05-29 11:34:10,698 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:34:10,698 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:34:10,698 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', "'ve", 'sho@@', 'wn', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'sli@@', 'de', 'c@@', 'alc@@', 'ul@@', 'us', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ica', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', '4@@', '8', 'dimen@@', 'sions', 'of', '4@@', '8', 'United', 'States', 'contin@@', 'ent@@', 'al', ',', 'it', "'s", 're@@', 'stre@@', 't@@', 'ched', 'to', '40', 'percent', '.', '</s>']
2025-05-29 11:34:10,698 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:34:10,698 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:34:10,698 - INFO - joeynmt.training - 	Hypothesis: I 've shown these slides to show that the slide calculus to show that the glacial calottica , which for almost three million years had the 48 dimensions of 48 United States continental , it 's restretched to 40 percent .
2025-05-29 11:34:10,698 - INFO - joeynmt.training - Example #1
2025-05-29 11:34:10,698 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:34:10,699 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:34:10,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'val@@', 'ue', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ess@@', 'or', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:34:10,699 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:34:10,699 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:34:10,699 - INFO - joeynmt.training - 	Hypothesis: But this subvalue the gravity of the problem because it doesn 't show the spessor of the ice .
2025-05-29 11:34:10,699 - INFO - joeynmt.training - Example #2
2025-05-29 11:34:10,699 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:34:10,699 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:34:10,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'c@@', 'c@@', 'alc@@', 'ul@@', 'ation', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:34:10,699 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:34:10,699 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:34:10,699 - INFO - joeynmt.training - 	Hypothesis: The arcccalculation is , in a sense , the clear of the global climate system .
2025-05-29 11:34:10,699 - INFO - joeynmt.training - Example #3
2025-05-29 11:34:10,699 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:34:10,699 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:34:10,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'go', 'up', 'to', 'the', 'w@@', 'int@@', 'er', 'and', 'you', 'get', 'to', 'ex@@', 'tre@@', 'me', '.', '</s>']
2025-05-29 11:34:10,699 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:34:10,699 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:34:10,699 - INFO - joeynmt.training - 	Hypothesis: You go up to the winter and you get to extreme .
2025-05-29 11:34:10,699 - INFO - joeynmt.training - Example #4
2025-05-29 11:34:10,699 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:34:10,699 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:34:10,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'qu@@', 'ick', 'rel@@', 'ated', 'car@@', 'ri@@', 'ed', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:34:10,699 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:34:10,700 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:34:10,700 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quick related carried on the last 25 years .
2025-05-29 11:34:29,175 - INFO - joeynmt.training - Epoch   7, Step:    24600, Batch Loss:     1.322690, Batch Acc: 0.624125, Tokens per Sec:     3785, Lr: 0.000300
2025-05-29 11:34:47,000 - INFO - joeynmt.training - Epoch   7, Step:    24700, Batch Loss:     1.443080, Batch Acc: 0.617853, Tokens per Sec:     4011, Lr: 0.000300
2025-05-29 11:35:05,902 - INFO - joeynmt.training - Epoch   7, Step:    24800, Batch Loss:     1.394269, Batch Acc: 0.616871, Tokens per Sec:     3744, Lr: 0.000300
2025-05-29 11:35:27,137 - INFO - joeynmt.training - Epoch   7, Step:    24900, Batch Loss:     1.277583, Batch Acc: 0.620419, Tokens per Sec:     3399, Lr: 0.000300
2025-05-29 11:35:48,662 - INFO - joeynmt.training - Epoch   7, Step:    25000, Batch Loss:     1.445145, Batch Acc: 0.614656, Tokens per Sec:     3330, Lr: 0.000300
2025-05-29 11:35:48,663 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:35:48,663 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:36:32,465 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.05, acc:   0.56, generation: 43.7912[sec], evaluation: 0.0000[sec]
2025-05-29 11:36:32,723 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/22500.ckpt
2025-05-29 11:36:32,725 - INFO - joeynmt.training - Example #0
2025-05-29 11:36:32,726 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:36:32,726 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:36:32,726 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', ',', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'next', 'cal@@', 'ot@@', 't@@', 'c', 'cal@@', 'ot@@', 't@@', 'ica', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', '4@@', '8', 'dimen@@', 'sions', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 11:36:32,726 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:36:32,726 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:36:32,726 - INFO - joeynmt.training - 	Hypothesis: Last year , I showed these slides to demonstrate that the next calottc calottica , which for almost three million years had the 48 dimensions of 48 continental .
2025-05-29 11:36:32,726 - INFO - joeynmt.training - Example #1
2025-05-29 11:36:32,726 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:36:32,726 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:36:32,726 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'val@@', 'ue', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'p@@', 'ay@@', 'er', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:36:32,726 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:36:32,726 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:36:32,726 - INFO - joeynmt.training - 	Hypothesis: But this subvalue the gravity of the problem because it doesn 't show the payer of the ice .
2025-05-29 11:36:32,726 - INFO - joeynmt.training - Example #2
2025-05-29 11:36:32,726 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:36:32,726 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:36:32,726 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'Ar@@', 'c@@', 'tic', 'cal@@', 'ot@@', 'ter', 'is', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:36:32,726 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:36:32,726 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:36:32,726 - INFO - joeynmt.training - 	Hypothesis: The Arctic calotter is , in a certain sense , the clear heart of global climate system .
2025-05-29 11:36:32,726 - INFO - joeynmt.training - Example #3
2025-05-29 11:36:32,726 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:36:32,726 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:36:32,727 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'go', 'out', 'and', 'w@@', 'int@@', 'er', 'and', 'you', 'ex@@', 'tre@@', 'me', 'on', 'sum@@', 'mer', '.', '</s>']
2025-05-29 11:36:32,727 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:36:32,727 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:36:32,727 - INFO - joeynmt.training - 	Hypothesis: You go out and winter and you extreme on summer .
2025-05-29 11:36:32,727 - INFO - joeynmt.training - Example #4
2025-05-29 11:36:32,727 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:36:32,727 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:36:32,727 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'qu@@', 'ick', 'rel@@', 'ated', 'to', 'the', 'ad@@', 'v@@', 'ent', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:36:32,727 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:36:32,727 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:36:32,727 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quick related to the advent of the last 25 years .
2025-05-29 11:36:52,361 - INFO - joeynmt.training - Epoch   7, Step:    25100, Batch Loss:     1.320302, Batch Acc: 0.615232, Tokens per Sec:     3591, Lr: 0.000300
2025-05-29 11:37:10,921 - INFO - joeynmt.training - Epoch   7, Step:    25200, Batch Loss:     1.440370, Batch Acc: 0.611533, Tokens per Sec:     3763, Lr: 0.000300
2025-05-29 11:37:32,135 - INFO - joeynmt.training - Epoch   7, Step:    25300, Batch Loss:     1.522763, Batch Acc: 0.609854, Tokens per Sec:     3362, Lr: 0.000300
2025-05-29 11:37:52,205 - INFO - joeynmt.training - Epoch   7, Step:    25400, Batch Loss:     1.383319, Batch Acc: 0.609066, Tokens per Sec:     3541, Lr: 0.000300
2025-05-29 11:38:14,126 - INFO - joeynmt.training - Epoch   7, Step:    25500, Batch Loss:     1.408951, Batch Acc: 0.613580, Tokens per Sec:     3235, Lr: 0.000300
2025-05-29 11:38:14,126 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:38:14,126 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:38:59,121 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.03, acc:   0.56, generation: 44.9866[sec], evaluation: 0.0000[sec]
2025-05-29 11:38:59,355 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/23000.ckpt
2025-05-29 11:38:59,357 - INFO - joeynmt.training - Example #0
2025-05-29 11:38:59,358 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:38:59,358 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:38:59,358 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', ',', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ical', 'cal@@', 'ot@@', 't@@', 'ica', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'had', 'the', 'U.@@', 'S.', 'about', '4@@', '8', 'percent', '.', '</s>']
2025-05-29 11:38:59,358 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:38:59,358 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:38:59,358 - INFO - joeynmt.training - 	Hypothesis: Last year , I showed these slides to show that the glacial calottical calottica , which is almost three million years had the size of 48 million years had the U.S. about 48 percent .
2025-05-29 11:38:59,358 - INFO - joeynmt.training - Example #1
2025-05-29 11:38:59,358 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:38:59,358 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:38:59,358 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho@@', 'w@@', 'ever', ',', 'this', 'sub@@', 'val@@', 'ue', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:38:59,358 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:38:59,358 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:38:59,358 - INFO - joeynmt.training - 	Hypothesis: However , this subvalue the gravity of the problem because it doesn 't show the ice of the ice .
2025-05-29 11:38:59,358 - INFO - joeynmt.training - Example #2
2025-05-29 11:38:59,358 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:38:59,358 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:38:59,358 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'gl@@', 'aci@@', 'al', 'ho@@', 'o@@', 'ds', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:38:59,358 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:38:59,358 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:38:59,358 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial hoods is , in a sense , the clear heart of the global climate system .
2025-05-29 11:38:59,358 - INFO - joeynmt.training - Example #3
2025-05-29 11:38:59,359 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:38:59,359 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:38:59,359 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'go', 'to', 'the', 'w@@', 'int@@', 'er', 'and', 'you', "'re", 're@@', 'ti@@', 'red', '.', '</s>']
2025-05-29 11:38:59,359 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:38:59,359 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:38:59,359 - INFO - joeynmt.training - 	Hypothesis: You go to the winter and you 're retired .
2025-05-29 11:38:59,359 - INFO - joeynmt.training - Example #4
2025-05-29 11:38:59,359 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:38:59,359 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:38:59,359 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'rel@@', 'ated', 'to', 'the', 'ad@@', 'v@@', 'anc@@', 'ed', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:38:59,359 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:38:59,359 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:38:59,359 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick related to the advanced the last 25 years .
2025-05-29 11:39:19,376 - INFO - joeynmt.training - Epoch   7, Step:    25600, Batch Loss:     1.534863, Batch Acc: 0.608106, Tokens per Sec:     3576, Lr: 0.000300
2025-05-29 11:39:38,625 - INFO - joeynmt.training - Epoch   7, Step:    25700, Batch Loss:     1.424701, Batch Acc: 0.612538, Tokens per Sec:     3646, Lr: 0.000300
2025-05-29 11:39:59,876 - INFO - joeynmt.training - Epoch   7, Step:    25800, Batch Loss:     1.317706, Batch Acc: 0.616975, Tokens per Sec:     3295, Lr: 0.000300
2025-05-29 11:40:18,281 - INFO - joeynmt.training - Epoch   7, Step:    25900, Batch Loss:     1.368353, Batch Acc: 0.616857, Tokens per Sec:     3880, Lr: 0.000300
2025-05-29 11:40:37,241 - INFO - joeynmt.training - Epoch   7, Step:    26000, Batch Loss:     1.328026, Batch Acc: 0.616119, Tokens per Sec:     3766, Lr: 0.000300
2025-05-29 11:40:37,242 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:40:37,242 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:41:22,065 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.04, acc:   0.55, generation: 44.8160[sec], evaluation: 0.0000[sec]
2025-05-29 11:41:22,291 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/25000.ckpt
2025-05-29 11:41:22,293 - INFO - joeynmt.training - Example #0
2025-05-29 11:41:22,294 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:41:22,294 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:41:22,294 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'show', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ar@@', 'c@@', 'tic', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'has', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', 'dimen@@', 'sions', 'of', 'the', 'United', 'States', ',', 'is', '40', 'percent', '.', '</s>']
2025-05-29 11:41:22,294 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:41:22,294 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:41:22,294 - INFO - joeynmt.training - 	Hypothesis: I showed these slides to show these slides to show that the glacial calottarctic , which for almost three million years has had the size of the 48 continental dimensions of the United States , is 40 percent .
2025-05-29 11:41:22,294 - INFO - joeynmt.training - Example #1
2025-05-29 11:41:22,294 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:41:22,294 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:41:22,294 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho@@', 'w@@', 'ever', ',', 'this', 'sub@@', 'val@@', 'ue', 'of', 'the', 'problem', 'because', 'it', "'s", 'not', 'shows', 'the', 'sp@@', 'ent', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:41:22,294 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:41:22,294 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:41:22,294 - INFO - joeynmt.training - 	Hypothesis: However , this subvalue of the problem because it 's not shows the spent of the ice .
2025-05-29 11:41:22,294 - INFO - joeynmt.training - Example #2
2025-05-29 11:41:22,294 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:41:22,294 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:41:22,294 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'Ar@@', 'c@@', 'tic', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ical', 'is', ',', 'in', 'a', 'way', ',', 'the', 'cle@@', 'ar', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:41:22,294 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:41:22,294 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:41:22,294 - INFO - joeynmt.training - 	Hypothesis: The Arctic glacial calottical is , in a way , the clear of the global climate system .
2025-05-29 11:41:22,294 - INFO - joeynmt.training - Example #3
2025-05-29 11:41:22,295 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:41:22,295 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:41:22,295 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'go', 'up', 'to', 'the', 'w@@', 'int@@', 'er', 'and', 'the', 'sum@@', 'mer', '.', '</s>']
2025-05-29 11:41:22,295 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:41:22,295 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:41:22,295 - INFO - joeynmt.training - 	Hypothesis: You go up to the winter and the summer .
2025-05-29 11:41:22,295 - INFO - joeynmt.training - Example #4
2025-05-29 11:41:22,295 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:41:22,295 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:41:22,295 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'qu@@', 'ick', 'car@@', 'rel@@', 'ated', 'to', 'the', 'av@@', 'im@@', 'ents', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:41:22,295 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:41:22,295 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:41:22,295 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quick carrelated to the aviments of the last 25 years .
2025-05-29 11:41:44,014 - INFO - joeynmt.training - Epoch   7, Step:    26100, Batch Loss:     1.563145, Batch Acc: 0.604257, Tokens per Sec:     3185, Lr: 0.000300
2025-05-29 11:42:04,687 - INFO - joeynmt.training - Epoch   7, Step:    26200, Batch Loss:     1.298247, Batch Acc: 0.609344, Tokens per Sec:     3472, Lr: 0.000300
2025-05-29 11:42:25,440 - INFO - joeynmt.training - Epoch   7, Step:    26300, Batch Loss:     1.459947, Batch Acc: 0.609281, Tokens per Sec:     3369, Lr: 0.000300
2025-05-29 11:43:26,828 - INFO - joeynmt.training - Epoch   7, Step:    26400, Batch Loss:     1.370927, Batch Acc: 0.607215, Tokens per Sec:     1177, Lr: 0.000300
2025-05-29 11:44:44,306 - INFO - joeynmt.training - Epoch   7, Step:    26500, Batch Loss:     1.438441, Batch Acc: 0.607987, Tokens per Sec:      909, Lr: 0.000300
2025-05-29 11:44:44,308 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:44:44,308 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:45:26,345 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.05, acc:   0.56, generation: 42.0288[sec], evaluation: 0.0000[sec]
2025-05-29 11:45:26,349 - INFO - joeynmt.training - Example #0
2025-05-29 11:45:26,349 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:45:26,349 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:45:26,349 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ice', 'cal@@', 'ot@@', 't@@', 'ar@@', 't@@', 'ical', 'ar@@', 'c@@', 't@@', 'ica', ',', 'that', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'United', 'States', ',', 'that', 'was', 'about', '40', 'percent', '.', '</s>']
2025-05-29 11:45:26,349 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:45:26,349 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:45:26,349 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to demonstrate that the ice calottartical arctica , that almost three million years had the size of 48 United States , that was about 40 percent .
2025-05-29 11:45:26,349 - INFO - joeynmt.training - Example #1
2025-05-29 11:45:26,349 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:45:26,349 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:45:26,349 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'val@@', 'u@@', 'able', 'to', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'ice', 'of', 'ice', '.', '</s>']
2025-05-29 11:45:26,350 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:45:26,350 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:45:26,350 - INFO - joeynmt.training - 	Hypothesis: But this subvaluable to gravity of the problem because it doesn 't show the ice of ice .
2025-05-29 11:45:26,350 - INFO - joeynmt.training - Example #2
2025-05-29 11:45:26,350 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:45:26,350 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:45:26,350 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'c@@', 'alc@@', 'ul@@', 'us', 'is', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:45:26,350 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:45:26,350 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:45:26,350 - INFO - joeynmt.training - 	Hypothesis: The arctic calculus is , in a certain sense , the heart of the global climate system .
2025-05-29 11:45:26,350 - INFO - joeynmt.training - Example #3
2025-05-29 11:45:26,350 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:45:26,350 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:45:26,350 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'ex@@', 'cu@@', 'se', 'and', 'you', 'get', 'ex@@', 'cu@@', 'se', '.', '</s>']
2025-05-29 11:45:26,350 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:45:26,350 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:45:26,350 - INFO - joeynmt.training - 	Hypothesis: It 's excuse and you get excuse .
2025-05-29 11:45:26,350 - INFO - joeynmt.training - Example #4
2025-05-29 11:45:26,350 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:45:26,350 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:45:26,350 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'qu@@', 'ick', 'car@@', 'rel@@', 'ated', 'to', 'the', 'av@@', 'im@@', 'ate', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:45:26,351 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:45:26,351 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:45:26,351 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quick carrelated to the avimate of the last 25 years .
2025-05-29 11:45:47,710 - INFO - joeynmt.training - Epoch   7, Step:    26600, Batch Loss:     1.361887, Batch Acc: 0.606927, Tokens per Sec:     3337, Lr: 0.000300
2025-05-29 11:46:07,899 - INFO - joeynmt.training - Epoch   7, Step:    26700, Batch Loss:     1.433308, Batch Acc: 0.610114, Tokens per Sec:     3492, Lr: 0.000300
2025-05-29 11:46:27,120 - INFO - joeynmt.training - Epoch   7, Step:    26800, Batch Loss:     1.387010, Batch Acc: 0.612129, Tokens per Sec:     3718, Lr: 0.000300
2025-05-29 11:46:47,068 - INFO - joeynmt.training - Epoch   7, Step:    26900, Batch Loss:     1.230097, Batch Acc: 0.599012, Tokens per Sec:     3593, Lr: 0.000300
2025-05-29 11:47:07,263 - INFO - joeynmt.training - Epoch   7, Step:    27000, Batch Loss:     1.382133, Batch Acc: 0.608704, Tokens per Sec:     3542, Lr: 0.000300
2025-05-29 11:47:07,264 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:47:07,264 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:47:53,048 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.97, acc:   0.56, generation: 45.7769[sec], evaluation: 0.0000[sec]
2025-05-29 11:47:53,051 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 11:47:53,276 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/26000.ckpt
2025-05-29 11:47:53,279 - INFO - joeynmt.training - Example #0
2025-05-29 11:47:53,279 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:47:53,279 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:47:53,279 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'de', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 't@@', 'ical', 'cal@@', 'ot@@', 't', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', '.', '</s>']
2025-05-29 11:47:53,279 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:47:53,279 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:47:53,279 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slide to demonstrate that the artical calott , which is almost three million years had the size of 48 .
2025-05-29 11:47:53,279 - INFO - joeynmt.training - Example #1
2025-05-29 11:47:53,279 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:47:53,279 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:47:53,279 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'est@@', 'ab@@', 'li@@', 'c', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'or@@', 'es', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:47:53,279 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:47:53,279 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:47:53,279 - INFO - joeynmt.training - 	Hypothesis: But this underestablic gravity of the problem because it doesn 't show the spores of the ice .
2025-05-29 11:47:53,279 - INFO - joeynmt.training - Example #2
2025-05-29 11:47:53,279 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:47:53,279 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:47:53,279 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'of', 'the', 'ar@@', 'c@@', 'tic', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', ',', 'the', 'cle@@', 'an', ',', 'the', 'cle@@', 'an', 'of', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:47:53,280 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:47:53,280 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:47:53,280 - INFO - joeynmt.training - 	Hypothesis: The arctic of the arctic , in a sense , the clean , the clean , the clean of global climate system .
2025-05-29 11:47:53,280 - INFO - joeynmt.training - Example #3
2025-05-29 11:47:53,280 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:47:53,280 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:47:53,280 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'w@@', 'in@@', 'ver@@', 'n@@', 'ment', 'and', 'you', 'get', 'the', 'sum@@', 'mer', '.', '</s>']
2025-05-29 11:47:53,280 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:47:53,280 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:47:53,280 - INFO - joeynmt.training - 	Hypothesis: It 's winvernment and you get the summer .
2025-05-29 11:47:53,280 - INFO - joeynmt.training - Example #4
2025-05-29 11:47:53,280 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:47:53,280 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:47:53,280 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'rel@@', 'ated', 'to', 'the', 'ad@@', 'v@@', 'an@@', 'ces', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:47:53,280 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:47:53,280 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:47:53,280 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick related to the advances of the last 25 years .
2025-05-29 11:48:13,796 - INFO - joeynmt.training - Epoch   7, Step:    27100, Batch Loss:     1.481001, Batch Acc: 0.607718, Tokens per Sec:     3476, Lr: 0.000300
2025-05-29 11:48:35,599 - INFO - joeynmt.training - Epoch   7, Step:    27200, Batch Loss:     1.460346, Batch Acc: 0.609646, Tokens per Sec:     3294, Lr: 0.000300
2025-05-29 11:48:55,335 - INFO - joeynmt.training - Epoch   7, Step:    27300, Batch Loss:     1.485011, Batch Acc: 0.607008, Tokens per Sec:     3562, Lr: 0.000300
2025-05-29 11:49:14,987 - INFO - joeynmt.training - Epoch   7, Step:    27400, Batch Loss:     1.202014, Batch Acc: 0.609621, Tokens per Sec:     3545, Lr: 0.000300
2025-05-29 11:49:34,685 - INFO - joeynmt.training - Epoch   7, Step:    27500, Batch Loss:     1.522581, Batch Acc: 0.606844, Tokens per Sec:     3532, Lr: 0.000300
2025-05-29 11:49:34,686 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:49:34,686 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:50:21,367 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.94, acc:   0.56, generation: 46.6738[sec], evaluation: 0.0000[sec]
2025-05-29 11:50:21,370 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 11:50:21,602 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/24000.ckpt
2025-05-29 11:50:21,604 - INFO - joeynmt.training - Example #0
2025-05-29 11:50:21,604 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:50:21,604 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:50:21,604 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'so@@', 'on', 'c@@', 'k@@', 'et', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'ago', ',', 'which', 'is', 'about', 'about', 'the', 'size', 'of', '4@@', '8', '.', '</s>']
2025-05-29 11:50:21,604 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:50:21,604 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:50:21,605 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to demonstrate that the soon cket , which is almost three million years ago , which is about about the size of 48 .
2025-05-29 11:50:21,605 - INFO - joeynmt.training - Example #1
2025-05-29 11:50:21,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:50:21,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:50:21,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'val@@', 'ue', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', "'s", 'not', 'the', 'con@@', 'vers@@', 'ation', 'of', 'the', 'problem', '.', '</s>']
2025-05-29 11:50:21,605 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:50:21,605 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:50:21,605 - INFO - joeynmt.training - 	Hypothesis: But this subvalue the gravity of the problem because it 's not the conversation of the problem .
2025-05-29 11:50:21,605 - INFO - joeynmt.training - Example #2
2025-05-29 11:50:21,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:50:21,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:50:21,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'e@@', 'th@@', 'ic', 'ho@@', 't', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', ',', 'the', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:50:21,605 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:50:21,605 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:50:21,605 - INFO - joeynmt.training - 	Hypothesis: The arcethic hot is , in a sense , the clean , the heart of the global climate system .
2025-05-29 11:50:21,605 - INFO - joeynmt.training - Example #3
2025-05-29 11:50:21,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:50:21,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:50:21,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'and', 'it', 'w@@', 'int@@', 'er', 'and', 're@@', 'tre@@', 'at', '.', '</s>']
2025-05-29 11:50:21,605 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:50:21,605 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:50:21,605 - INFO - joeynmt.training - 	Hypothesis: You expand it winter and retreat .
2025-05-29 11:50:21,605 - INFO - joeynmt.training - Example #4
2025-05-29 11:50:21,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:50:21,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:50:21,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'rapi@@', 'd', 'car@@', 'ri@@', 'ed', 'in', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:50:21,606 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:50:21,606 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:50:21,606 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a rapid carried in the last 25 years .
2025-05-29 11:50:41,519 - INFO - joeynmt.training - Epoch   7, Step:    27600, Batch Loss:     1.368134, Batch Acc: 0.610688, Tokens per Sec:     3548, Lr: 0.000300
2025-05-29 11:51:00,615 - INFO - joeynmt.training - Epoch   7, Step:    27700, Batch Loss:     1.385951, Batch Acc: 0.605159, Tokens per Sec:     3796, Lr: 0.000300
2025-05-29 11:51:20,803 - INFO - joeynmt.training - Epoch   7, Step:    27800, Batch Loss:     1.448615, Batch Acc: 0.609933, Tokens per Sec:     3531, Lr: 0.000300
2025-05-29 11:51:41,791 - INFO - joeynmt.training - Epoch   7, Step:    27900, Batch Loss:     1.495496, Batch Acc: 0.604343, Tokens per Sec:     3375, Lr: 0.000300
2025-05-29 11:52:02,221 - INFO - joeynmt.training - Epoch   7, Step:    28000, Batch Loss:     1.353685, Batch Acc: 0.604332, Tokens per Sec:     3559, Lr: 0.000300
2025-05-29 11:52:02,222 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:52:02,222 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:52:45,526 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.91, acc:   0.56, generation: 43.2964[sec], evaluation: 0.0000[sec]
2025-05-29 11:52:45,528 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 11:52:45,769 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/25500.ckpt
2025-05-29 11:52:45,772 - INFO - joeynmt.training - Example #0
2025-05-29 11:52:45,772 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:52:45,773 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:52:45,773 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'these', 'sli@@', 'de', 'to', 'show', 'that', 'the', 'sli@@', 'de', 'of', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ica', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', '.', '</s>']
2025-05-29 11:52:45,773 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:52:45,773 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:52:45,773 - INFO - joeynmt.training - 	Hypothesis: I showed these slide to show that the slide of the glacial calottica , which for almost three million years had 48 million years had the size of 48 million years had the size of 48 .
2025-05-29 11:52:45,773 - INFO - joeynmt.training - Example #1
2025-05-29 11:52:45,773 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:52:45,773 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:52:45,773 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'val@@', 'ue', 'the', 'problem', 'because', 'it', "'s", 'not', 'about', 'the', 'problem', 'because', 'it', "'s", 'not', 'the', 'sp@@', 'ac@@', 'ter', 'of', 'ice', '.', '</s>']
2025-05-29 11:52:45,773 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:52:45,773 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:52:45,773 - INFO - joeynmt.training - 	Hypothesis: But this subvalue the problem because it 's not about the problem because it 's not the spacter of ice .
2025-05-29 11:52:45,773 - INFO - joeynmt.training - Example #2
2025-05-29 11:52:45,773 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:52:45,773 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:52:45,773 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'Ar@@', 't@@', 'ica', "'s", 'gl@@', 'aci@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an@@', 'ing', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:52:45,773 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:52:45,773 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:52:45,773 - INFO - joeynmt.training - 	Hypothesis: The Artica 's glacial is , in a sense , the cleaning of the global climate system .
2025-05-29 11:52:45,773 - INFO - joeynmt.training - Example #3
2025-05-29 11:52:45,773 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:52:45,773 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:52:45,773 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'and@@', 'ed', 'up', 'the', 'w@@', 'int@@', 'er', 'and', 're@@', 'tre@@', 'at', '.', '</s>']
2025-05-29 11:52:45,774 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:52:45,774 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:52:45,774 - INFO - joeynmt.training - 	Hypothesis: You expanded up the winter and retreat .
2025-05-29 11:52:45,774 - INFO - joeynmt.training - Example #4
2025-05-29 11:52:45,774 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:52:45,774 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:52:45,774 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'positi@@', 've', 'will', 'be', 'a', 'rapi@@', 'd', 'car@@', 'ri@@', 'ed', 'in', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:52:45,774 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:52:45,774 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:52:45,774 - INFO - joeynmt.training - 	Hypothesis: The next positive will be a rapid carried in the last 25 years .
2025-05-29 11:53:05,622 - INFO - joeynmt.training - Epoch   7, Step:    28100, Batch Loss:     1.347356, Batch Acc: 0.608428, Tokens per Sec:     3479, Lr: 0.000300
2025-05-29 11:53:25,419 - INFO - joeynmt.training - Epoch   7, Step:    28200, Batch Loss:     1.456568, Batch Acc: 0.603851, Tokens per Sec:     3616, Lr: 0.000300
2025-05-29 11:53:43,539 - INFO - joeynmt.training - Epoch   7, Step:    28300, Batch Loss:     1.404658, Batch Acc: 0.599931, Tokens per Sec:     3858, Lr: 0.000300
2025-05-29 11:54:01,322 - INFO - joeynmt.training - Epoch   7, Step:    28400, Batch Loss:     1.280470, Batch Acc: 0.606309, Tokens per Sec:     3992, Lr: 0.000300
2025-05-29 11:54:19,467 - INFO - joeynmt.training - Epoch   7, Step:    28500, Batch Loss:     1.461782, Batch Acc: 0.611193, Tokens per Sec:     3997, Lr: 0.000300
2025-05-29 11:54:19,469 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:54:19,469 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:55:05,185 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.88, acc:   0.57, generation: 45.7070[sec], evaluation: 0.0000[sec]
2025-05-29 11:55:05,192 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 11:55:05,311 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/24500.ckpt
2025-05-29 11:55:05,315 - INFO - joeynmt.training - Example #0
2025-05-29 11:55:05,315 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:55:05,316 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:55:05,316 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'sli@@', 'de', 'c@@', 'alc@@', 'ul@@', 'us', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 't@@', 'ical', 'cal@@', 'ot@@', 'ter', ',', 'which', 'is', 'about', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', '.', 'It', "'s", 'stre@@', 't@@', 'ch', 'for', '40', 'percent', '.', '</s>']
2025-05-29 11:55:05,316 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:55:05,316 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:55:05,316 - INFO - joeynmt.training - 	Hypothesis: I showed these slides to show that the slide calculus to demonstrate that the artical calotter , which is about three million years had the size of 48 continental . It 's stretch for 40 percent .
2025-05-29 11:55:05,317 - INFO - joeynmt.training - Example #1
2025-05-29 11:55:05,317 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:55:05,317 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:55:05,317 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'est@@', 'im@@', 'ate', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'end@@', 'ing', 'of', 'ice', '.', '</s>']
2025-05-29 11:55:05,317 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:55:05,317 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:55:05,317 - INFO - joeynmt.training - 	Hypothesis: But this underestimate the gravity of the problem because it doesn 't show the spending of ice .
2025-05-29 11:55:05,317 - INFO - joeynmt.training - Example #2
2025-05-29 11:55:05,317 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:55:05,317 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:55:05,317 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ical', 'cal@@', 'ot@@', 'ter', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:55:05,317 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:55:05,317 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:55:05,317 - INFO - joeynmt.training - 	Hypothesis: The artical calotter is , in a sense , the clear heart of the global climate system .
2025-05-29 11:55:05,317 - INFO - joeynmt.training - Example #3
2025-05-29 11:55:05,318 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:55:05,318 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:55:05,318 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'and@@', 'ed', 'up', 'and', 'you', 'get', 'to', 'the', 'sum@@', 'mer', '.', '</s>']
2025-05-29 11:55:05,318 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:55:05,318 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:55:05,318 - INFO - joeynmt.training - 	Hypothesis: You expanded up and you get to the summer .
2025-05-29 11:55:05,318 - INFO - joeynmt.training - Example #4
2025-05-29 11:55:05,318 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:55:05,318 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:55:05,318 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'qu@@', 'ick', ',', 'is', 'going', 'to', 'be', 'a', 'little', 'bit', 'about', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:55:05,318 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:55:05,318 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:55:05,318 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quick , is going to be a little bit about the last 25 years .
2025-05-29 11:55:18,618 - INFO - joeynmt.training - Epoch   7: total training loss 5658.35
2025-05-29 11:55:18,619 - INFO - joeynmt.training - EPOCH 8
2025-05-29 11:55:25,995 - INFO - joeynmt.training - Epoch   8, Step:    28600, Batch Loss:     1.449054, Batch Acc: 0.630936, Tokens per Sec:     3463, Lr: 0.000300
2025-05-29 11:55:47,212 - INFO - joeynmt.training - Epoch   8, Step:    28700, Batch Loss:     1.382609, Batch Acc: 0.623451, Tokens per Sec:     3377, Lr: 0.000300
2025-05-29 11:56:07,284 - INFO - joeynmt.training - Epoch   8, Step:    28800, Batch Loss:     1.405434, Batch Acc: 0.628539, Tokens per Sec:     3488, Lr: 0.000300
2025-05-29 11:56:26,515 - INFO - joeynmt.training - Epoch   8, Step:    28900, Batch Loss:     1.231266, Batch Acc: 0.626351, Tokens per Sec:     3773, Lr: 0.000300
2025-05-29 11:56:45,692 - INFO - joeynmt.training - Epoch   8, Step:    29000, Batch Loss:     1.343926, Batch Acc: 0.628004, Tokens per Sec:     3808, Lr: 0.000300
2025-05-29 11:56:45,692 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:56:45,692 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:57:27,302 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.93, acc:   0.56, generation: 41.6001[sec], evaluation: 0.0000[sec]
2025-05-29 11:57:27,450 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/23500.ckpt
2025-05-29 11:57:27,456 - INFO - joeynmt.training - Example #0
2025-05-29 11:57:27,456 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:57:27,456 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:57:27,456 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'c@@', 'alc@@', 'ul@@', 'ot@@', 't@@', 'ical', 'c@@', 'alc@@', 'ul@@', 'ations', ',', 'which', 'for', 'almost', 'three', 'million', 'years', ',', 'which', 'is', 'about', '4@@', '8', 'dimen@@', 'sions', 'of', 'the', 'size', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', ',', 'is', 'about', '40', 'percent', '.', '</s>']
2025-05-29 11:57:27,456 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:57:27,456 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:57:27,456 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the glacial calculottical calculations , which for almost three million years , which is about 48 dimensions of the size of 48 continental , is about 40 percent .
2025-05-29 11:57:27,456 - INFO - joeynmt.training - Example #1
2025-05-29 11:57:27,457 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:57:27,457 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:57:27,457 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'val@@', 'ue', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'read@@', 'ing', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:57:27,457 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:57:27,457 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:57:27,457 - INFO - joeynmt.training - 	Hypothesis: But this subvalue the gravity of the problem because it doesn 't show the spreading of the ice .
2025-05-29 11:57:27,457 - INFO - joeynmt.training - Example #2
2025-05-29 11:57:27,457 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:57:27,457 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:57:27,457 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ical', 'c@@', 'alc@@', 'ul@@', 'ations', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', ',', 'the', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:57:27,457 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:57:27,457 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:57:27,457 - INFO - joeynmt.training - 	Hypothesis: The glacial calottical calculations is , in a sense , the clean , the heart of the global climate system .
2025-05-29 11:57:27,457 - INFO - joeynmt.training - Example #3
2025-05-29 11:57:27,457 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:57:27,457 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:57:27,457 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'an@@', 'ies', 'w@@', 'int@@', 'er', 'and', 'you', 'get', 'r@@', 'iti@@', 'ra', '.', '</s>']
2025-05-29 11:57:27,457 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:57:27,457 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:57:27,457 - INFO - joeynmt.training - 	Hypothesis: You expanies winter and you get ritira .
2025-05-29 11:57:27,457 - INFO - joeynmt.training - Example #4
2025-05-29 11:57:27,457 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:57:27,457 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:57:27,457 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'rapi@@', 'd', 'car@@', 'l@@', 'ated', 'on', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:57:27,458 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:57:27,458 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:57:27,458 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a rapid carlated on to the last 25 years .
2025-05-29 11:57:45,479 - INFO - joeynmt.training - Epoch   8, Step:    29100, Batch Loss:     1.594547, Batch Acc: 0.627421, Tokens per Sec:     3881, Lr: 0.000300
2025-05-29 11:58:04,240 - INFO - joeynmt.training - Epoch   8, Step:    29200, Batch Loss:     1.333358, Batch Acc: 0.627423, Tokens per Sec:     3878, Lr: 0.000300
2025-05-29 11:58:22,656 - INFO - joeynmt.training - Epoch   8, Step:    29300, Batch Loss:     1.255618, Batch Acc: 0.627872, Tokens per Sec:     3991, Lr: 0.000300
2025-05-29 11:58:42,278 - INFO - joeynmt.training - Epoch   8, Step:    29400, Batch Loss:     1.347855, Batch Acc: 0.624479, Tokens per Sec:     3510, Lr: 0.000300
2025-05-29 11:59:03,438 - INFO - joeynmt.training - Epoch   8, Step:    29500, Batch Loss:     1.250764, Batch Acc: 0.624381, Tokens per Sec:     3425, Lr: 0.000300
2025-05-29 11:59:03,439 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 11:59:03,439 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 11:59:52,771 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.96, acc:   0.56, generation: 49.3226[sec], evaluation: 0.0000[sec]
2025-05-29 11:59:52,908 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/27000.ckpt
2025-05-29 11:59:52,911 - INFO - joeynmt.training - Example #0
2025-05-29 11:59:52,911 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 11:59:52,911 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 11:59:52,911 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'these', 'de@@', 'b@@', 'ated', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'H@@', 'e@@', 'al@@', 't@@', 'ical', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', ',', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'United', 'States', ',', 'it', "'s", 'going', 'to', 'be', '40', 'percent', '.', '</s>']
2025-05-29 11:59:52,911 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 11:59:52,911 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 11:59:52,911 - INFO - joeynmt.training - 	Hypothesis: I showed these debated slides to show that the Healtical ice ice ice ice ice ice ice ice ice ice ice ice ice ice ice ice ice , for almost three million years had the size of 48 United States , it 's going to be 40 percent .
2025-05-29 11:59:52,911 - INFO - joeynmt.training - Example #1
2025-05-29 11:59:52,911 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 11:59:52,911 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 11:59:52,911 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'read@@', 'ing', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 11:59:52,911 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 11:59:52,911 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 11:59:52,911 - INFO - joeynmt.training - 	Hypothesis: But this is a gravity of the problem because it doesn 't show the spreading the ice of the ice .
2025-05-29 11:59:52,912 - INFO - joeynmt.training - Example #2
2025-05-29 11:59:52,912 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 11:59:52,912 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 11:59:52,912 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'gl@@', 'aci@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', ',', 'the', 'cle@@', 'an', 'heart', 'of', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 11:59:52,912 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 11:59:52,912 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 11:59:52,912 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial is , in a sense , the clean , the clean heart of global climate system .
2025-05-29 11:59:52,912 - INFO - joeynmt.training - Example #3
2025-05-29 11:59:52,912 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 11:59:52,912 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 11:59:52,912 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'ands', 'up', 'the', 'w@@', 'int@@', 'er', 'and', 'you', 'get', 'r@@', 'iti@@', 'ra', '.', '</s>']
2025-05-29 11:59:52,912 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 11:59:52,912 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 11:59:52,912 - INFO - joeynmt.training - 	Hypothesis: You expands up the winter and you get ritira .
2025-05-29 11:59:52,912 - INFO - joeynmt.training - Example #4
2025-05-29 11:59:52,912 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 11:59:52,912 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 11:59:52,912 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'qu@@', 'ick', ',', 'it', 'will', 'be', 'a', 'qu@@', 'ick', ',', 'in', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 11:59:52,912 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 11:59:52,913 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 11:59:52,913 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quick , it will be a quick , in the last 25 years .
2025-05-29 12:00:12,483 - INFO - joeynmt.training - Epoch   8, Step:    29600, Batch Loss:     1.451918, Batch Acc: 0.619817, Tokens per Sec:     3638, Lr: 0.000300
2025-05-29 12:00:30,777 - INFO - joeynmt.training - Epoch   8, Step:    29700, Batch Loss:     1.511297, Batch Acc: 0.616094, Tokens per Sec:     3898, Lr: 0.000300
2025-05-29 12:00:49,155 - INFO - joeynmt.training - Epoch   8, Step:    29800, Batch Loss:     1.351194, Batch Acc: 0.620930, Tokens per Sec:     3983, Lr: 0.000300
2025-05-29 12:01:06,714 - INFO - joeynmt.training - Epoch   8, Step:    29900, Batch Loss:     1.497437, Batch Acc: 0.621281, Tokens per Sec:     3987, Lr: 0.000300
2025-05-29 12:01:24,035 - INFO - joeynmt.training - Epoch   8, Step:    30000, Batch Loss:     1.640254, Batch Acc: 0.621562, Tokens per Sec:     4024, Lr: 0.000300
2025-05-29 12:01:24,036 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:01:24,036 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:02:03,514 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.92, acc:   0.56, generation: 39.4694[sec], evaluation: 0.0000[sec]
2025-05-29 12:02:03,625 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/29500.ckpt
2025-05-29 12:02:03,626 - INFO - joeynmt.helpers - delete /Users/jingma/Desktop/machine_translation/mt-exercise-4/models/transformer_bpe_3200/29500.ckpt
2025-05-29 12:02:03,626 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/jingma/Desktop/machine_translation/mt-exercise-4/models/transformer_bpe_3200/29500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/jingma/Desktop/machine_translation/mt-exercise-4/models/transformer_bpe_3200/29500.ckpt')
2025-05-29 12:02:03,627 - INFO - joeynmt.training - Example #0
2025-05-29 12:02:03,627 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:02:03,627 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:02:03,627 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', ',', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', ',', 'for', 'almost', 'three', 'million', 'years', ',', 'had', 'the', 'size', 'of', '4@@', '8', 'United', 'States', ',', 'it', "'s", '40', 'percent', '.', '</s>']
2025-05-29 12:02:03,627 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:02:03,627 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:02:03,627 - INFO - joeynmt.training - 	Hypothesis: Last year , I showed these slides to show that the ice ice ice ice ice ice ice ice ice ice ice ice ice ice ice ice , for almost three million years , had the size of 48 United States , it 's 40 percent .
2025-05-29 12:02:03,627 - INFO - joeynmt.training - Example #1
2025-05-29 12:02:03,627 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:02:03,627 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:02:03,627 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'val@@', 'u@@', 'able', 'to', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'read@@', 'ing', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 12:02:03,627 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:02:03,627 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:02:03,627 - INFO - joeynmt.training - 	Hypothesis: But this subvaluable to the gravity of the problem because it doesn 't show the spreading of the ice .
2025-05-29 12:02:03,627 - INFO - joeynmt.training - Example #2
2025-05-29 12:02:03,627 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:02:03,627 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:02:03,627 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'ter', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:02:03,628 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:02:03,628 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:02:03,628 - INFO - joeynmt.training - 	Hypothesis: The glacial calotter is , in a sense , the clear heart of the global climate system .
2025-05-29 12:02:03,628 - INFO - joeynmt.training - Example #3
2025-05-29 12:02:03,628 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:02:03,628 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:02:03,628 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'turns', 'out', 'you', 'w@@', 'int@@', 'er', 'and', 'you', 'get', 'r@@', 'iti@@', 'ra', '.', '</s>']
2025-05-29 12:02:03,628 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:02:03,628 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:02:03,628 - INFO - joeynmt.training - 	Hypothesis: It turns out you winter and you get ritira .
2025-05-29 12:02:03,628 - INFO - joeynmt.training - Example #4
2025-05-29 12:02:03,628 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:02:03,628 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:02:03,628 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rapi@@', 'd', 'car@@', 'rel@@', 'ated', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:02:03,628 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:02:03,628 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:02:03,628 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid carrelated to the last 25 years .
2025-05-29 12:02:21,321 - INFO - joeynmt.training - Epoch   8, Step:    30100, Batch Loss:     1.501704, Batch Acc: 0.620343, Tokens per Sec:     4029, Lr: 0.000300
2025-05-29 12:02:39,156 - INFO - joeynmt.training - Epoch   8, Step:    30200, Batch Loss:     1.225147, Batch Acc: 0.622093, Tokens per Sec:     4015, Lr: 0.000300
2025-05-29 12:02:57,235 - INFO - joeynmt.training - Epoch   8, Step:    30300, Batch Loss:     1.343823, Batch Acc: 0.618794, Tokens per Sec:     3806, Lr: 0.000300
2025-05-29 12:03:14,733 - INFO - joeynmt.training - Epoch   8, Step:    30400, Batch Loss:     1.353433, Batch Acc: 0.614347, Tokens per Sec:     4115, Lr: 0.000300
2025-05-29 12:03:32,323 - INFO - joeynmt.training - Epoch   8, Step:    30500, Batch Loss:     1.274397, Batch Acc: 0.613419, Tokens per Sec:     4072, Lr: 0.000300
2025-05-29 12:03:32,324 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:03:32,324 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:04:18,908 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.91, acc:   0.56, generation: 46.5768[sec], evaluation: 0.0000[sec]
2025-05-29 12:04:19,018 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/27500.ckpt
2025-05-29 12:04:19,021 - INFO - joeynmt.training - Example #0
2025-05-29 12:04:19,021 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:04:19,021 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:04:19,021 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'these', 'de@@', 'vic@@', 'es', 'to', 'show', 'that', 'the', 'sli@@', 'de', 'of', 'the', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'ter', ',', 'which', 'for', 'almost', 'three', 'million', 'years', ',', 'had', 'the', 'size', 'of', '4@@', '8', 'United', 'States', ',', 'it', "'s", 'been', 'clo@@', 'se', 'to', '40', 'percent', '.', '</s>']
2025-05-29 12:04:19,022 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:04:19,022 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:04:19,022 - INFO - joeynmt.training - 	Hypothesis: I showed these devices to show that the slide of the demonstrate that the glacial calotter , which for almost three million years , had the size of 48 United States , it 's been close to 40 percent .
2025-05-29 12:04:19,022 - INFO - joeynmt.training - Example #1
2025-05-29 12:04:19,022 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:04:19,022 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:04:19,022 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'ne@@', 'ath', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', "'s", 'not', 'sho@@', 'wing', 'the', 'p@@', 'ess@@', 'or', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 12:04:19,022 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:04:19,022 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:04:19,022 - INFO - joeynmt.training - 	Hypothesis: But this underneath the gravity of the problem because it 's not showing the pessor of the ice .
2025-05-29 12:04:19,022 - INFO - joeynmt.training - Example #2
2025-05-29 12:04:19,022 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:04:19,022 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:04:19,022 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'Ar@@', 'c@@', 'tic', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:04:19,022 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:04:19,022 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:04:19,022 - INFO - joeynmt.training - 	Hypothesis: The Arctic ice is , in a sense , the clear of the global climate system .
2025-05-29 12:04:19,022 - INFO - joeynmt.training - Example #3
2025-05-29 12:04:19,022 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:04:19,022 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:04:19,022 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'ands', 'up', 'to', 'the', 'w@@', 'int@@', 'er', 'and', 'you', 're@@', 'tre@@', 'at', 'the', 'end', '.', '</s>']
2025-05-29 12:04:19,022 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:04:19,023 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:04:19,023 - INFO - joeynmt.training - 	Hypothesis: You expands up to the winter and you retreat the end .
2025-05-29 12:04:19,023 - INFO - joeynmt.training - Example #4
2025-05-29 12:04:19,023 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:04:19,023 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:04:19,023 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'f@@', 'ast', 'car@@', 'rel@@', 'ated', 'to', 'the', 'ad@@', 'v@@', 'anc@@', 'ed', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:04:19,023 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:04:19,023 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:04:19,023 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a fast carrelated to the advanced of the last 25 years .
2025-05-29 12:04:37,036 - INFO - joeynmt.training - Epoch   8, Step:    30600, Batch Loss:     1.261659, Batch Acc: 0.622409, Tokens per Sec:     4011, Lr: 0.000300
2025-05-29 12:04:54,863 - INFO - joeynmt.training - Epoch   8, Step:    30700, Batch Loss:     1.332900, Batch Acc: 0.621020, Tokens per Sec:     3950, Lr: 0.000300
2025-05-29 12:05:12,701 - INFO - joeynmt.training - Epoch   8, Step:    30800, Batch Loss:     1.371936, Batch Acc: 0.620170, Tokens per Sec:     3983, Lr: 0.000300
2025-05-29 12:05:31,449 - INFO - joeynmt.training - Epoch   8, Step:    30900, Batch Loss:     1.210127, Batch Acc: 0.620181, Tokens per Sec:     3765, Lr: 0.000300
2025-05-29 12:05:48,928 - INFO - joeynmt.training - Epoch   8, Step:    31000, Batch Loss:     1.343503, Batch Acc: 0.618718, Tokens per Sec:     4024, Lr: 0.000300
2025-05-29 12:05:48,929 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:05:48,929 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:06:34,334 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.92, acc:   0.56, generation: 45.3980[sec], evaluation: 0.0000[sec]
2025-05-29 12:06:34,462 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/29000.ckpt
2025-05-29 12:06:34,465 - INFO - joeynmt.training - Example #0
2025-05-29 12:06:34,465 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:06:34,465 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:06:34,465 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'next', 'next', 'next', 'year', ',', 'which', 'is', 'about', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'which', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'United', 'States', ',', 'it', "'s", 're@@', 'mark@@', 'able', 'to', 'the', 'U.@@', 'S.', ',', 'it', "'s", 're@@', 'mark@@', 'able', '40', 'percent', '.', '</s>']
2025-05-29 12:06:34,466 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:06:34,466 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:06:34,466 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the next next next year , which is about three million years had the size of 48 , which almost three million years had the size of 48 , the United States , it 's remarkable to the U.S. , it 's remarkable 40 percent .
2025-05-29 12:06:34,466 - INFO - joeynmt.training - Example #1
2025-05-29 12:06:34,466 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:06:34,466 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:06:34,466 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho@@', 'w@@', 'ever', 'this', 'under@@', 'water', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ent', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 12:06:34,466 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:06:34,466 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:06:34,466 - INFO - joeynmt.training - 	Hypothesis: However this underwater gravity of the problem because it doesn 't show the spent of the ice .
2025-05-29 12:06:34,466 - INFO - joeynmt.training - Example #2
2025-05-29 12:06:34,466 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:06:34,466 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:06:34,466 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ci@@', 'al', 'ho@@', 't', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'c@@', 'y@@', 'cle', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:06:34,466 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:06:34,466 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:06:34,466 - INFO - joeynmt.training - 	Hypothesis: The arccial hot is , in a sense , the clear cycle of the global climate system .
2025-05-29 12:06:34,466 - INFO - joeynmt.training - Example #3
2025-05-29 12:06:34,466 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:06:34,466 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:06:34,466 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'going', 'down', 'to', 'w@@', 'int@@', 'er', 'and', 'you', 'r@@', 'ate', '.', '</s>']
2025-05-29 12:06:34,466 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:06:34,466 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:06:34,466 - INFO - joeynmt.training - 	Hypothesis: It 's going down to winter and you rate .
2025-05-29 12:06:34,466 - INFO - joeynmt.training - Example #4
2025-05-29 12:06:34,466 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:06:34,466 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:06:34,467 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'qu@@', 'ick', ',', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'ri@@', 'ed', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:06:34,467 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:06:34,467 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:06:34,467 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quick , is going to be a quick carried on the last 25 years .
2025-05-29 12:06:51,800 - INFO - joeynmt.training - Epoch   8, Step:    31100, Batch Loss:     1.395655, Batch Acc: 0.615150, Tokens per Sec:     3931, Lr: 0.000300
2025-05-29 12:07:09,674 - INFO - joeynmt.training - Epoch   8, Step:    31200, Batch Loss:     1.281375, Batch Acc: 0.616228, Tokens per Sec:     3979, Lr: 0.000300
2025-05-29 12:07:26,967 - INFO - joeynmt.training - Epoch   8, Step:    31300, Batch Loss:     1.258299, Batch Acc: 0.618950, Tokens per Sec:     4044, Lr: 0.000300
2025-05-29 12:07:44,808 - INFO - joeynmt.training - Epoch   8, Step:    31400, Batch Loss:     1.381874, Batch Acc: 0.613850, Tokens per Sec:     3843, Lr: 0.000300
2025-05-29 12:08:02,876 - INFO - joeynmt.training - Epoch   8, Step:    31500, Batch Loss:     1.524752, Batch Acc: 0.614800, Tokens per Sec:     3957, Lr: 0.000300
2025-05-29 12:08:02,877 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:08:02,877 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:08:49,545 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.90, acc:   0.56, generation: 46.6608[sec], evaluation: 0.0000[sec]
2025-05-29 12:08:49,716 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/30000.ckpt
2025-05-29 12:08:49,719 - INFO - joeynmt.training - Example #0
2025-05-29 12:08:49,719 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:08:49,719 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:08:49,719 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'last', 'year', ',', 'I', 'sho@@', 'wed', 'these', 'de@@', 'mon@@', 'str@@', 'ate', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'cal@@', 'ot@@', 'ter', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'has', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'size', 'of', 'the', '4@@', '8', ',', 'is', 're@@', 'mark@@', 'able', 'of', '40', 'percent', '.', '</s>']
2025-05-29 12:08:49,719 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:08:49,719 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:08:49,719 - INFO - joeynmt.training - 	Hypothesis: And last year , I showed these demonstrate demonstrate that the arctic calotter , which for almost three million years has had the size of 48 , the size of 48 , the size of the 48 , is remarkable of 40 percent .
2025-05-29 12:08:49,719 - INFO - joeynmt.training - Example #1
2025-05-29 12:08:49,719 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:08:49,719 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:08:49,719 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'val@@', 'u@@', 'able', 'to', 'gr@@', 'av@@', 'ity', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sh@@', 'ore', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 12:08:49,720 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:08:49,720 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:08:49,720 - INFO - joeynmt.training - 	Hypothesis: But this subvaluable to gravity the gravity of the problem because it doesn 't show the shore of the ice .
2025-05-29 12:08:49,720 - INFO - joeynmt.training - Example #2
2025-05-29 12:08:49,720 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:08:49,720 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:08:49,720 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'ter', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:08:49,720 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:08:49,720 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:08:49,720 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial calotter is , in a sense , the clear heart of global climate system .
2025-05-29 12:08:49,720 - INFO - joeynmt.training - Example #3
2025-05-29 12:08:49,720 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:08:49,720 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:08:49,720 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'exp@@', 'and@@', 'ed', 'up', 'and', 're@@', 'tre@@', 'at@@', 's', '.', '</s>']
2025-05-29 12:08:49,720 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:08:49,720 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:08:49,720 - INFO - joeynmt.training - 	Hypothesis: It 's expanded up and retreats .
2025-05-29 12:08:49,720 - INFO - joeynmt.training - Example #4
2025-05-29 12:08:49,720 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:08:49,720 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:08:49,720 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rapi@@', 'd@@', 'ly', 'car@@', 'rel@@', 'ated', 'to', 'the', 'ad@@', 'v@@', 'v@@', 'oc@@', 'ate', 'over', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:08:49,720 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:08:49,720 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:08:49,720 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapidly carrelated to the advvocate over the last 25 years .
2025-05-29 12:09:07,237 - INFO - joeynmt.training - Epoch   8, Step:    31600, Batch Loss:     1.337952, Batch Acc: 0.620324, Tokens per Sec:     4017, Lr: 0.000300
2025-05-29 12:09:25,270 - INFO - joeynmt.training - Epoch   8, Step:    31700, Batch Loss:     1.441963, Batch Acc: 0.615255, Tokens per Sec:     3882, Lr: 0.000300
2025-05-29 12:09:43,264 - INFO - joeynmt.training - Epoch   8, Step:    31800, Batch Loss:     1.436380, Batch Acc: 0.620812, Tokens per Sec:     3961, Lr: 0.000300
2025-05-29 12:10:01,551 - INFO - joeynmt.training - Epoch   8, Step:    31900, Batch Loss:     1.380783, Batch Acc: 0.616227, Tokens per Sec:     3896, Lr: 0.000300
2025-05-29 12:10:18,895 - INFO - joeynmt.training - Epoch   8, Step:    32000, Batch Loss:     1.335849, Batch Acc: 0.615660, Tokens per Sec:     4160, Lr: 0.000300
2025-05-29 12:10:18,896 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:10:18,896 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:11:02,323 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.85, acc:   0.57, generation: 43.4195[sec], evaluation: 0.0000[sec]
2025-05-29 12:11:02,325 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 12:11:02,524 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/31000.ckpt
2025-05-29 12:11:02,527 - INFO - joeynmt.training - Example #0
2025-05-29 12:11:02,527 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:11:02,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:11:02,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'sc@@', 're@@', 'p@@', 'air', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'ter', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'of', 'the', 'size', 'of', '4@@', '8', 'percent', '.', '</s>']
2025-05-29 12:11:02,528 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:11:02,528 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:11:02,528 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to demonstrate that the screpair that the glacial calotter , which for almost three million years had the size of 48 million years of the size of 48 percent .
2025-05-29 12:11:02,528 - INFO - joeynmt.training - Example #1
2025-05-29 12:11:02,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:11:02,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:11:02,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho@@', 'w@@', 'ever', ',', 'this', 'sub@@', 'val@@', 'ue', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ac@@', 'es', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 12:11:02,528 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:11:02,528 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:11:02,528 - INFO - joeynmt.training - 	Hypothesis: However , this subvalue the problem because it doesn 't show the spaces of the ice .
2025-05-29 12:11:02,528 - INFO - joeynmt.training - Example #2
2025-05-29 12:11:02,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:11:02,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:11:02,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'ter', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:11:02,528 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:11:02,528 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:11:02,528 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial calotter is , in a sense , the clear of the global climate system .
2025-05-29 12:11:02,528 - INFO - joeynmt.training - Example #3
2025-05-29 12:11:02,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:11:02,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:11:02,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'exp@@', 'and@@', 'ed', 'and', 'you', 'get', 'r@@', 'iti@@', 'g@@', 'en', 'on', 'the', 'sum@@', 'mer', '.', '</s>']
2025-05-29 12:11:02,529 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:11:02,529 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:11:02,529 - INFO - joeynmt.training - 	Hypothesis: It 's expanded and you get ritigen on the summer .
2025-05-29 12:11:02,529 - INFO - joeynmt.training - Example #4
2025-05-29 12:11:02,529 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:11:02,529 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:11:02,529 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rapi@@', 'd', 'car@@', 'ri@@', 'ed', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:11:02,529 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:11:02,529 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:11:02,529 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid carried on the last 25 years .
2025-05-29 12:11:20,152 - INFO - joeynmt.training - Epoch   8, Step:    32100, Batch Loss:     1.270651, Batch Acc: 0.615808, Tokens per Sec:     4109, Lr: 0.000300
2025-05-29 12:11:38,299 - INFO - joeynmt.training - Epoch   8, Step:    32200, Batch Loss:     1.231624, Batch Acc: 0.616767, Tokens per Sec:     3894, Lr: 0.000300
2025-05-29 12:11:56,300 - INFO - joeynmt.training - Epoch   8, Step:    32300, Batch Loss:     1.368223, Batch Acc: 0.613769, Tokens per Sec:     4013, Lr: 0.000300
2025-05-29 12:12:15,118 - INFO - joeynmt.training - Epoch   8, Step:    32400, Batch Loss:     1.384140, Batch Acc: 0.615310, Tokens per Sec:     3723, Lr: 0.000300
2025-05-29 12:12:32,893 - INFO - joeynmt.training - Epoch   8, Step:    32500, Batch Loss:     1.317960, Batch Acc: 0.605756, Tokens per Sec:     3892, Lr: 0.000300
2025-05-29 12:12:32,895 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:12:32,895 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:13:18,773 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.87, acc:   0.57, generation: 45.8711[sec], evaluation: 0.0000[sec]
2025-05-29 12:13:18,931 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/30500.ckpt
2025-05-29 12:13:18,935 - INFO - joeynmt.training - Example #0
2025-05-29 12:13:18,935 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:13:18,935 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:13:18,935 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'these', 'sli@@', 'de', 'de@@', 'mon@@', 'str@@', 'ated', 'sli@@', 'de', 'that', 'the', 'ar@@', 'c@@', 'cal@@', 'ot@@', 'ter', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'has', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', '.', '</s>']
2025-05-29 12:13:18,935 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:13:18,935 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:13:18,935 - INFO - joeynmt.training - 	Hypothesis: I showed these slide demonstrated slide that the arccalotter , which for almost three million years has 48 million years had the size of 48 million years had the size of 48 .
2025-05-29 12:13:18,935 - INFO - joeynmt.training - Example #1
2025-05-29 12:13:18,935 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:13:18,935 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:13:18,935 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'val@@', 'u@@', 'able', 'to', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'read@@', 'ing', '.', '</s>']
2025-05-29 12:13:18,935 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:13:18,935 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:13:18,935 - INFO - joeynmt.training - 	Hypothesis: But this subvaluable to gravity of the problem because it doesn 't show the spreading .
2025-05-29 12:13:18,935 - INFO - joeynmt.training - Example #2
2025-05-29 12:13:18,935 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:13:18,935 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:13:18,935 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'c@@', 'alc@@', 'ul@@', 'ot@@', 'ter', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'c@@', 'y@@', 'cle', 'of', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:13:18,936 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:13:18,936 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:13:18,936 - INFO - joeynmt.training - 	Hypothesis: The arccalculotter is , in a sense , the clear cycle of global climate system .
2025-05-29 12:13:18,936 - INFO - joeynmt.training - Example #3
2025-05-29 12:13:18,936 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:13:18,936 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:13:18,936 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'exp@@', 'ands', 'up', 'on', 'sum@@', 'mer', '.', '</s>']
2025-05-29 12:13:18,936 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:13:18,936 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:13:18,936 - INFO - joeynmt.training - 	Hypothesis: It expands up on summer .
2025-05-29 12:13:18,936 - INFO - joeynmt.training - Example #4
2025-05-29 12:13:18,936 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:13:18,936 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:13:18,936 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'rel@@', 'ated', 'to', 'the', 'ad@@', 'v@@', 'v@@', 'oc@@', 'ate', 'over', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:13:18,936 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:13:18,936 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:13:18,936 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick carrelated to the advvocate over the last 25 years .
2025-05-29 12:13:37,305 - INFO - joeynmt.training - Epoch   8, Step:    32600, Batch Loss:     1.394327, Batch Acc: 0.617872, Tokens per Sec:     3868, Lr: 0.000300
2025-05-29 12:13:46,298 - INFO - joeynmt.training - Epoch   8: total training loss 5504.83
2025-05-29 12:13:46,300 - INFO - joeynmt.training - EPOCH 9
2025-05-29 12:13:55,232 - INFO - joeynmt.training - Epoch   9, Step:    32700, Batch Loss:     1.262095, Batch Acc: 0.640600, Tokens per Sec:     4049, Lr: 0.000300
2025-05-29 12:14:12,403 - INFO - joeynmt.training - Epoch   9, Step:    32800, Batch Loss:     1.284927, Batch Acc: 0.645731, Tokens per Sec:     4166, Lr: 0.000300
2025-05-29 12:14:29,879 - INFO - joeynmt.training - Epoch   9, Step:    32900, Batch Loss:     1.212421, Batch Acc: 0.636743, Tokens per Sec:     4068, Lr: 0.000300
2025-05-29 12:14:47,731 - INFO - joeynmt.training - Epoch   9, Step:    33000, Batch Loss:     1.313753, Batch Acc: 0.639715, Tokens per Sec:     3952, Lr: 0.000300
2025-05-29 12:14:47,732 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:14:47,732 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:15:28,487 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.89, acc:   0.57, generation: 40.7467[sec], evaluation: 0.0000[sec]
2025-05-29 12:15:28,656 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/28000.ckpt
2025-05-29 12:15:28,660 - INFO - joeynmt.training - Example #0
2025-05-29 12:15:28,660 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:15:28,660 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:15:28,660 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'ter', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'has', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'United', 'States', ',', 'is', 're@@', 'ach@@', 'ing', '40', 'percent', '.', '</s>']
2025-05-29 12:15:28,660 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:15:28,660 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:15:28,660 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the glacial calotter , which for almost three million years has had the size of the 48 million years had the size of 48 United States , is reaching 40 percent .
2025-05-29 12:15:28,660 - INFO - joeynmt.training - Example #1
2025-05-29 12:15:28,660 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:15:28,660 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:15:28,660 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'val@@', 'u@@', 'able', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', "'s", 'not', 'shows', 'the', 'sp@@', 'ess@@', 'or', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 12:15:28,660 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:15:28,660 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:15:28,660 - INFO - joeynmt.training - 	Hypothesis: But this undervaluable gravity of the problem because it 's not shows the spessor of the ice .
2025-05-29 12:15:28,660 - INFO - joeynmt.training - Example #2
2025-05-29 12:15:28,660 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:15:28,660 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:15:28,660 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'gl@@', 'aci@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:15:28,661 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:15:28,661 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:15:28,661 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial is , in a sense , the clear heart of the global climate system .
2025-05-29 12:15:28,661 - INFO - joeynmt.training - Example #3
2025-05-29 12:15:28,661 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:15:28,661 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:15:28,661 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'w@@', 'int@@', 'er', 'and', 're@@', 'tre@@', 'ated', '.', '</s>']
2025-05-29 12:15:28,661 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:15:28,661 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:15:28,661 - INFO - joeynmt.training - 	Hypothesis: It 's winter and retreated .
2025-05-29 12:15:28,661 - INFO - joeynmt.training - Example #4
2025-05-29 12:15:28,661 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:15:28,661 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:15:28,661 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'ri@@', 'ed', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:15:28,661 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:15:28,661 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:15:28,661 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick carried on the last 25 years .
2025-05-29 12:15:47,749 - INFO - joeynmt.training - Epoch   9, Step:    33100, Batch Loss:     1.260856, Batch Acc: 0.634145, Tokens per Sec:     3706, Lr: 0.000300
2025-05-29 12:16:13,335 - INFO - joeynmt.training - Epoch   9, Step:    33200, Batch Loss:     1.307407, Batch Acc: 0.637595, Tokens per Sec:     2784, Lr: 0.000300
2025-05-29 12:16:39,600 - INFO - joeynmt.training - Epoch   9, Step:    33300, Batch Loss:     1.254647, Batch Acc: 0.632608, Tokens per Sec:     2723, Lr: 0.000300
2025-05-29 12:17:02,190 - INFO - joeynmt.training - Epoch   9, Step:    33400, Batch Loss:     1.361021, Batch Acc: 0.632084, Tokens per Sec:     3181, Lr: 0.000300
2025-05-29 12:17:23,360 - INFO - joeynmt.training - Epoch   9, Step:    33500, Batch Loss:     1.409087, Batch Acc: 0.629007, Tokens per Sec:     3191, Lr: 0.000300
2025-05-29 12:17:23,361 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:17:23,361 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:18:07,959 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.93, acc:   0.56, generation: 44.5892[sec], evaluation: 0.0000[sec]
2025-05-29 12:18:07,963 - INFO - joeynmt.training - Example #0
2025-05-29 12:18:07,963 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:18:07,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:18:07,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'show', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 't@@', 'c', 'cal@@', 'ot@@', 't@@', '-@@', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', '-@@', 'size', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 12:18:07,964 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:18:07,964 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:18:07,964 - INFO - joeynmt.training - 	Hypothesis: And I showed these slides to show these slides to show that the artc calott-glacial calott-size , which for almost three million years had the size of 48 continental .
2025-05-29 12:18:07,964 - INFO - joeynmt.training - Example #1
2025-05-29 12:18:07,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:18:07,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:18:07,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'just', 'a', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sh@@', 'ore', 'of', 'ice', '.', '</s>']
2025-05-29 12:18:07,964 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:18:07,964 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:18:07,964 - INFO - joeynmt.training - 	Hypothesis: It 's just a gravity of the problem because it doesn 't show the shore of ice .
2025-05-29 12:18:07,964 - INFO - joeynmt.training - Example #2
2025-05-29 12:18:07,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:18:07,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:18:07,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'c', 'cal@@', 'ot@@', 't@@', 'ica', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:18:07,964 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:18:07,964 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:18:07,964 - INFO - joeynmt.training - 	Hypothesis: The artc calottica is , in a sense , the clear heart of the global climate system .
2025-05-29 12:18:07,964 - INFO - joeynmt.training - Example #3
2025-05-29 12:18:07,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:18:07,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:18:07,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'exp@@', 'and@@', 'ed', 'w@@', 'id@@', 'th', 'and', 're@@', 'tre@@', 'at@@', 'ment', '.', '</s>']
2025-05-29 12:18:07,965 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:18:07,965 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:18:07,965 - INFO - joeynmt.training - 	Hypothesis: It expanded width and retreatment .
2025-05-29 12:18:07,965 - INFO - joeynmt.training - Example #4
2025-05-29 12:18:07,965 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:18:07,965 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:18:07,965 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rapi@@', 'd', 'car@@', 'rel@@', 'ed', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:18:07,965 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:18:07,965 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:18:07,965 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid carreled on the last 25 years .
2025-05-29 12:18:26,395 - INFO - joeynmt.training - Epoch   9, Step:    33600, Batch Loss:     1.307636, Batch Acc: 0.624519, Tokens per Sec:     3696, Lr: 0.000300
2025-05-29 12:18:45,759 - INFO - joeynmt.training - Epoch   9, Step:    33700, Batch Loss:     1.490060, Batch Acc: 0.626630, Tokens per Sec:     3635, Lr: 0.000300
2025-05-29 12:19:05,011 - INFO - joeynmt.training - Epoch   9, Step:    33800, Batch Loss:     1.345544, Batch Acc: 0.629992, Tokens per Sec:     3833, Lr: 0.000300
2025-05-29 12:19:23,973 - INFO - joeynmt.training - Epoch   9, Step:    33900, Batch Loss:     1.300490, Batch Acc: 0.629652, Tokens per Sec:     3822, Lr: 0.000300
2025-05-29 12:19:44,695 - INFO - joeynmt.training - Epoch   9, Step:    34000, Batch Loss:     1.158286, Batch Acc: 0.629682, Tokens per Sec:     3467, Lr: 0.000300
2025-05-29 12:19:44,696 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:19:44,696 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:20:29,113 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.91, acc:   0.56, generation: 44.4096[sec], evaluation: 0.0000[sec]
2025-05-29 12:20:29,117 - INFO - joeynmt.training - Example #0
2025-05-29 12:20:29,117 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:20:29,117 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:20:29,117 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'this', 'sli@@', 'de', 'to', 'show', 'that', 'the', 'sli@@', 'de', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 12:20:29,118 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:20:29,118 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:20:29,118 - INFO - joeynmt.training - 	Hypothesis: I showed this slide to show that the slide that the glacial calott , which for almost three million years had the size of the 48 million years had the size of the 48 continental .
2025-05-29 12:20:29,118 - INFO - joeynmt.training - Example #1
2025-05-29 12:20:29,118 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:20:29,118 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:20:29,118 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'val@@', 'u@@', 'able', 'to', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 12:20:29,118 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:20:29,118 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:20:29,118 - INFO - joeynmt.training - 	Hypothesis: But this subvaluable to the gravity of the problem because it doesn 't show the ice of the ice .
2025-05-29 12:20:29,118 - INFO - joeynmt.training - Example #2
2025-05-29 12:20:29,118 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:20:29,118 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:20:29,118 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'cal@@', 'ot@@', 't', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', 'c@@', 'y@@', 'cle', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:20:29,118 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:20:29,118 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:20:29,118 - INFO - joeynmt.training - 	Hypothesis: The arccalott is , in a sense , the clean cycle of the global climate system .
2025-05-29 12:20:29,118 - INFO - joeynmt.training - Example #3
2025-05-29 12:20:29,118 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:20:29,118 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:20:29,118 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'exp@@', 'ands', 'up', 'in', 'the', 'w@@', 'int@@', 'er', 'and', 'you', 'get', 'on', 'sum@@', 'mer', '.', '</s>']
2025-05-29 12:20:29,118 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:20:29,118 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:20:29,119 - INFO - joeynmt.training - 	Hypothesis: It expands up in the winter and you get on summer .
2025-05-29 12:20:29,119 - INFO - joeynmt.training - Example #4
2025-05-29 12:20:29,119 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:20:29,119 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:20:29,119 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'rapi@@', 'd', 'car@@', 'ri@@', 'ed', 'on', 'the', 'ad@@', 'v@@', 'anc@@', 'ed', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:20:29,119 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:20:29,119 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:20:29,119 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a rapid carried on the advanced of the last 25 years .
2025-05-29 12:20:46,690 - INFO - joeynmt.training - Epoch   9, Step:    34100, Batch Loss:     1.343337, Batch Acc: 0.628348, Tokens per Sec:     4155, Lr: 0.000300
2025-05-29 12:21:04,296 - INFO - joeynmt.training - Epoch   9, Step:    34200, Batch Loss:     1.412897, Batch Acc: 0.628280, Tokens per Sec:     3914, Lr: 0.000300
2025-05-29 12:21:24,063 - INFO - joeynmt.training - Epoch   9, Step:    34300, Batch Loss:     1.222196, Batch Acc: 0.621983, Tokens per Sec:     3494, Lr: 0.000300
2025-05-29 12:21:43,879 - INFO - joeynmt.training - Epoch   9, Step:    34400, Batch Loss:     1.404875, Batch Acc: 0.629642, Tokens per Sec:     3511, Lr: 0.000300
2025-05-29 12:22:01,481 - INFO - joeynmt.training - Epoch   9, Step:    34500, Batch Loss:     1.241315, Batch Acc: 0.627082, Tokens per Sec:     3964, Lr: 0.000300
2025-05-29 12:22:01,482 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:22:01,482 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:22:47,871 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.85, acc:   0.57, generation: 46.3799[sec], evaluation: 0.0000[sec]
2025-05-29 12:22:48,115 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/31500.ckpt
2025-05-29 12:22:48,118 - INFO - joeynmt.training - Example #0
2025-05-29 12:22:48,119 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:22:48,119 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:22:48,119 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', "'ve", 'sho@@', 'wn', 'this', 'year', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', '-@@', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ica', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 12:22:48,119 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:22:48,119 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:22:48,119 - INFO - joeynmt.training - 	Hypothesis: I 've shown this year I showed these slides to show that the glacial calott-glacial calottica , which is almost three million years had the size of the 48 continental .
2025-05-29 12:22:48,119 - INFO - joeynmt.training - Example #1
2025-05-29 12:22:48,119 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:22:48,119 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:22:48,119 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', "'s", 'not', 'sho@@', 'wing', 'the', 'problem', 'because', 'it', "'s", 'not', 'sho@@', 'wer', 'the', 'ice', 'of', 'ice', '.', '</s>']
2025-05-29 12:22:48,119 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:22:48,119 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:22:48,119 - INFO - joeynmt.training - 	Hypothesis: But this is a gravity of the problem because it 's not showing the problem because it 's not shower the ice of ice .
2025-05-29 12:22:48,119 - INFO - joeynmt.training - Example #2
2025-05-29 12:22:48,119 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:22:48,119 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:22:48,119 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'alc@@', 'al', 'cal@@', 'ot@@', 't@@', 'ica', 'is', ',', 'in', 'a', 'way', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:22:48,120 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:22:48,120 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:22:48,120 - INFO - joeynmt.training - 	Hypothesis: The arcalcal calottica is , in a way , the clear heart of the global climate system .
2025-05-29 12:22:48,120 - INFO - joeynmt.training - Example #3
2025-05-29 12:22:48,120 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:22:48,120 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:22:48,120 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'and@@', 'ed', 'up', 'on', 'the', 'sum@@', 'mer', 'and', 'you', "'re", 'r@@', 'iti@@', 'zed', '.', '</s>']
2025-05-29 12:22:48,120 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:22:48,120 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:22:48,120 - INFO - joeynmt.training - 	Hypothesis: You expanded up on the summer and you 're ritized .
2025-05-29 12:22:48,120 - INFO - joeynmt.training - Example #4
2025-05-29 12:22:48,120 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:22:48,120 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:22:48,120 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'rel@@', 'ated', 'to', 'the', 'ad@@', 'v@@', 'v@@', 'oc@@', 'ate', 'over', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:22:48,120 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:22:48,120 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:22:48,120 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick carrelated to the advvocate over the last 25 years .
2025-05-29 12:23:08,644 - INFO - joeynmt.training - Epoch   9, Step:    34600, Batch Loss:     1.512366, Batch Acc: 0.630196, Tokens per Sec:     3440, Lr: 0.000300
2025-05-29 12:23:28,487 - INFO - joeynmt.training - Epoch   9, Step:    34700, Batch Loss:     1.409852, Batch Acc: 0.627073, Tokens per Sec:     3708, Lr: 0.000300
2025-05-29 12:23:47,265 - INFO - joeynmt.training - Epoch   9, Step:    34800, Batch Loss:     1.225911, Batch Acc: 0.628925, Tokens per Sec:     3895, Lr: 0.000300
2025-05-29 12:24:04,728 - INFO - joeynmt.training - Epoch   9, Step:    34900, Batch Loss:     1.415397, Batch Acc: 0.630321, Tokens per Sec:     4187, Lr: 0.000300
2025-05-29 12:24:22,389 - INFO - joeynmt.training - Epoch   9, Step:    35000, Batch Loss:     1.455083, Batch Acc: 0.626859, Tokens per Sec:     4108, Lr: 0.000300
2025-05-29 12:24:22,390 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:24:22,390 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:25:02,967 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.86, acc:   0.57, generation: 40.5699[sec], evaluation: 0.0000[sec]
2025-05-29 12:25:03,409 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/33000.ckpt
2025-05-29 12:25:03,411 - INFO - joeynmt.training - Example #0
2025-05-29 12:25:03,411 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:25:03,411 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:25:03,411 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', "'ve", 'sho@@', 'wn', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 'c@@', 'cal@@', 'ot@@', 'ter', "'s", 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'has', 'had', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'percent', '.', '</s>']
2025-05-29 12:25:03,411 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:25:03,411 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:25:03,411 - INFO - joeynmt.training - 	Hypothesis: I 've shown these slides to show that the arccalotter 's glacial calott , which for almost three million years has had the size of 48 million years had the size of 48 percent .
2025-05-29 12:25:03,411 - INFO - joeynmt.training - Example #1
2025-05-29 12:25:03,412 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:25:03,412 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:25:03,412 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'l@@', 'ying', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sc@@', 'ore', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 12:25:03,412 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:25:03,412 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:25:03,412 - INFO - joeynmt.training - 	Hypothesis: But this underlying gravity of the problem because it doesn 't show the score of the ice .
2025-05-29 12:25:03,412 - INFO - joeynmt.training - Example #2
2025-05-29 12:25:03,412 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:25:03,412 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:25:03,412 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'A@@', 't@@', 'ical', 'cal@@', 'ot@@', 'ter', 'is', ',', 'in', 'a', 'way', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:25:03,412 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:25:03,412 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:25:03,412 - INFO - joeynmt.training - 	Hypothesis: The Atical calotter is , in a way , the clear heart of the global climate system .
2025-05-29 12:25:03,412 - INFO - joeynmt.training - Example #3
2025-05-29 12:25:03,412 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:25:03,412 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:25:03,412 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'exp@@', 'ands', 'up', 'to', 'w@@', 'int@@', 'er', 'and', 'you', 'r@@', 'iti@@', 'ate', '.', '</s>']
2025-05-29 12:25:03,412 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:25:03,412 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:25:03,412 - INFO - joeynmt.training - 	Hypothesis: It expands up to winter and you ritiate .
2025-05-29 12:25:03,412 - INFO - joeynmt.training - Example #4
2025-05-29 12:25:03,412 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:25:03,412 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:25:03,412 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'qu@@', 'ick', ',', 'you', 'know', ',', 'the', 'next', 'sli@@', 'de', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:25:03,412 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:25:03,412 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:25:03,412 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quick , you know , the next slide the last 25 years .
2025-05-29 12:25:23,565 - INFO - joeynmt.training - Epoch   9, Step:    35100, Batch Loss:     1.250851, Batch Acc: 0.622138, Tokens per Sec:     3385, Lr: 0.000300
2025-05-29 12:25:43,328 - INFO - joeynmt.training - Epoch   9, Step:    35200, Batch Loss:     1.383136, Batch Acc: 0.619510, Tokens per Sec:     3566, Lr: 0.000300
2025-05-29 12:26:02,528 - INFO - joeynmt.training - Epoch   9, Step:    35300, Batch Loss:     1.303725, Batch Acc: 0.625650, Tokens per Sec:     3695, Lr: 0.000300
2025-05-29 12:26:22,461 - INFO - joeynmt.training - Epoch   9, Step:    35400, Batch Loss:     1.496725, Batch Acc: 0.621957, Tokens per Sec:     3504, Lr: 0.000300
2025-05-29 12:26:43,522 - INFO - joeynmt.training - Epoch   9, Step:    35500, Batch Loss:     1.505777, Batch Acc: 0.621839, Tokens per Sec:     3430, Lr: 0.000300
2025-05-29 12:26:43,522 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:26:43,522 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:27:33,556 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.84, acc:   0.57, generation: 50.0260[sec], evaluation: 0.0000[sec]
2025-05-29 12:27:33,558 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 12:27:33,783 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/28500.ckpt
2025-05-29 12:27:33,788 - INFO - joeynmt.training - Example #0
2025-05-29 12:27:33,788 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:27:33,788 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:27:33,789 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'show', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', ',', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'size', 'of', 'the', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 12:27:33,789 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:27:33,789 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:27:33,789 - INFO - joeynmt.training - 	Hypothesis: I showed these slides to show these slides to show that the arctic ice , for almost three million years had the size of the 48 size of the 48 million years had the size of the 48 continental .
2025-05-29 12:27:33,789 - INFO - joeynmt.training - Example #1
2025-05-29 12:27:33,789 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:27:33,789 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:27:33,789 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho@@', 'w@@', 'ever', ',', 'this', 'sub@@', 'val@@', 'u@@', 'able', 'to', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', "'s", 'not', 'sho@@', 'wer', 'the', 'ice', 'of', 'ice', '.', '</s>']
2025-05-29 12:27:33,789 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:27:33,789 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:27:33,789 - INFO - joeynmt.training - 	Hypothesis: However , this subvaluable to gravity of the problem because it 's not shower the ice of ice .
2025-05-29 12:27:33,789 - INFO - joeynmt.training - Example #2
2025-05-29 12:27:33,789 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:27:33,789 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:27:33,789 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'is', ',', 'in', 'a', 'way', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:27:33,789 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:27:33,789 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:27:33,789 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial calottis , in a way , the clear heart of the global climate system .
2025-05-29 12:27:33,789 - INFO - joeynmt.training - Example #3
2025-05-29 12:27:33,789 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:27:33,789 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:27:33,789 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'an@@', 'ding', 'on', 'the', 'w@@', 'int@@', 'er', 'and', 're@@', 'tre@@', 'at@@', 'ment', '.', '</s>']
2025-05-29 12:27:33,790 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:27:33,790 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:27:33,790 - INFO - joeynmt.training - 	Hypothesis: You expanding on the winter and retreatment .
2025-05-29 12:27:33,790 - INFO - joeynmt.training - Example #4
2025-05-29 12:27:33,790 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:27:33,790 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:27:33,790 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rapi@@', 'd', 'car@@', 'rel@@', 'ated', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:27:33,790 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:27:33,790 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:27:33,790 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid carrelated to the last 25 years .
2025-05-29 12:27:53,889 - INFO - joeynmt.training - Epoch   9, Step:    35600, Batch Loss:     1.291194, Batch Acc: 0.619338, Tokens per Sec:     3435, Lr: 0.000300
2025-05-29 12:28:13,510 - INFO - joeynmt.training - Epoch   9, Step:    35700, Batch Loss:     1.235510, Batch Acc: 0.625009, Tokens per Sec:     3617, Lr: 0.000300
2025-05-29 12:28:33,943 - INFO - joeynmt.training - Epoch   9, Step:    35800, Batch Loss:     1.395911, Batch Acc: 0.624447, Tokens per Sec:     3510, Lr: 0.000300
2025-05-29 12:28:55,238 - INFO - joeynmt.training - Epoch   9, Step:    35900, Batch Loss:     1.454139, Batch Acc: 0.621361, Tokens per Sec:     3269, Lr: 0.000300
2025-05-29 12:29:13,614 - INFO - joeynmt.training - Epoch   9, Step:    36000, Batch Loss:     1.436441, Batch Acc: 0.622414, Tokens per Sec:     3899, Lr: 0.000300
2025-05-29 12:29:13,615 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:29:13,615 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:30:03,538 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.84, acc:   0.57, generation: 49.9151[sec], evaluation: 0.0000[sec]
2025-05-29 12:30:03,541 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 12:30:03,731 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/32500.ckpt
2025-05-29 12:30:03,735 - INFO - joeynmt.training - Example #0
2025-05-29 12:30:03,736 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:30:03,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:30:03,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'wn', 'these', 'sli@@', 'positi@@', 've', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'cal@@', 'ot@@', 't@@', 'ical', ',', 'for', 'almost', 'three', 'million', 'years', ',', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', 'dimen@@', 'sions', 'of', 'the', 'United', 'States', ',', 'it', "'s", 're@@', 'ach@@', 'es', ',', '40', 'percent', '.', '</s>']
2025-05-29 12:30:03,736 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:30:03,736 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:30:03,736 - INFO - joeynmt.training - 	Hypothesis: Last year I shown these slipositive slides to demonstrate that the arctic calottical , for almost three million years , the size of the 48 continental dimensions of the United States , it 's reaches , 40 percent .
2025-05-29 12:30:03,736 - INFO - joeynmt.training - Example #1
2025-05-29 12:30:03,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:30:03,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:30:03,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', "'s", 'actually', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', "'s", 'not', 'sho@@', 'wer', 'the', 'sh@@', 'ore', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 12:30:03,736 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:30:03,736 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:30:03,736 - INFO - joeynmt.training - 	Hypothesis: But it 's actually the gravity of the problem because it 's not shower the shore of the ice .
2025-05-29 12:30:03,736 - INFO - joeynmt.training - Example #2
2025-05-29 12:30:03,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:30:03,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:30:03,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'h', 'is', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:30:03,737 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:30:03,737 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:30:03,737 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial caloth is , in a certain sense , the clear heart of the global climate system .
2025-05-29 12:30:03,737 - INFO - joeynmt.training - Example #3
2025-05-29 12:30:03,737 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:30:03,737 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:30:03,737 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'and@@', 'ed', 'up', 'and', 'the', 'w@@', 'int@@', 'er', 'and', 'the', 'sum@@', 'mer', '.', '</s>']
2025-05-29 12:30:03,737 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:30:03,737 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:30:03,737 - INFO - joeynmt.training - 	Hypothesis: You expanded up and the winter and the summer .
2025-05-29 12:30:03,737 - INFO - joeynmt.training - Example #4
2025-05-29 12:30:03,737 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:30:03,737 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:30:03,737 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rapi@@', 'd', 'car@@', 'rel@@', 'ate', 'to', 'the', 'ad@@', 'v@@', 'anc@@', 'ement', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:30:03,737 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:30:03,737 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:30:03,737 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid carrelate to the advancement of the last 25 years .
2025-05-29 12:30:26,445 - INFO - joeynmt.training - Epoch   9, Step:    36100, Batch Loss:     1.223986, Batch Acc: 0.624052, Tokens per Sec:     3172, Lr: 0.000300
2025-05-29 12:30:46,403 - INFO - joeynmt.training - Epoch   9, Step:    36200, Batch Loss:     1.513243, Batch Acc: 0.623414, Tokens per Sec:     3602, Lr: 0.000300
2025-05-29 12:31:05,334 - INFO - joeynmt.training - Epoch   9, Step:    36300, Batch Loss:     1.261084, Batch Acc: 0.620336, Tokens per Sec:     3633, Lr: 0.000300
2025-05-29 12:31:26,052 - INFO - joeynmt.training - Epoch   9, Step:    36400, Batch Loss:     1.311646, Batch Acc: 0.624386, Tokens per Sec:     3556, Lr: 0.000300
2025-05-29 12:31:45,744 - INFO - joeynmt.training - Epoch   9, Step:    36500, Batch Loss:     1.399152, Batch Acc: 0.620437, Tokens per Sec:     3534, Lr: 0.000300
2025-05-29 12:31:45,745 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:31:45,745 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:32:29,609 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.84, acc:   0.57, generation: 43.8565[sec], evaluation: 0.0000[sec]
2025-05-29 12:32:29,611 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 12:32:29,850 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/35000.ckpt
2025-05-29 12:32:29,855 - INFO - joeynmt.training - Example #0
2025-05-29 12:32:29,856 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:32:29,856 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:32:29,856 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', ',', 'I', 'sho@@', 'wed', 'these', 'de@@', 'vic@@', 'es', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'ter', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', '.', '</s>']
2025-05-29 12:32:29,856 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:32:29,856 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:32:29,856 - INFO - joeynmt.training - 	Hypothesis: Last year , I showed these devices to demonstrate that the glacial calotter , which is almost three million years had the size of the 48 continental .
2025-05-29 12:32:29,856 - INFO - joeynmt.training - Example #1
2025-05-29 12:32:29,856 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:32:29,856 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:32:29,856 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'l@@', 'ying', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', "'s", 'not', 'about', 'the', 'sp@@', 'ess@@', 'or', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 12:32:29,856 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:32:29,856 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:32:29,856 - INFO - joeynmt.training - 	Hypothesis: But this underlying the gravity of the problem because it 's not about the spessor of the ice .
2025-05-29 12:32:29,856 - INFO - joeynmt.training - Example #2
2025-05-29 12:32:29,856 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:32:29,856 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:32:29,856 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'ter', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:32:29,857 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:32:29,857 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:32:29,857 - INFO - joeynmt.training - 	Hypothesis: The glacial calotter is , in a sense , the clear heart of the global climate system .
2025-05-29 12:32:29,857 - INFO - joeynmt.training - Example #3
2025-05-29 12:32:29,857 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:32:29,857 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:32:29,857 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'and@@', 'ed', 'w@@', 'int@@', 'er', 'and', 'you', 're@@', 'tre@@', 'at', 'the', 'sum@@', 'mer', '.', '</s>']
2025-05-29 12:32:29,857 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:32:29,857 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:32:29,857 - INFO - joeynmt.training - 	Hypothesis: You expanded winter and you retreat the summer .
2025-05-29 12:32:29,857 - INFO - joeynmt.training - Example #4
2025-05-29 12:32:29,857 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:32:29,857 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:32:29,857 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'rapi@@', 'd', 'car@@', 'rel@@', 'ed', 'on', 'the', 'ad@@', 'v@@', 'oc@@', 'ation', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:32:29,857 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:32:29,857 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:32:29,857 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a rapid carreled on the advocation of the last 25 years .
2025-05-29 12:32:50,188 - INFO - joeynmt.training - Epoch   9, Step:    36600, Batch Loss:     1.258561, Batch Acc: 0.617223, Tokens per Sec:     3474, Lr: 0.000300
2025-05-29 12:33:10,489 - INFO - joeynmt.training - Epoch   9, Step:    36700, Batch Loss:     1.150093, Batch Acc: 0.625103, Tokens per Sec:     3522, Lr: 0.000300
2025-05-29 12:33:17,595 - INFO - joeynmt.training - Epoch   9: total training loss 5385.17
2025-05-29 12:33:17,595 - INFO - joeynmt.training - EPOCH 10
2025-05-29 12:33:30,589 - INFO - joeynmt.training - Epoch  10, Step:    36800, Batch Loss:     1.292872, Batch Acc: 0.644782, Tokens per Sec:     3434, Lr: 0.000300
2025-05-29 12:33:50,506 - INFO - joeynmt.training - Epoch  10, Step:    36900, Batch Loss:     1.152003, Batch Acc: 0.645153, Tokens per Sec:     3551, Lr: 0.000300
2025-05-29 12:34:10,845 - INFO - joeynmt.training - Epoch  10, Step:    37000, Batch Loss:     1.362025, Batch Acc: 0.646066, Tokens per Sec:     3524, Lr: 0.000300
2025-05-29 12:34:10,846 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:34:10,846 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:34:56,713 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.84, acc:   0.57, generation: 45.8592[sec], evaluation: 0.0000[sec]
2025-05-29 12:34:56,946 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/34500.ckpt
2025-05-29 12:34:56,951 - INFO - joeynmt.training - Example #0
2025-05-29 12:34:56,951 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:34:56,951 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:34:56,951 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', ',', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'Ar@@', 'c@@', 'tic', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ical', ',', 'which', 'for', 'almost', 'three', 'million', 'years', ',', 'had', 'the', 'size', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', 'dimen@@', 'sions', ',', 'has', 'been', 're@@', 'mark@@', 'able', 'to', 'the', 'U.@@', 'S.', 'contin@@', 'ent@@', 'al', ',', 'has', 'been', 're@@', 'mark@@', 'able', 'to', '40', 'percent', '.', '</s>']
2025-05-29 12:34:56,951 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:34:56,951 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:34:56,951 - INFO - joeynmt.training - 	Hypothesis: Last year , I showed these slides to show that the Arctic glacial calottical , which for almost three million years , had the size of 48 continental dimensions , has been remarkable to the U.S. continental , has been remarkable to 40 percent .
2025-05-29 12:34:56,951 - INFO - joeynmt.training - Example #1
2025-05-29 12:34:56,952 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:34:56,952 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:34:56,952 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'read@@', 'ing', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'read@@', 'ing', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 12:34:56,952 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:34:56,952 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:34:56,952 - INFO - joeynmt.training - 	Hypothesis: But this is a gravity of the problem because it doesn 't show the spreading because it doesn 't show the spreading of the ice .
2025-05-29 12:34:56,952 - INFO - joeynmt.training - Example #2
2025-05-29 12:34:56,952 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:34:56,952 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:34:56,952 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ical', 'is', ',', 'in', 'a', 'way', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:34:56,952 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:34:56,952 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:34:56,952 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial calottical is , in a way , the clear heart of the global climate system .
2025-05-29 12:34:56,952 - INFO - joeynmt.training - Example #3
2025-05-29 12:34:56,952 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:34:56,952 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:34:56,952 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'and@@', 'ed', 'up', 'and', 'h@@', 'and@@', 'w@@', 'id@@', 'er', 'and', 're@@', 'ti@@', 'red', 'of', 'ex@@', 'tre@@', 'me', '.', '</s>']
2025-05-29 12:34:56,952 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:34:56,952 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:34:56,952 - INFO - joeynmt.training - 	Hypothesis: You expanded up and handwider and retired of extreme .
2025-05-29 12:34:56,952 - INFO - joeynmt.training - Example #4
2025-05-29 12:34:56,952 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:34:56,952 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:34:56,952 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'positi@@', 've', 'is', 'going', 'to', 'be', 'a', 'k@@', 'it@@', 'er@@', '-@@', 'to@@', '-@@', 'r@@', 'an', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:34:56,953 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:34:56,953 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:34:56,953 - INFO - joeynmt.training - 	Hypothesis: The next positive is going to be a kiter-to-ran on the last 25 years .
2025-05-29 12:35:15,797 - INFO - joeynmt.training - Epoch  10, Step:    37100, Batch Loss:     1.278578, Batch Acc: 0.643810, Tokens per Sec:     3553, Lr: 0.000300
2025-05-29 12:35:34,615 - INFO - joeynmt.training - Epoch  10, Step:    37200, Batch Loss:     1.136560, Batch Acc: 0.641071, Tokens per Sec:     3803, Lr: 0.000300
2025-05-29 12:35:52,877 - INFO - joeynmt.training - Epoch  10, Step:    37300, Batch Loss:     1.280290, Batch Acc: 0.649107, Tokens per Sec:     3948, Lr: 0.000300
2025-05-29 12:36:11,284 - INFO - joeynmt.training - Epoch  10, Step:    37400, Batch Loss:     1.076085, Batch Acc: 0.642045, Tokens per Sec:     3879, Lr: 0.000300
2025-05-29 12:36:30,368 - INFO - joeynmt.training - Epoch  10, Step:    37500, Batch Loss:     1.208866, Batch Acc: 0.638823, Tokens per Sec:     3851, Lr: 0.000300
2025-05-29 12:36:30,368 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:36:30,368 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:37:22,338 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.83, acc:   0.57, generation: 51.9616[sec], evaluation: 0.0000[sec]
2025-05-29 12:37:22,341 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 12:37:22,608 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/32000.ckpt
2025-05-29 12:37:22,612 - INFO - joeynmt.training - Example #0
2025-05-29 12:37:22,612 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:37:22,612 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:37:22,612 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'these', 'de@@', 'vic@@', 'es', 'to', 'show', 'that', 'the', 'Ar@@', 'c@@', 'tic', 'ice', ',', 'for', 'almost', 'three', 'million', 'years', ',', 'which', 'for', 'almost', 'three', 'million', 'years', ',', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', 'size', 'of', '4@@', '8', 'percent', '.', '</s>']
2025-05-29 12:37:22,612 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:37:22,612 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:37:22,612 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these these devices to show that the Arctic ice , for almost three million years , which for almost three million years , had the size of the 48 continental size of 48 percent .
2025-05-29 12:37:22,612 - INFO - joeynmt.training - Example #1
2025-05-29 12:37:22,612 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:37:22,612 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:37:22,612 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'or@@', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 12:37:22,612 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:37:22,613 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:37:22,613 - INFO - joeynmt.training - 	Hypothesis: But this is a gravity of the problem because it doesn 't show the sporof the ice of the ice .
2025-05-29 12:37:22,613 - INFO - joeynmt.training - Example #2
2025-05-29 12:37:22,613 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:37:22,613 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:37:22,613 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'gl@@', 'aci@@', 'al', 'is', ',', 'in', 'a', 'way', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:37:22,613 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:37:22,613 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:37:22,613 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial is , in a way , the clear heart of the global climate system .
2025-05-29 12:37:22,613 - INFO - joeynmt.training - Example #3
2025-05-29 12:37:22,613 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:37:22,613 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:37:22,613 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'an@@', 'ies', 'of', 'w@@', 'int@@', 'er', 'and', 'you', 'take', 'away', 'away', '.', '</s>']
2025-05-29 12:37:22,613 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:37:22,613 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:37:22,613 - INFO - joeynmt.training - 	Hypothesis: You expanies of winter and you take away away .
2025-05-29 12:37:22,613 - INFO - joeynmt.training - Example #4
2025-05-29 12:37:22,613 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:37:22,613 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:37:22,613 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'positi@@', 've', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'rel@@', 'ated', 'to', 'the', 'ad@@', 'v@@', 'oc@@', 'ate', 'over', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:37:22,613 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:37:22,613 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:37:22,613 - INFO - joeynmt.training - 	Hypothesis: The next next positive is going to be a quick carrelated to the advocate over the last 25 years .
2025-05-29 12:37:41,101 - INFO - joeynmt.training - Epoch  10, Step:    37600, Batch Loss:     1.197819, Batch Acc: 0.635644, Tokens per Sec:     3836, Lr: 0.000300
2025-05-29 12:38:00,606 - INFO - joeynmt.training - Epoch  10, Step:    37700, Batch Loss:     1.123592, Batch Acc: 0.639688, Tokens per Sec:     3540, Lr: 0.000300
2025-05-29 12:38:20,662 - INFO - joeynmt.training - Epoch  10, Step:    37800, Batch Loss:     1.185983, Batch Acc: 0.634260, Tokens per Sec:     3605, Lr: 0.000300
2025-05-29 12:38:41,468 - INFO - joeynmt.training - Epoch  10, Step:    37900, Batch Loss:     1.357080, Batch Acc: 0.638117, Tokens per Sec:     3407, Lr: 0.000300
2025-05-29 12:39:03,604 - INFO - joeynmt.training - Epoch  10, Step:    38000, Batch Loss:     1.225807, Batch Acc: 0.633271, Tokens per Sec:     3222, Lr: 0.000300
2025-05-29 12:39:03,619 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:39:03,620 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:39:54,327 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.82, acc:   0.57, generation: 50.6988[sec], evaluation: 0.0000[sec]
2025-05-29 12:39:54,329 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 12:39:54,632 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/35500.ckpt
2025-05-29 12:39:54,634 - INFO - joeynmt.training - Example #0
2025-05-29 12:39:54,666 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:39:54,667 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:39:54,667 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'show', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 'ter', ',', 'which', 'for', 'almost', 'three', 'million', 'years', ',', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', 'size', 'of', 'the', 'United', 'States', ',', 'it', "'s", 're@@', 'ar@@', 't@@', 'ical', ',', 'that', 'was', 're@@', 'ar@@', 't@@', 'ical', 'of', '40', 'percent', '.', '</s>']
2025-05-29 12:39:54,668 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:39:54,668 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:39:54,668 - INFO - joeynmt.training - 	Hypothesis: I showed these slides to show these slides to show that the glacial calotter , which for almost three million years , had the size of the 48 continental size of the United States , it 's reartical , that was reartical of 40 percent .
2025-05-29 12:39:54,668 - INFO - joeynmt.training - Example #1
2025-05-29 12:39:54,669 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:39:54,669 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:39:54,669 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'val@@', 'u@@', 'es', 'the', 'problem', ',', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ent', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 12:39:54,669 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:39:54,669 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:39:54,669 - INFO - joeynmt.training - 	Hypothesis: But this subvalues the problem , because it doesn 't show the spent of the ice .
2025-05-29 12:39:54,669 - INFO - joeynmt.training - Example #2
2025-05-29 12:39:54,670 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:39:54,670 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:39:54,670 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ical', 'cal@@', 'ot@@', 'ter', 'is', 'in', 'a', 'way', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:39:54,670 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:39:54,670 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:39:54,670 - INFO - joeynmt.training - 	Hypothesis: The artical calotter is in a way , the clear heart of the global climate system .
2025-05-29 12:39:54,670 - INFO - joeynmt.training - Example #3
2025-05-29 12:39:54,670 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:39:54,670 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:39:54,670 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'exp@@', 'and@@', 'ed', 'by', 'the', 'sum@@', 'mer', '.', '</s>']
2025-05-29 12:39:54,670 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:39:54,670 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:39:54,671 - INFO - joeynmt.training - 	Hypothesis: It 's expanded by the summer .
2025-05-29 12:39:54,671 - INFO - joeynmt.training - Example #4
2025-05-29 12:39:54,671 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:39:54,671 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:39:54,671 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'rapi@@', 'd', 'car@@', 'rel@@', 'ed', 'on', 'the', 'ad@@', 'v@@', 'anc@@', 'ed', 'for', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:39:54,671 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:39:54,671 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:39:54,671 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a rapid carreled on the advanced for the last 25 years .
2025-05-29 12:40:15,470 - INFO - joeynmt.training - Epoch  10, Step:    38100, Batch Loss:     1.181095, Batch Acc: 0.638631, Tokens per Sec:     3423, Lr: 0.000300
2025-05-29 12:40:36,757 - INFO - joeynmt.training - Epoch  10, Step:    38200, Batch Loss:     1.382752, Batch Acc: 0.636901, Tokens per Sec:     3495, Lr: 0.000300
2025-05-29 12:40:57,789 - INFO - joeynmt.training - Epoch  10, Step:    38300, Batch Loss:     1.306151, Batch Acc: 0.635998, Tokens per Sec:     3480, Lr: 0.000300
2025-05-29 12:41:17,238 - INFO - joeynmt.training - Epoch  10, Step:    38400, Batch Loss:     1.237198, Batch Acc: 0.641332, Tokens per Sec:     3791, Lr: 0.000300
2025-05-29 12:41:38,033 - INFO - joeynmt.training - Epoch  10, Step:    38500, Batch Loss:     1.236516, Batch Acc: 0.634777, Tokens per Sec:     3430, Lr: 0.000300
2025-05-29 12:41:38,034 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:41:38,034 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:42:30,071 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.83, acc:   0.57, generation: 52.0278[sec], evaluation: 0.0000[sec]
2025-05-29 12:42:30,363 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/36000.ckpt
2025-05-29 12:42:30,365 - INFO - joeynmt.training - Example #0
2025-05-29 12:42:30,365 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:42:30,365 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:42:30,365 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', "'ve", 'sho@@', 'wn', 'these', 'de@@', 'vic@@', 'es', 'to', 'show', 'that', 'the', 'sli@@', 'des', 'of', 'the', 'bo@@', 'tto@@', 'm', 'of', 'the', 'ar@@', 'c@@', 'tic', 'ice', ',', 'which', 'for', 'almost', 'three', 'million', 'years', ',', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', 'dimen@@', 'sions', ',', 'is', 'clo@@', 'sel@@', 'y', 'of', '40', 'percent', '.', '</s>']
2025-05-29 12:42:30,365 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:42:30,365 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:42:30,365 - INFO - joeynmt.training - 	Hypothesis: I 've shown these devices to show that the slides of the bottom of the arctic ice , which for almost three million years , had the size of the 48 continental dimensions , is closely of 40 percent .
2025-05-29 12:42:30,365 - INFO - joeynmt.training - Example #1
2025-05-29 12:42:30,365 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:42:30,365 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:42:30,365 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 'sub@@', 'val@@', 'ue', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ent', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 12:42:30,365 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:42:30,365 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:42:30,365 - INFO - joeynmt.training - 	Hypothesis: But this is a subvalue of the problem because it doesn 't show the spent of the ice of the ice of the ice of the ice .
2025-05-29 12:42:30,365 - INFO - joeynmt.training - Example #2
2025-05-29 12:42:30,366 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:42:30,366 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:42:30,366 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'ice', 'is', 'in', 'a', 'sense', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', 'c@@', 'lue', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:42:30,366 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:42:30,366 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:42:30,366 - INFO - joeynmt.training - 	Hypothesis: The arctic ice is in a sense , in a sense , the clean clue heart of the global climate system .
2025-05-29 12:42:30,366 - INFO - joeynmt.training - Example #3
2025-05-29 12:42:30,366 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:42:30,366 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:42:30,366 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'exp@@', 'and@@', 'ed', 'on', 'the', 'w@@', 'int@@', 'er', 'and', 'the', 'sum@@', 'mer', '.', '</s>']
2025-05-29 12:42:30,366 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:42:30,366 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:42:30,366 - INFO - joeynmt.training - 	Hypothesis: It expanded on the winter and the summer .
2025-05-29 12:42:30,366 - INFO - joeynmt.training - Example #4
2025-05-29 12:42:30,366 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:42:30,366 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:42:30,366 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'rapi@@', 'd', 'car@@', 'rel@@', 'ed', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:42:30,366 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:42:30,366 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:42:30,366 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a rapid carreled on the last 25 years .
2025-05-29 12:42:53,761 - INFO - joeynmt.training - Epoch  10, Step:    38600, Batch Loss:     1.241167, Batch Acc: 0.631702, Tokens per Sec:     3061, Lr: 0.000300
2025-05-29 12:43:16,934 - INFO - joeynmt.training - Epoch  10, Step:    38700, Batch Loss:     1.360526, Batch Acc: 0.634037, Tokens per Sec:     3089, Lr: 0.000300
2025-05-29 12:43:41,075 - INFO - joeynmt.training - Epoch  10, Step:    38800, Batch Loss:     1.377221, Batch Acc: 0.632696, Tokens per Sec:     2962, Lr: 0.000300
2025-05-29 12:44:03,682 - INFO - joeynmt.training - Epoch  10, Step:    38900, Batch Loss:     1.630319, Batch Acc: 0.636300, Tokens per Sec:     3118, Lr: 0.000300
2025-05-29 12:44:26,748 - INFO - joeynmt.training - Epoch  10, Step:    39000, Batch Loss:     1.169695, Batch Acc: 0.629167, Tokens per Sec:     3124, Lr: 0.000300
2025-05-29 12:44:26,749 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:44:26,749 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:45:17,317 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.79, acc:   0.57, generation: 50.5588[sec], evaluation: 0.0000[sec]
2025-05-29 12:45:17,320 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 12:45:17,638 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/37000.ckpt
2025-05-29 12:45:17,644 - INFO - joeynmt.training - Example #0
2025-05-29 12:45:17,644 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:45:17,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:45:17,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'last', 'year', 'I', 'sho@@', 'wed', 'these', 'de@@', 'vic@@', 'es', 'to', 'show', 'that', 'the', 'ar@@', 't@@', 'ical', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', ',', 'which', 'was', 'almost', 'three', 'million', 'years', 'old', 'had', 'the', 'size', 'of', '4@@', '8', 'the', 'size', 'of', 'the', 'United', 'States', ',', 'it', "'s", '4@@', '8', 'percent', '.', '</s>']
2025-05-29 12:45:17,644 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:45:17,644 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:45:17,644 - INFO - joeynmt.training - 	Hypothesis: And last year I showed these devices to show that the artical ice ice ice ice ice ice ice ice , which was almost three million years old had the size of 48 the size of the United States , it 's 48 percent .
2025-05-29 12:45:17,644 - INFO - joeynmt.training - Example #1
2025-05-29 12:45:17,644 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:45:17,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:45:17,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'est@@', 'im@@', 'ates', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', "'s", 'not', 'shows', 'the', 'ex@@', 'ec@@', 'uti@@', 've', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 12:45:17,644 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:45:17,644 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:45:17,644 - INFO - joeynmt.training - 	Hypothesis: But this underestimates the gravity of the problem because it 's not shows the executive of the ice .
2025-05-29 12:45:17,644 - INFO - joeynmt.training - Example #2
2025-05-29 12:45:17,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:45:17,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:45:17,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ical', 'ho@@', 't', 'is', ',', 'in', 'a', 'way', ',', 'the', 'cle@@', 'ar', 'cle@@', 'ar', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:45:17,645 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:45:17,645 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:45:17,645 - INFO - joeynmt.training - 	Hypothesis: The artical hot is , in a way , the clear clear of the global climate system .
2025-05-29 12:45:17,645 - INFO - joeynmt.training - Example #3
2025-05-29 12:45:17,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:45:17,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:45:17,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'exp@@', 'ands', 'up', 'w@@', 'int@@', 'er', 'and', 'you', "'re", 'r@@', 'iti@@', 'ate', '.', '</s>']
2025-05-29 12:45:17,645 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:45:17,645 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:45:17,645 - INFO - joeynmt.training - 	Hypothesis: It expands up winter and you 're ritiate .
2025-05-29 12:45:17,645 - INFO - joeynmt.training - Example #4
2025-05-29 12:45:17,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:45:17,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:45:17,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rapi@@', 'd', 'car@@', 'rel@@', 'ated', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:45:17,645 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:45:17,645 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:45:17,645 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid carrelated on the last 25 years .
2025-05-29 12:45:39,032 - INFO - joeynmt.training - Epoch  10, Step:    39100, Batch Loss:     1.315569, Batch Acc: 0.634965, Tokens per Sec:     3323, Lr: 0.000300
2025-05-29 12:46:00,246 - INFO - joeynmt.training - Epoch  10, Step:    39200, Batch Loss:     1.204475, Batch Acc: 0.632390, Tokens per Sec:     3287, Lr: 0.000300
2025-05-29 12:46:18,755 - INFO - joeynmt.training - Epoch  10, Step:    39300, Batch Loss:     1.193595, Batch Acc: 0.628714, Tokens per Sec:     3815, Lr: 0.000300
2025-05-29 12:46:36,928 - INFO - joeynmt.training - Epoch  10, Step:    39400, Batch Loss:     1.231944, Batch Acc: 0.633318, Tokens per Sec:     3903, Lr: 0.000300
2025-05-29 12:46:56,283 - INFO - joeynmt.training - Epoch  10, Step:    39500, Batch Loss:     1.180516, Batch Acc: 0.631141, Tokens per Sec:     3890, Lr: 0.000300
2025-05-29 12:46:56,284 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:46:56,284 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:47:42,819 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.56, ppl:   4.78, acc:   0.57, generation: 46.5276[sec], evaluation: 0.0000[sec]
2025-05-29 12:47:42,821 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 12:47:43,042 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/36500.ckpt
2025-05-29 12:47:43,051 - INFO - joeynmt.training - Example #0
2025-05-29 12:47:43,051 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:47:43,052 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:47:43,052 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'de@@', 'vic@@', 'es', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ical', 'war@@', 'm', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'United', 'States', ',', 'which', 'is', 'about', '40', 'percent', '.', '</s>']
2025-05-29 12:47:43,052 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:47:43,052 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:47:43,052 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these devices to show that the glacial calottical warm , which for almost three million years had the size of the 48 United States , which is about 40 percent .
2025-05-29 12:47:43,052 - INFO - joeynmt.training - Example #1
2025-05-29 12:47:43,052 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:47:43,052 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:47:43,052 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'l@@', 'ying', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'ent', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 12:47:43,052 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:47:43,052 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:47:43,052 - INFO - joeynmt.training - 	Hypothesis: But this underlying gravity of the problem because it doesn 't show the spent of the ice .
2025-05-29 12:47:43,052 - INFO - joeynmt.training - Example #2
2025-05-29 12:47:43,052 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:47:43,052 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:47:43,052 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'gl@@', 'aci@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:47:43,052 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:47:43,052 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:47:43,052 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial is , in a sense , the clear heart of the global climate system .
2025-05-29 12:47:43,052 - INFO - joeynmt.training - Example #3
2025-05-29 12:47:43,052 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:47:43,052 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:47:43,052 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'and', 'it', 'to', 'the', 'sum@@', 'mer', '.', '</s>']
2025-05-29 12:47:43,053 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:47:43,053 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:47:43,053 - INFO - joeynmt.training - 	Hypothesis: You expand it to the summer .
2025-05-29 12:47:43,053 - INFO - joeynmt.training - Example #4
2025-05-29 12:47:43,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:47:43,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:47:43,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'ri@@', 'ed', 'in', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:47:43,053 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:47:43,053 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:47:43,053 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick carried in the last 25 years .
2025-05-29 12:48:01,449 - INFO - joeynmt.training - Epoch  10, Step:    39600, Batch Loss:     1.234994, Batch Acc: 0.629527, Tokens per Sec:     3813, Lr: 0.000300
2025-05-29 12:48:18,987 - INFO - joeynmt.training - Epoch  10, Step:    39700, Batch Loss:     1.251672, Batch Acc: 0.635454, Tokens per Sec:     4101, Lr: 0.000300
2025-05-29 12:48:36,938 - INFO - joeynmt.training - Epoch  10, Step:    39800, Batch Loss:     1.483765, Batch Acc: 0.627189, Tokens per Sec:     3982, Lr: 0.000300
2025-05-29 12:48:55,469 - INFO - joeynmt.training - Epoch  10, Step:    39900, Batch Loss:     1.352922, Batch Acc: 0.628387, Tokens per Sec:     3761, Lr: 0.000300
2025-05-29 12:49:14,095 - INFO - joeynmt.training - Epoch  10, Step:    40000, Batch Loss:     1.247065, Batch Acc: 0.631942, Tokens per Sec:     3783, Lr: 0.000300
2025-05-29 12:49:14,096 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:49:14,096 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:50:01,578 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.79, acc:   0.57, generation: 47.4744[sec], evaluation: 0.0000[sec]
2025-05-29 12:50:01,779 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/38500.ckpt
2025-05-29 12:50:01,782 - INFO - joeynmt.training - Example #0
2025-05-29 12:50:01,783 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:50:01,783 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:50:01,783 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'ori@@', 'ous', 'cal@@', 'ot@@', 't@@', '-@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', '-@@', 'sc@@', 'aci@@', 'al', 'cal@@', 'ot@@', 't@@', 'ica', ',', 'which', 'for', 'almost', 'three', 'million', 'years', ',', 'had', 'the', 'size', 'of', '4@@', '8', '.', '</s>']
2025-05-29 12:50:01,783 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:50:01,783 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:50:01,783 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the glorious calott-acial calott-scacial calottica , which for almost three million years , had the size of 48 .
2025-05-29 12:50:01,783 - INFO - joeynmt.training - Example #1
2025-05-29 12:50:01,783 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:50:01,783 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:50:01,783 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'l@@', 'ying', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', "'s", 'not', 'sho@@', 'wing', 'the', 'ice', 'of', 'ice', '.', '</s>']
2025-05-29 12:50:01,783 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:50:01,783 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:50:01,783 - INFO - joeynmt.training - 	Hypothesis: But this underlying gravity of the problem because it 's not showing the ice of ice .
2025-05-29 12:50:01,783 - INFO - joeynmt.training - Example #2
2025-05-29 12:50:01,783 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:50:01,783 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:50:01,783 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ical', 'cal@@', 'ot@@', 'ter', 'is', ',', 'in', 'a', 'way', ',', 'the', 'cle@@', 'an', 'c@@', 'alc@@', 'ul@@', 'ation', 'of', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:50:01,783 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:50:01,783 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:50:01,783 - INFO - joeynmt.training - 	Hypothesis: The artical calotter is , in a way , the clean calculation of global climate system .
2025-05-29 12:50:01,783 - INFO - joeynmt.training - Example #3
2025-05-29 12:50:01,784 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:50:01,784 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:50:01,784 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', "'s", 'w@@', 'in@@', '-@@', 'gre@@', 'en', 'and', 'w@@', 'in@@', 'ds', '.', '</s>']
2025-05-29 12:50:01,784 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:50:01,784 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:50:01,784 - INFO - joeynmt.training - 	Hypothesis: It 's win-green and winds .
2025-05-29 12:50:01,784 - INFO - joeynmt.training - Example #4
2025-05-29 12:50:01,784 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:50:01,784 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:50:01,784 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'will', 'be', 'a', 'f@@', 'ast', 'relati@@', 'on@@', 'ship', 'to', 'the', 'ad@@', 'v@@', 'oc@@', 'ation', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:50:01,784 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:50:01,784 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:50:01,784 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a fast relationship to the advocation of the last 25 years .
2025-05-29 12:50:23,127 - INFO - joeynmt.training - Epoch  10, Step:    40100, Batch Loss:     1.265714, Batch Acc: 0.625681, Tokens per Sec:     3246, Lr: 0.000300
2025-05-29 12:50:44,817 - INFO - joeynmt.training - Epoch  10, Step:    40200, Batch Loss:     1.491811, Batch Acc: 0.628972, Tokens per Sec:     3324, Lr: 0.000300
2025-05-29 12:51:04,758 - INFO - joeynmt.training - Epoch  10, Step:    40300, Batch Loss:     1.327110, Batch Acc: 0.630988, Tokens per Sec:     3502, Lr: 0.000300
2025-05-29 12:51:24,482 - INFO - joeynmt.training - Epoch  10, Step:    40400, Batch Loss:     1.436064, Batch Acc: 0.621432, Tokens per Sec:     3579, Lr: 0.000300
2025-05-29 12:51:44,082 - INFO - joeynmt.training - Epoch  10, Step:    40500, Batch Loss:     1.427724, Batch Acc: 0.627646, Tokens per Sec:     3654, Lr: 0.000300
2025-05-29 12:51:44,083 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:51:44,083 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:52:33,601 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.56, ppl:   4.75, acc:   0.57, generation: 49.5096[sec], evaluation: 0.0000[sec]
2025-05-29 12:52:33,603 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 12:52:33,761 - INFO - joeynmt.helpers - delete models/transformer_bpe_3200/37500.ckpt
2025-05-29 12:52:33,765 - INFO - joeynmt.training - Example #0
2025-05-29 12:52:33,766 - DEBUG - joeynmt.training - 	Tokenized source:     ["L'", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 'tta', 'del', '40', '%', '.']
2025-05-29 12:52:33,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2025-05-29 12:52:33,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'wed', 'this', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'ad', 'the', 'ar@@', 'th@@', 't@@', 'ical', 'cal@@', 'ot@@', 't', ',', 'which', 'is', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'United', 'States', ',', 'which', 'is', 're@@', 'mark@@', 'able', 'to', '40', 'percent', '.', '</s>']
2025-05-29 12:52:33,766 - INFO - joeynmt.training - 	Source:     L' anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2025-05-29 12:52:33,766 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2025-05-29 12:52:33,766 - INFO - joeynmt.training - 	Hypothesis: Last year I showed this slides to show that the glad the arthtical calott , which is for almost three million years had the size of the 48 United States , which is remarkable to 40 percent .
2025-05-29 12:52:33,766 - INFO - joeynmt.training - Example #1
2025-05-29 12:52:33,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'so@@', 'tto@@', 'val@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2025-05-29 12:52:33,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2025-05-29 12:52:33,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'val@@', 'u@@', 'able', 'to', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', "'t", 'show', 'the', 'sp@@', 'or', 'of', 'the', 'ice', '.', '</s>']
2025-05-29 12:52:33,766 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2025-05-29 12:52:33,766 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn 't show the thickness of the ice .
2025-05-29 12:52:33,766 - INFO - joeynmt.training - 	Hypothesis: But this subvaluable to the gravity of the problem because it doesn 't show the spor of the ice .
2025-05-29 12:52:33,766 - INFO - joeynmt.training - Example #2
2025-05-29 12:52:33,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'globale', '.']
2025-05-29 12:52:33,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.']
2025-05-29 12:52:33,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'A@@', 't@@', 'ical', 'cal@@', 'ot@@', 'ter', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'ar', 'heart', 'of', 'the', 'global', 'cli@@', 'mate', 'system', '.', '</s>']
2025-05-29 12:52:33,766 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2025-05-29 12:52:33,766 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2025-05-29 12:52:33,766 - INFO - joeynmt.training - 	Hypothesis: The Atical calotter is , in a sense , the clear heart of the global climate system .
2025-05-29 12:52:33,766 - INFO - joeynmt.training - Example #3
2025-05-29 12:52:33,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', "d'", 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', "d'", 'est@@', 'ate', '.']
2025-05-29 12:52:33,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2025-05-29 12:52:33,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'exp@@', 'ands', 'up', 'the', 'w@@', 'int@@', 'er', 'and', 'you', 're@@', 'tre@@', 'at', 'it', '.', '</s>']
2025-05-29 12:52:33,767 - INFO - joeynmt.training - 	Source:     Si espande d' inverno e si ritira d' estate .
2025-05-29 12:52:33,767 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2025-05-29 12:52:33,767 - INFO - joeynmt.training - 	Hypothesis: You expands up the winter and you retreat it .
2025-05-29 12:52:33,767 - INFO - joeynmt.training - Example #4
2025-05-29 12:52:33,767 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2025-05-29 12:52:33,767 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'f@@', 'ast@@', '-@@', 'for@@', 'ward', 'of', 'what', "'s", 'happened', 'over', 'the', 'last', '25', 'years', '.']
2025-05-29 12:52:33,767 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', ',', 'in', 'the', 'last', '25', 'years', '.', '</s>']
2025-05-29 12:52:33,767 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2025-05-29 12:52:33,767 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what 's happened over the last 25 years .
2025-05-29 12:52:33,767 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick , in the last 25 years .
2025-05-29 12:52:52,635 - INFO - joeynmt.training - Epoch  10, Step:    40600, Batch Loss:     1.332523, Batch Acc: 0.631801, Tokens per Sec:     3675, Lr: 0.000300
2025-05-29 12:53:12,021 - INFO - joeynmt.training - Epoch  10, Step:    40700, Batch Loss:     1.376360, Batch Acc: 0.625546, Tokens per Sec:     3675, Lr: 0.000300
2025-05-29 12:53:31,022 - INFO - joeynmt.training - Epoch  10, Step:    40800, Batch Loss:     1.413463, Batch Acc: 0.626637, Tokens per Sec:     3644, Lr: 0.000300
2025-05-29 12:53:32,320 - INFO - joeynmt.training - Epoch  10: total training loss 5256.32
2025-05-29 12:53:32,321 - INFO - joeynmt.training - Training ended after  10 epochs.
2025-05-29 12:53:32,321 - INFO - joeynmt.training - Best validation result (greedy) at step    40500:   4.75 ppl.
2025-05-29 12:53:32,358 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-29 12:53:32,413 - INFO - joeynmt.model - Enc-dec model built.
2025-05-29 12:53:32,480 - INFO - joeynmt.helpers - Load model from /Users/jingma/Desktop/machine_translation/mt-exercise-4/models/transformer_bpe_3200/40500.ckpt.
2025-05-29 12:53:32,491 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=3418),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=3418),
	loss_function=None)
2025-05-29 12:53:32,501 - INFO - joeynmt.prediction - Decoding on dev set...
2025-05-29 12:53:32,501 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:53:32,501 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:54:27,224 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 54.7151[sec], evaluation: 0.0000[sec]
2025-05-29 12:54:27,230 - INFO - joeynmt.prediction - Translations saved to: /Users/jingma/Desktop/machine_translation/mt-exercise-4/models/transformer_bpe_3200/00040500.hyps.dev.
2025-05-29 12:54:27,230 - INFO - joeynmt.prediction - Decoding on test set...
2025-05-29 12:54:27,230 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 12:54:27,230 - INFO - joeynmt.prediction - Predicting 1566 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 12:55:48,840 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 81.5992[sec], evaluation: 0.0000[sec]
2025-05-29 12:55:48,844 - INFO - joeynmt.prediction - Translations saved to: /Users/jingma/Desktop/machine_translation/mt-exercise-4/models/transformer_bpe_3200/00040500.hyps.test.
